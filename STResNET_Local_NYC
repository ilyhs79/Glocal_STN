{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"STResNET_Local_NYC","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPscjnAVAb/aALyuaLi/bqC"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KV_EdNWClAq9","executionInfo":{"status":"ok","timestamp":1657429156114,"user_tz":-540,"elapsed":20872,"user":{"displayName":"Heounmo Go","userId":"00816368495368211847"}},"outputId":"656bb860-bd73-45a7-8382-456f70054dc9"},"source":["# google drive connect\n","Copied_path = '/content/drive/MyDrive/Colab Notebooks/MyPaper/GlocalSTN' # Paste target directory here\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir(Copied_path) "],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"AauHopRUnGYv","executionInfo":{"status":"ok","timestamp":1657429159635,"user_tz":-540,"elapsed":410,"user":{"displayName":"Heounmo Go","userId":"00816368495368211847"}}},"source":["# m0_Ent\n","\n","import numpy as np\n","\n","class MM:\n","    def __init__(self,MM_max,MM_min):\n","        self.max=MM_max\n","        self.min=MM_min\n","\n","# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n","def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n","    \n","    all_data=np.load('data3/m0_Ent.npy')\n","    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n","    len_total,feature,map_height,map_width=all_data.shape\n","    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n","    #len_total,feature,map_height,map_width=all_data.shape\n","    print('all_data shape: ',all_data.shape)\n","    #mm=MM(np.max(all_data),np.min(all_data))\n","    print('max=',np.max(all_data),' min=',np.min(all_data))\n","    \n","    #for time\n","    time=np.arange(len_total,dtype=int)\n","    #hour\n","    time_hour=time%T_period\n","    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n","    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n","    for i in range(len_total):\n","        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #day\n","    time_day=(time//T_period)%7\n","    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n","    for i in range(len_total):\n","        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #con\n","    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n","    \n","    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n","    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n","    \n","    if len_trend>0:\n","        number_of_skip_hours=T_trend*len_trend\n","    elif len_period>0:\n","        number_of_skip_hours=T_period*len_period\n","    elif len_closeness>0:\n","        number_of_skip_hours=T_closeness*len_closeness  \n","    else:\n","        print(\"wrong\")\n","    print('number_of_skip_hours:',number_of_skip_hours)\n","    \n","    Y=all_data[number_of_skip_hours:len_total]\n","\n","    if len_closeness>0:\n","        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n","        for i in range(len_closeness-1):\n","            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n","    if len_period>0:\n","        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n","        for i in range(len_period-1):\n","            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n","    if len_trend>0:\n","        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n","        for i in range(len_trend-1):\n","            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n","    \n","    matrix_T=matrix_T[number_of_skip_hours:]\n","    \n","    X_closeness_train=X_closeness[:-len_test] \n","    X_period_train=X_period[:-len_test] \n","    X_trend_train=X_trend[:-len_test]  \n","    T_train=matrix_T[:-len_test] \n","    X_closeness_test=X_closeness[-len_test:] \n","    X_period_test=X_period[-len_test:] \n","    X_trend_test=X_trend[-len_test:]          \n","    T_test=matrix_T[-len_test:]         \n","    \n","    X_train=[X_closeness_train,X_period_train,X_trend_train]\n","    X_test=[X_closeness_test,X_period_test,X_trend_test]\n","    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n","    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n","    Y_train=Y[:-len_test] \n","    Y_test=Y[-len_test:] \n","\n","    len_train=X_closeness_train.shape[0]\n","    len_test=X_closeness_test.shape[0]\n","    print('len_train='+str(len_train))\n","    print('len_test ='+str(len_test ))\n","    \n","    '''\n","    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n","    for i in range(poi.shape[0]):\n","        poi[i]=poi[i]/np.max(poi[i])\n","    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n","    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n","    \n","    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n","    '''\n","    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n","    "],"execution_count":2,"outputs":[]},{"cell_type":"code","source":["'''\n","# DST Network/ilayer.py 이건 ST resnet 쪽에 있던 ilayer,똑같은 거 같음\n","\n","\n","from keras import backend as K\n","from keras.engine.topology import Layer\n","# from keras.layers import Dense\n","import numpy as np\n","\n","\n","class iLayer(Layer):\n","    def __init__(self, **kwargs):\n","        # self.output_dim = output_dim\n","        super(iLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        initial_weight_value = np.random.random(input_shape[1:])\n","        self.W = K.variable(initial_weight_value)\n","        self.trainable_weights = [self.W]\n","\n","    def call(self, x, mask=None):\n","        return x * self.W\n","\n","    def get_output_shape_for(self, input_shape):\n","        return input_shape\n","'''\n"],"metadata":{"id":"cTwpbtYcnVFs","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1657429160184,"user_tz":-540,"elapsed":26,"user":{"displayName":"Heounmo Go","userId":"00816368495368211847"}},"outputId":"d77dc96d-870f-4b27-bef3-3d8b31f9e1a8"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# DST Network/ilayer.py 이건 ST resnet 쪽에 있던 ilayer,똑같은 거 같음\\n\\n\\nfrom keras import backend as K\\nfrom keras.engine.topology import Layer\\n# from keras.layers import Dense\\nimport numpy as np\\n\\n\\nclass iLayer(Layer):\\n    def __init__(self, **kwargs):\\n        # self.output_dim = output_dim\\n        super(iLayer, self).__init__(**kwargs)\\n\\n    def build(self, input_shape):\\n        initial_weight_value = np.random.random(input_shape[1:])\\n        self.W = K.variable(initial_weight_value)\\n        self.trainable_weights = [self.W]\\n\\n    def call(self, x, mask=None):\\n        return x * self.W\\n\\n    def get_output_shape_for(self, input_shape):\\n        return input_shape\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"FgFX7E7fo_a8","executionInfo":{"status":"ok","timestamp":1657429162996,"user_tz":-540,"elapsed":2510,"user":{"displayName":"Heounmo Go","userId":"00816368495368211847"}}},"source":["# DST Network/ilayer.py\n","\n","from keras import backend as K\n","#from keras.engine.topology import Layer\n","#from tensorflow.keras.layers import Layer\n","from keras.layers import Layer\n","# from keras.layers import Dense\n","import numpy as np\n","\n","\n","class iLayer(Layer):\n","    def __init__(self, **kwargs):\n","        # self.output_dim = output_dim\n","        super(iLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        initial_weight_value = np.random.random(input_shape[1:])\n","        self.W = K.variable(initial_weight_value)\n","        #self.trainable_weights = [self.W]\n","        self.trainable_weight = [self.W]\n","\n","    def call(self, x, mask=None):\n","        return x * self.W\n","\n","    def get_output_shape_for(self, input_shape):\n","        return input_shape"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"k925xkl8Uynj","executionInfo":{"status":"ok","timestamp":1657429162997,"user_tz":-540,"elapsed":19,"user":{"displayName":"Heounmo Go","userId":"00816368495368211847"}}},"source":["# \"metrics.py\"\n","\n","# import numpy as np\n","from keras import backend as K\n","\n","def mean_squared_error(y_true, y_pred):\n","    return K.mean(K.square(y_pred - y_true))\n","\n","\n","def root_mean_square_error(y_true, y_pred):\n","    return mean_squared_error(y_true, y_pred) ** 0.5\n","\n","def rmse(y_true, y_pred):\n","    return mean_squared_error(y_true, y_pred) ** 0.5\n","\n","\n","# aliases\n","mse = MSE = mean_squared_error\n","# rmse = RMSE = root_mean_square_error\n","\n","\n","def masked_mean_squared_error(y_true, y_pred):\n","    idx = (y_true > 1e-6).nonzero()\n","    return K.mean(K.square(y_pred[idx] - y_true[idx]))\n","\n","def masked_rmse(y_true, y_pred):\n","    return masked_mean_squared_error(y_true, y_pred) ** 0.5\n","\n","\n","def mean_absolute_error(y_true, y_pred):\n","    return K.mean(K.abs(y_pred - y_true))\n","\n","def mae(y_true, y_pred):\n","    return K.mean(K.abs(y_pred - y_true))\n","\n","\t\n","threshold=0.05\n","\n","def mean_absolute_percentage_error(y_true, y_pred):\n","    return K.mean( K.abs(y_pred-y_true) / K.maximum(K.cast(threshold,'float32'),y_true+1.0) )\n","\n","def mape(y_true, y_pred):\n","    return K.mean( K.abs(y_pred-y_true) / K.maximum(K.cast(threshold,'float32'),y_true+1.0) )\n","\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","source":["'''\n","    ST-ResNet: Deep Spatio-temporal Residual Networks\n","'''\n","#!pip install keras-layer-normalization\n","from keras.layers.convolutional import Conv2D\n","from __future__ import print_function\n","from keras.layers import (\n","    Input,\n","    Activation,\n","    merge,\n","    Dense,\n","    Reshape\n",")\n","from keras.layers.convolutional import Convolution2D\n","#from keras.layers.normalization import BatchNormalization\n","from keras.layers import Input,Activation,Dropout,BatchNormalization,AveragePooling2D,ZeroPadding2D,Multiply, Add\n","#from keras.layers import concatenate\n","#from tensorflow.keras.layers.normalization import BatchNormalization\n","from keras.models import Model\n","#from keras.utils.visualize_util import plot\n","\n","\n","def _shortcut(input, residual):\n","    #return merge([input, residual], mode='sum')\n","    return Add()([input,residual])\n","    \n","\n","\n","def _bn_relu_conv(nb_filter, nb_row, nb_col, subsample=(1, 1), bn=False):\n","    def f(input):\n","        if bn:\n","            input = BatchNormalization(mode=0, axis=1)(input)\n","        activation = Activation('relu')(input)\n","        #return Convolution2D(nb_filter=nb_filter, nb_row=nb_row, nb_col=nb_col, subsample=subsample, border_mode=\"same\")(activation)\n","        return Conv2D(filters=nb_filter, kernel_size=(nb_row, nb_col), strides=(1,1), padding=\"same\")(activation)\n","        \n","    return f\n","\n","\n","def _residual_unit(nb_filter, init_subsample=(1, 1)):\n","    def f(input):\n","        residual = _bn_relu_conv(nb_filter, 3, 3)(input)\n","        residual = _bn_relu_conv(nb_filter, 3, 3)(residual)\n","        return _shortcut(input, residual)\n","    return f\n","\n","\n","def ResUnits(residual_unit, nb_filter, repetations=1):\n","    def f(input):\n","        for i in range(repetations):\n","            init_subsample = (1, 1)\n","            input = residual_unit(nb_filter=nb_filter,init_subsample=init_subsample)(input)\n","        return input\n","    return f\n","\n","\n","def stresnet(c_conf=(3, 2, 32, 32), p_conf=(3, 2, 32, 32), t_conf=(3, 2, 32, 32), external_dim=8, nb_residual_unit=3, CF=64):\n","    '''\n","    C - Temporal Closeness\n","    P - Period\n","    T - Trend\n","    conf = (len_seq, nb_flow, map_height, map_width)\n","    external_dim\n","    '''\n","\n","    # main input\n","    main_inputs = []\n","    outputs = []\n","    for conf in [c_conf, p_conf, t_conf]:\n","        if conf is not None:\n","            len_seq, nb_flow, map_height, map_width = conf\n","            input = Input(shape=(nb_flow * len_seq, map_height, map_width))\n","            main_inputs.append(input)\n","            # Conv1\n","            #conv1 = Convolution2D(nb_filter=CF, nb_row=3, nb_col=3, border_mode=\"same\")(input)\n","            conv1 = Conv2D(filters=CF, kernel_size=(3,3),padding=\"same\")(input)\n","            # [nb_residual_unit] Residual Units\n","            residual_output = ResUnits(_residual_unit, nb_filter=CF,\n","                              repetations=nb_residual_unit)(conv1)\n","            # Conv2\n","            activation = Activation('relu')(residual_output)\n","            #conv2 = Convolution2D(nb_filter=nb_flow, nb_row=3, nb_col=3, border_mode=\"same\")(activation)\n","            conv2 = Conv2D(filters=nb_flow, kernel_size=(3,3),padding=\"same\")(activation)\n","            outputs.append(conv2)\n","\n","    # parameter-matrix-based fusion\n","    if len(outputs) == 1:\n","        main_output = outputs[0]\n","    else:\n","        #from DST_network.ilayer import iLayer\n","        new_outputs = []\n","        for output in outputs:\n","            new_outputs.append(iLayer()(output))\n","        #main_output = merge(new_outputs, mode='sum')\n","        main_output = Add()(new_outputs)\n","\n","    # fusing with external component\n","    if external_dim != None and external_dim > 0:\n","        # external input\n","        external_input = Input(shape=(external_dim,))\n","        main_inputs.append(external_input)\n","        embedding = Dense(output_dim=10)(external_input)\n","        embedding = Activation('relu')(embedding)\n","        h1 = Dense(output_dim=nb_flow * map_height * map_width)(embedding)\n","        activation = Activation('relu')(h1)\n","        external_output = Reshape((nb_flow, map_height, map_width))(activation)\n","        main_output = merge([main_output, external_output], mode='sum')\n","    else:\n","        print('external_dim:', external_dim)\n","\n","    main_output = Activation('tanh')(main_output)\n","    model = Model(inputs=main_inputs, outputs=main_output)\n","\n","    return model\n","'''\n","if __name__ == '__main__':\n","    model = stresnet(external_dim=28, nb_residual_unit=12)\n","    #plot(model, to_file='ST-ResNet.png', show_shapes=True)\n","    model.summary()\n","'''"],"metadata":{"id":"nJA-LD4IoEwq","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1657429163001,"user_tz":-540,"elapsed":19,"user":{"displayName":"Heounmo Go","userId":"00816368495368211847"}},"outputId":"216b252c-4831-4f1e-b706-583de3356ad4"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nif __name__ == '__main__':\\n    model = stresnet(external_dim=28, nb_residual_unit=12)\\n    #plot(model, to_file='ST-ResNet.png', show_shapes=True)\\n    model.summary()\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["\n","NO=4\n","#for reproduction\n","seed=1\n","for i in range(NO):\n","    seed=seed*10+7\n","seed=seed*10+7\n","np.random.seed(seed)\n","import tensorflow as tf  #from V1707\n","from keras import backend as K\n","\n","\n","#hyperparameters\n","epoch = 100  # number of epoch at training stage\n","batch_size = 32  # batch size\n","lr = 0.0001  # learning rate\n","\n","#H,W,channel = 21,12,2   # grid size\n","H,W,channel = 16,12,1   # grid size\n","\n","#T = 24*1  # number of time intervals in one day\n","T = 8*1  # number of time intervals in one day\n","\n","len_closeness = 4  # length of closeness dependent sequence\n","len_period = 4  # length of peroid dependent sequence\n","len_trend = 4  # length of trend dependent sequence\n","\n","T_closeness,T_period,T_trend=1,T,T*7\n","\n","# last 7 days for testing data\n","days_test = 14\n","len_test = T * days_test\n","\n","#the number of repetition and if retrain the model\n","iterate_num=10\n"],"metadata":{"id":"D6ttw6NLq5ys","executionInfo":{"status":"ok","timestamp":1657429177554,"user_tz":-540,"elapsed":300,"user":{"displayName":"Heounmo Go","userId":"00816368495368211847"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["\n","print(\"loading data...\")\n","#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","\n","R_N = 4   # number of residual units\n","\n","#from keras.optimizers import Adam\n","from tensorflow.keras.optimizers import Adam\n","from keras.layers.convolutional import Conv2D\n","#from DST_network.STResNet import stresnet\n","#import DST_network.metrics as metrics\n","#import PPT3_network.metrics as metrics\n","\n","def build_model(external_dim,CFN):\n","  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n","  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n","  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n","\n","  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n","  \n","  adam = Adam(lr=lr)\n","  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n","  #model.summary()\n","  #from keras.utils.visualize_util import plot\n","  #plot(model, to_file='model.png', show_shapes=True)\n","  return model\n","\n","\n","CF=64\n","\n","iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n","\n","RMSE=np.zeros([iterate_num,1])\n","MAE =np.zeros([iterate_num,1])\n","count_sum=iterate_num\n","\n","import time\n","\n","count=0\n","\n","  \n","for iterate_index in range(iterate_num):\n","  count=count+1\n","  iterate=iterate_loop[iterate_index]\n","      \n","  time_start=time.time()\n","  \n","  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n","      \n","  model = build_model(external_dim=False,CFN=CF)\n","  '''\n","  model_checkpoint=ModelCheckpoint(\n","      filepath=F,\n","      monitor='val_rmse',\n","      verbose=1,\n","      save_best_only=True,\n","      save_weights_only=False,\n","      mode='min',\n","      period=1)\n","  '''    \n","  print('=' * 10)\n","  print(\"training model...\")\n","  history = model.fit(X_train, Y_train,\n","                      epochs=epoch,\n","                      batch_size=batch_size,\n","                      validation_split=0.1,\n","                      #callbacks=[model_checkpoint],\n","                      verbose=0)\n","      \n","  #print('=' * 10)\n","  #print('evaluating using the model that has the best loss on the valid set')\n","  #model.load_weights(F)\n","  \n","  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n","  print('              mse     rmse    mae')\n","  print('Train score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n","  print('Test  score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  print(np.array(score))\n","      \n","  RMSE[iterate_index,0]=score[1]\n","  MAE [iterate_index,0]=score[2]\n","      \n","  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n","\n","  np.set_printoptions(precision=4, suppress=True)\n","  print('RMSE  MAE')\n","  print(for_show)\n","      \n","  for_show=np.mean(for_show,axis=0)\n","  print('RMSE  MAE')\n","  print(for_show)\n","  \n","  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n","      \n","  time_end=time.time()\n","      \n","  print('totally cost',time_end-time_start)\n","  print(str(count)+'/'+str(count_sum))\n","\n"],"metadata":{"id":"9Ym-sGl1oyGv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657429363373,"user_tz":-540,"elapsed":184990,"user":{"displayName":"Heounmo Go","userId":"00816368495368211847"}},"outputId":"9a069bd1-45d4-464f-eeab-1deb3a8edbf1"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["loading data...\n","all_data shape:  (800, 1, 16, 12)\n","max= 49.0  min= 0.0\n","mean= -0.9962797619047619  variance= 0.02770920949471694\n","number_of_skip_hours: 224\n","len_train=464\n","len_test =112\n","external_dim: False\n","==========\n","training model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["              mse     rmse    mae\n","Train score: Test  score: [0.000268 0.016368 0.002159]\n","RMSE  MAE\n","[[0.0164 0.0022]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0016 0.0002]\n","totally cost 28.71329164505005\n","1/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000268 0.016368 0.002149]\n","RMSE  MAE\n","[[0.0164 0.0022]\n"," [0.0164 0.0021]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0033 0.0004]\n","totally cost 17.646305084228516\n","2/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000268 0.016368 0.00212 ]\n","RMSE  MAE\n","[[0.0164 0.0022]\n"," [0.0164 0.0021]\n"," [0.0164 0.0021]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0049 0.0006]\n","totally cost 17.07029914855957\n","3/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000268 0.016368 0.002184]\n","RMSE  MAE\n","[[0.0164 0.0022]\n"," [0.0164 0.0021]\n"," [0.0164 0.0021]\n"," [0.0164 0.0022]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0065 0.0009]\n","totally cost 17.5172758102417\n","4/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000268 0.016368 0.00217 ]\n","RMSE  MAE\n","[[0.0164 0.0022]\n"," [0.0164 0.0021]\n"," [0.0164 0.0021]\n"," [0.0164 0.0022]\n"," [0.0164 0.0022]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0082 0.0011]\n","totally cost 17.364298105239868\n","5/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000263 0.016209 0.002459]\n","RMSE  MAE\n","[[0.0164 0.0022]\n"," [0.0164 0.0021]\n"," [0.0164 0.0021]\n"," [0.0164 0.0022]\n"," [0.0164 0.0022]\n"," [0.0162 0.0025]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0098 0.0013]\n","totally cost 17.025307178497314\n","6/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000268 0.016366 0.002265]\n","RMSE  MAE\n","[[0.0164 0.0022]\n"," [0.0164 0.0021]\n"," [0.0164 0.0021]\n"," [0.0164 0.0022]\n"," [0.0164 0.0022]\n"," [0.0162 0.0025]\n"," [0.0164 0.0023]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0114 0.0016]\n","totally cost 17.721054792404175\n","7/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000267 0.016347 0.002462]\n","RMSE  MAE\n","[[0.0164 0.0022]\n"," [0.0164 0.0021]\n"," [0.0164 0.0021]\n"," [0.0164 0.0022]\n"," [0.0164 0.0022]\n"," [0.0162 0.0025]\n"," [0.0164 0.0023]\n"," [0.0163 0.0025]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0131 0.0018]\n","totally cost 17.12771701812744\n","8/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000268 0.016367 0.002185]\n","RMSE  MAE\n","[[0.0164 0.0022]\n"," [0.0164 0.0021]\n"," [0.0164 0.0021]\n"," [0.0164 0.0022]\n"," [0.0164 0.0022]\n"," [0.0162 0.0025]\n"," [0.0164 0.0023]\n"," [0.0163 0.0025]\n"," [0.0164 0.0022]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0147 0.002 ]\n","totally cost 17.17501735687256\n","9/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000263 0.016204 0.0027  ]\n","RMSE  MAE\n","[[0.0164 0.0022]\n"," [0.0164 0.0021]\n"," [0.0164 0.0021]\n"," [0.0164 0.0022]\n"," [0.0164 0.0022]\n"," [0.0162 0.0025]\n"," [0.0164 0.0023]\n"," [0.0163 0.0025]\n"," [0.0164 0.0022]\n"," [0.0162 0.0027]]\n","RMSE  MAE\n","[0.0163 0.0023]\n","totally cost 17.518725872039795\n","10/10\n"]}]},{"cell_type":"code","source":["# m1_Col\n","\n","import numpy as np\n","\n","class MM:\n","    def __init__(self,MM_max,MM_min):\n","        self.max=MM_max\n","        self.min=MM_min\n","\n","# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n","def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n","    \n","    all_data=np.load('data3/m1_Col.npy')\n","    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n","    len_total,feature,map_height,map_width=all_data.shape\n","    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n","    #len_total,feature,map_height,map_width=all_data.shape\n","    print('all_data shape: ',all_data.shape)\n","    #mm=MM(np.max(all_data),np.min(all_data))\n","    print('max=',np.max(all_data),' min=',np.min(all_data))\n","    \n","    #for time\n","    time=np.arange(len_total,dtype=int)\n","    #hour\n","    time_hour=time%T_period\n","    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n","    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n","    for i in range(len_total):\n","        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #day\n","    time_day=(time//T_period)%7\n","    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n","    for i in range(len_total):\n","        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #con\n","    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n","    \n","    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n","    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n","    \n","    if len_trend>0:\n","        number_of_skip_hours=T_trend*len_trend\n","    elif len_period>0:\n","        number_of_skip_hours=T_period*len_period\n","    elif len_closeness>0:\n","        number_of_skip_hours=T_closeness*len_closeness  \n","    else:\n","        print(\"wrong\")\n","    print('number_of_skip_hours:',number_of_skip_hours)\n","    \n","    Y=all_data[number_of_skip_hours:len_total]\n","\n","    if len_closeness>0:\n","        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n","        for i in range(len_closeness-1):\n","            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n","    if len_period>0:\n","        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n","        for i in range(len_period-1):\n","            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n","    if len_trend>0:\n","        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n","        for i in range(len_trend-1):\n","            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n","    \n","    matrix_T=matrix_T[number_of_skip_hours:]\n","    \n","    X_closeness_train=X_closeness[:-len_test] \n","    X_period_train=X_period[:-len_test] \n","    X_trend_train=X_trend[:-len_test]  \n","    T_train=matrix_T[:-len_test] \n","    X_closeness_test=X_closeness[-len_test:] \n","    X_period_test=X_period[-len_test:] \n","    X_trend_test=X_trend[-len_test:]          \n","    T_test=matrix_T[-len_test:]         \n","    \n","    X_train=[X_closeness_train,X_period_train,X_trend_train]\n","    X_test=[X_closeness_test,X_period_test,X_trend_test]\n","    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n","    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n","    Y_train=Y[:-len_test] \n","    Y_test=Y[-len_test:] \n","\n","    len_train=X_closeness_train.shape[0]\n","    len_test=X_closeness_test.shape[0]\n","    print('len_train='+str(len_train))\n","    print('len_test ='+str(len_test ))\n","    \n","    '''\n","    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n","    for i in range(poi.shape[0]):\n","        poi[i]=poi[i]/np.max(poi[i])\n","    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n","    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n","    \n","    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n","    '''\n","    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n","  \n","\n","\n","print(\"loading data...\")\n","#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","\n","R_N = 4   # number of residual units\n","\n","#from keras.optimizers import Adam\n","from tensorflow.keras.optimizers import Adam\n","from keras.layers.convolutional import Conv2D\n","#from DST_network.STResNet import stresnet\n","#import DST_network.metrics as metrics\n","#import PPT3_network.metrics as metrics\n","\n","def build_model(external_dim,CFN):\n","  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n","  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n","  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n","\n","  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n","  \n","  adam = Adam(lr=lr)\n","  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n","  #model.summary()\n","  #from keras.utils.visualize_util import plot\n","  #plot(model, to_file='model.png', show_shapes=True)\n","  return model\n","\n","\n","CF=64\n","\n","iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n","\n","RMSE=np.zeros([iterate_num,1])\n","MAE =np.zeros([iterate_num,1])\n","count_sum=iterate_num\n","\n","import time\n","\n","count=0\n","\n","  \n","for iterate_index in range(iterate_num):\n","  count=count+1\n","  iterate=iterate_loop[iterate_index]\n","      \n","  time_start=time.time()\n","  \n","  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n","      \n","  model = build_model(external_dim=False,CFN=CF)\n","  '''\n","  model_checkpoint=ModelCheckpoint(\n","      filepath=F,\n","      monitor='val_rmse',\n","      verbose=1,\n","      save_best_only=True,\n","      save_weights_only=False,\n","      mode='min',\n","      period=1)\n","  '''    \n","  print('=' * 10)\n","  print(\"training model...\")\n","  history = model.fit(X_train, Y_train,\n","                      epochs=epoch,\n","                      batch_size=batch_size,\n","                      validation_split=0.1,\n","                      #callbacks=[model_checkpoint],\n","                      verbose=0)\n","      \n","  #print('=' * 10)\n","  #print('evaluating using the model that has the best loss on the valid set')\n","  #model.load_weights(F)\n","  \n","  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n","  print('              mse     rmse    mae')\n","  print('Train score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n","  print('Test  score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  print(np.array(score))\n","      \n","  RMSE[iterate_index,0]=score[1]\n","  MAE [iterate_index,0]=score[2]\n","      \n","  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n","\n","  np.set_printoptions(precision=4, suppress=True)\n","  print('RMSE  MAE')\n","  print(for_show)\n","      \n","  for_show=np.mean(for_show,axis=0)\n","  print('RMSE  MAE')\n","  print(for_show)\n","  \n","  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n","      \n","  time_end=time.time()\n","      \n","  print('totally cost',time_end-time_start)\n","  print(str(count)+'/'+str(count_sum))\n","\n","\n","    "],"metadata":{"id":"_lnZBDA6oyEf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657429538733,"user_tz":-540,"elapsed":175387,"user":{"displayName":"Heounmo Go","userId":"00816368495368211847"}},"outputId":"07cb5ac7-490b-4091-9003-e1dce3febf8b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["loading data...\n","all_data shape:  (800, 1, 16, 12)\n","max= 7.0  min= 0.0\n","mean= -0.9955078124999998  variance= 0.04561460128187354\n","number_of_skip_hours: 224\n","len_train=464\n","len_test =112\n","external_dim: False\n","==========\n","training model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["              mse     rmse    mae\n","Train score: Test  score: [0.000838 0.02895  0.003257]\n","RMSE  MAE\n","[[0.029  0.0033]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0029 0.0003]\n","totally cost 17.410360097885132\n","1/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000838 0.028943 0.002991]\n","RMSE  MAE\n","[[0.029  0.0033]\n"," [0.0289 0.003 ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0058 0.0006]\n","totally cost 17.561672687530518\n","2/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000839 0.028962 0.002968]\n","RMSE  MAE\n","[[0.029  0.0033]\n"," [0.0289 0.003 ]\n"," [0.029  0.003 ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0087 0.0009]\n","totally cost 17.114917039871216\n","3/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000843 0.02903  0.002583]\n","RMSE  MAE\n","[[0.029  0.0033]\n"," [0.0289 0.003 ]\n"," [0.029  0.003 ]\n"," [0.029  0.0026]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0116 0.0012]\n","totally cost 17.14259099960327\n","4/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000843 0.02903  0.002478]\n","RMSE  MAE\n","[[0.029  0.0033]\n"," [0.0289 0.003 ]\n"," [0.029  0.003 ]\n"," [0.029  0.0026]\n"," [0.029  0.0025]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0145 0.0014]\n","totally cost 17.57541561126709\n","5/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000836 0.028918 0.003851]\n","RMSE  MAE\n","[[0.029  0.0033]\n"," [0.0289 0.003 ]\n"," [0.029  0.003 ]\n"," [0.029  0.0026]\n"," [0.029  0.0025]\n"," [0.0289 0.0039]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0174 0.0018]\n","totally cost 17.43646812438965\n","6/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000837 0.028938 0.002979]\n","RMSE  MAE\n","[[0.029  0.0033]\n"," [0.0289 0.003 ]\n"," [0.029  0.003 ]\n"," [0.029  0.0026]\n"," [0.029  0.0025]\n"," [0.0289 0.0039]\n"," [0.0289 0.003 ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0203 0.0021]\n","totally cost 17.246805429458618\n","7/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000842 0.029026 0.00267 ]\n","RMSE  MAE\n","[[0.029  0.0033]\n"," [0.0289 0.003 ]\n"," [0.029  0.003 ]\n"," [0.029  0.0026]\n"," [0.029  0.0025]\n"," [0.0289 0.0039]\n"," [0.0289 0.003 ]\n"," [0.029  0.0027]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0232 0.0024]\n","totally cost 17.859377145767212\n","8/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000833 0.02887  0.003213]\n","RMSE  MAE\n","[[0.029  0.0033]\n"," [0.0289 0.003 ]\n"," [0.029  0.003 ]\n"," [0.029  0.0026]\n"," [0.029  0.0025]\n"," [0.0289 0.0039]\n"," [0.0289 0.003 ]\n"," [0.029  0.0027]\n"," [0.0289 0.0032]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0261 0.0027]\n","totally cost 17.699799299240112\n","9/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000838 0.028943 0.002897]\n","RMSE  MAE\n","[[0.029  0.0033]\n"," [0.0289 0.003 ]\n"," [0.029  0.003 ]\n"," [0.029  0.0026]\n"," [0.029  0.0025]\n"," [0.0289 0.0039]\n"," [0.0289 0.003 ]\n"," [0.029  0.0027]\n"," [0.0289 0.0032]\n"," [0.0289 0.0029]]\n","RMSE  MAE\n","[0.029 0.003]\n","totally cost 17.618592977523804\n","10/10\n"]}]},{"cell_type":"code","source":["# m2_Ev\n","\n","import numpy as np\n","\n","class MM:\n","    def __init__(self,MM_max,MM_min):\n","        self.max=MM_max\n","        self.min=MM_min\n","\n","# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n","def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n","    \n","    all_data=np.load('data3/m2_Ev.npy')\n","    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n","    len_total,feature,map_height,map_width=all_data.shape\n","    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n","    #len_total,feature,map_height,map_width=all_data.shape\n","    print('all_data shape: ',all_data.shape)\n","    #mm=MM(np.max(all_data),np.min(all_data))\n","    print('max=',np.max(all_data),' min=',np.min(all_data))\n","    \n","    #for time\n","    time=np.arange(len_total,dtype=int)\n","    #hour\n","    time_hour=time%T_period\n","    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n","    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n","    for i in range(len_total):\n","        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #day\n","    time_day=(time//T_period)%7\n","    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n","    for i in range(len_total):\n","        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #con\n","    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n","    \n","    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n","    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n","    \n","    if len_trend>0:\n","        number_of_skip_hours=T_trend*len_trend\n","    elif len_period>0:\n","        number_of_skip_hours=T_period*len_period\n","    elif len_closeness>0:\n","        number_of_skip_hours=T_closeness*len_closeness  \n","    else:\n","        print(\"wrong\")\n","    print('number_of_skip_hours:',number_of_skip_hours)\n","    \n","    Y=all_data[number_of_skip_hours:len_total]\n","\n","    if len_closeness>0:\n","        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n","        for i in range(len_closeness-1):\n","            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n","    if len_period>0:\n","        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n","        for i in range(len_period-1):\n","            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n","    if len_trend>0:\n","        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n","        for i in range(len_trend-1):\n","            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n","    \n","    matrix_T=matrix_T[number_of_skip_hours:]\n","    \n","    X_closeness_train=X_closeness[:-len_test] \n","    X_period_train=X_period[:-len_test] \n","    X_trend_train=X_trend[:-len_test]  \n","    T_train=matrix_T[:-len_test] \n","    X_closeness_test=X_closeness[-len_test:] \n","    X_period_test=X_period[-len_test:] \n","    X_trend_test=X_trend[-len_test:]          \n","    T_test=matrix_T[-len_test:]         \n","    \n","    X_train=[X_closeness_train,X_period_train,X_trend_train]\n","    X_test=[X_closeness_test,X_period_test,X_trend_test]\n","    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n","    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n","    Y_train=Y[:-len_test] \n","    Y_test=Y[-len_test:] \n","\n","    len_train=X_closeness_train.shape[0]\n","    len_test=X_closeness_test.shape[0]\n","    print('len_train='+str(len_train))\n","    print('len_test ='+str(len_test ))\n","    \n","    '''\n","    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n","    for i in range(poi.shape[0]):\n","        poi[i]=poi[i]/np.max(poi[i])\n","    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n","    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n","    \n","    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n","    '''\n","    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n","  \n","\n","\n","print(\"loading data...\")\n","#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","\n","R_N = 4   # number of residual units\n","\n","#from keras.optimizers import Adam\n","from tensorflow.keras.optimizers import Adam\n","from keras.layers.convolutional import Conv2D\n","#from DST_network.STResNet import stresnet\n","#import DST_network.metrics as metrics\n","#import PPT3_network.metrics as metrics\n","\n","def build_model(external_dim,CFN):\n","  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n","  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n","  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n","\n","  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n","  \n","  adam = Adam(lr=lr)\n","  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n","  #model.summary()\n","  #from keras.utils.visualize_util import plot\n","  #plot(model, to_file='model.png', show_shapes=True)\n","  return model\n","\n","\n","CF=64\n","\n","iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n","\n","RMSE=np.zeros([iterate_num,1])\n","MAE =np.zeros([iterate_num,1])\n","count_sum=iterate_num\n","\n","import time\n","\n","count=0\n","\n","  \n","for iterate_index in range(iterate_num):\n","  count=count+1\n","  iterate=iterate_loop[iterate_index]\n","      \n","  time_start=time.time()\n","  \n","  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n","      \n","  model = build_model(external_dim=False,CFN=CF)\n","  '''\n","  model_checkpoint=ModelCheckpoint(\n","      filepath=F,\n","      monitor='val_rmse',\n","      verbose=1,\n","      save_best_only=True,\n","      save_weights_only=False,\n","      mode='min',\n","      period=1)\n","  '''    \n","  print('=' * 10)\n","  print(\"training model...\")\n","  history = model.fit(X_train, Y_train,\n","                      epochs=epoch,\n","                      batch_size=batch_size,\n","                      validation_split=0.1,\n","                      #callbacks=[model_checkpoint],\n","                      verbose=0)\n","      \n","  #print('=' * 10)\n","  #print('evaluating using the model that has the best loss on the valid set')\n","  #model.load_weights(F)\n","  \n","  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n","  print('              mse     rmse    mae')\n","  print('Train score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n","  print('Test  score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  print(np.array(score))\n","      \n","  RMSE[iterate_index,0]=score[1]\n","  MAE [iterate_index,0]=score[2]\n","      \n","  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n","\n","  np.set_printoptions(precision=4, suppress=True)\n","  print('RMSE  MAE')\n","  print(for_show)\n","      \n","  for_show=np.mean(for_show,axis=0)\n","  print('RMSE  MAE')\n","  print(for_show)\n","  \n","  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n","      \n","  time_end=time.time()\n","      \n","  print('totally cost',time_end-time_start)\n","  print(str(count)+'/'+str(count_sum))\n","\n","\n","    "],"metadata":{"id":"6gmFQYoeoyCY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657429712766,"user_tz":-540,"elapsed":174061,"user":{"displayName":"Heounmo Go","userId":"00816368495368211847"}},"outputId":"072a7704-9582-43ad-81ac-d847ea6199e3"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["loading data...\n","all_data shape:  (800, 1, 16, 12)\n","max= 2.0  min= 0.0\n","mean= -0.9995963541666667  variance= 0.020408423180341476\n","number_of_skip_hours: 224\n","len_train=464\n","len_test =112\n","external_dim: False\n","==========\n","training model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["              mse     rmse    mae\n","Train score: Test  score: [0.000233 0.015249 0.000265]\n","RMSE  MAE\n","[[0.0152 0.0003]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0015 0.    ]\n","totally cost 17.277265310287476\n","1/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000233 0.015249 0.000312]\n","RMSE  MAE\n","[[0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.003  0.0001]\n","totally cost 17.21434235572815\n","2/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000232 0.015248 0.000264]\n","RMSE  MAE\n","[[0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0046 0.0001]\n","totally cost 17.715749740600586\n","3/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000233 0.015249 0.000311]\n","RMSE  MAE\n","[[0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0061 0.0001]\n","totally cost 17.22455859184265\n","4/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000233 0.01525  0.000291]\n","RMSE  MAE\n","[[0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0076 0.0001]\n","totally cost 17.14474868774414\n","5/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000233 0.015249 0.000292]\n","RMSE  MAE\n","[[0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0091 0.0002]\n","totally cost 17.667385578155518\n","6/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000233 0.015249 0.000273]\n","RMSE  MAE\n","[[0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0107 0.0002]\n","totally cost 17.20336079597473\n","7/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000233 0.015249 0.000253]\n","RMSE  MAE\n","[[0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0122 0.0002]\n","totally cost 17.57772445678711\n","8/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000233 0.015249 0.000312]\n","RMSE  MAE\n","[[0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0137 0.0003]\n","totally cost 17.238352060317993\n","9/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000233 0.015249 0.000247]\n","RMSE  MAE\n","[[0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0003]\n"," [0.0152 0.0002]]\n","RMSE  MAE\n","[0.0152 0.0003]\n","totally cost 17.131205558776855\n","10/10\n"]}]},{"cell_type":"code","source":["# m3_Food\n","\n","import numpy as np\n","\n","class MM:\n","    def __init__(self,MM_max,MM_min):\n","        self.max=MM_max\n","        self.min=MM_min\n","\n","# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n","def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n","    \n","    all_data=np.load('data3/m3_Food.npy')\n","    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n","    len_total,feature,map_height,map_width=all_data.shape\n","    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n","    #len_total,feature,map_height,map_width=all_data.shape\n","    print('all_data shape: ',all_data.shape)\n","    #mm=MM(np.max(all_data),np.min(all_data))\n","    print('max=',np.max(all_data),' min=',np.min(all_data))\n","    \n","    #for time\n","    time=np.arange(len_total,dtype=int)\n","    #hour\n","    time_hour=time%T_period\n","    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n","    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n","    for i in range(len_total):\n","        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #day\n","    time_day=(time//T_period)%7\n","    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n","    for i in range(len_total):\n","        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #con\n","    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n","    \n","    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n","    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n","    \n","    if len_trend>0:\n","        number_of_skip_hours=T_trend*len_trend\n","    elif len_period>0:\n","        number_of_skip_hours=T_period*len_period\n","    elif len_closeness>0:\n","        number_of_skip_hours=T_closeness*len_closeness  \n","    else:\n","        print(\"wrong\")\n","    print('number_of_skip_hours:',number_of_skip_hours)\n","    \n","    Y=all_data[number_of_skip_hours:len_total]\n","\n","    if len_closeness>0:\n","        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n","        for i in range(len_closeness-1):\n","            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n","    if len_period>0:\n","        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n","        for i in range(len_period-1):\n","            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n","    if len_trend>0:\n","        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n","        for i in range(len_trend-1):\n","            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n","    \n","    matrix_T=matrix_T[number_of_skip_hours:]\n","    \n","    X_closeness_train=X_closeness[:-len_test] \n","    X_period_train=X_period[:-len_test] \n","    X_trend_train=X_trend[:-len_test]  \n","    T_train=matrix_T[:-len_test] \n","    X_closeness_test=X_closeness[-len_test:] \n","    X_period_test=X_period[-len_test:] \n","    X_trend_test=X_trend[-len_test:]          \n","    T_test=matrix_T[-len_test:]         \n","    \n","    X_train=[X_closeness_train,X_period_train,X_trend_train]\n","    X_test=[X_closeness_test,X_period_test,X_trend_test]\n","    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n","    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n","    Y_train=Y[:-len_test] \n","    Y_test=Y[-len_test:] \n","\n","    len_train=X_closeness_train.shape[0]\n","    len_test=X_closeness_test.shape[0]\n","    print('len_train='+str(len_train))\n","    print('len_test ='+str(len_test ))\n","    \n","    '''\n","    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n","    for i in range(poi.shape[0]):\n","        poi[i]=poi[i]/np.max(poi[i])\n","    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n","    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n","    \n","    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n","    '''\n","    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n","  \n","\n","\n","print(\"loading data...\")\n","#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","\n","R_N = 4   # number of residual units\n","\n","#from keras.optimizers import Adam\n","from tensorflow.keras.optimizers import Adam\n","from keras.layers.convolutional import Conv2D\n","#from DST_network.STResNet import stresnet\n","#import DST_network.metrics as metrics\n","#import PPT3_network.metrics as metrics\n","\n","def build_model(external_dim,CFN):\n","  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n","  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n","  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n","\n","  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n","  \n","  adam = Adam(lr=lr)\n","  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n","  #model.summary()\n","  #from keras.utils.visualize_util import plot\n","  #plot(model, to_file='model.png', show_shapes=True)\n","  return model\n","\n","\n","CF=64\n","\n","iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n","\n","RMSE=np.zeros([iterate_num,1])\n","MAE =np.zeros([iterate_num,1])\n","count_sum=iterate_num\n","\n","import time\n","\n","count=0\n","\n","  \n","for iterate_index in range(iterate_num):\n","  count=count+1\n","  iterate=iterate_loop[iterate_index]\n","      \n","  time_start=time.time()\n","  \n","  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n","      \n","  model = build_model(external_dim=False,CFN=CF)\n","  '''\n","  model_checkpoint=ModelCheckpoint(\n","      filepath=F,\n","      monitor='val_rmse',\n","      verbose=1,\n","      save_best_only=True,\n","      save_weights_only=False,\n","      mode='min',\n","      period=1)\n","  '''    \n","  print('=' * 10)\n","  print(\"training model...\")\n","  history = model.fit(X_train, Y_train,\n","                      epochs=epoch,\n","                      batch_size=batch_size,\n","                      validation_split=0.1,\n","                      #callbacks=[model_checkpoint],\n","                      verbose=0)\n","      \n","  #print('=' * 10)\n","  #print('evaluating using the model that has the best loss on the valid set')\n","  #model.load_weights(F)\n","  \n","  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n","  print('              mse     rmse    mae')\n","  print('Train score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n","  print('Test  score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  print(np.array(score))\n","      \n","  RMSE[iterate_index,0]=score[1]\n","  MAE [iterate_index,0]=score[2]\n","      \n","  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n","\n","  np.set_printoptions(precision=4, suppress=True)\n","  print('RMSE  MAE')\n","  print(for_show)\n","      \n","  for_show=np.mean(for_show,axis=0)\n","  print('RMSE  MAE')\n","  print(for_show)\n","  \n","  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n","      \n","  time_end=time.time()\n","      \n","  print('totally cost',time_end-time_start)\n","  print(str(count)+'/'+str(count_sum))\n","\n","\n","    "],"metadata":{"id":"3kSWHETFoyAF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657429888243,"user_tz":-540,"elapsed":175500,"user":{"displayName":"Heounmo Go","userId":"00816368495368211847"}},"outputId":"9446f003-ee98-4c21-8012-ece25d1c98ab"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["loading data...\n","all_data shape:  (800, 1, 16, 12)\n","max= 98.0  min= 0.0\n","mean= -0.9913027476615647  variance= 0.054585593962263146\n","number_of_skip_hours: 224\n","len_train=464\n","len_test =112\n","external_dim: False\n","==========\n","training model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["              mse     rmse    mae\n","Train score: Test  score: [0.000897 0.029957 0.005505]\n","RMSE  MAE\n","[[0.03   0.0055]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.003  0.0006]\n","totally cost 17.761358976364136\n","1/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000914 0.030226 0.005088]\n","RMSE  MAE\n","[[0.03   0.0055]\n"," [0.0302 0.0051]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.006  0.0011]\n","totally cost 17.246950149536133\n","2/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000894 0.029902 0.005587]\n","RMSE  MAE\n","[[0.03   0.0055]\n"," [0.0302 0.0051]\n"," [0.0299 0.0056]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.009  0.0016]\n","totally cost 17.675230503082275\n","3/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000914 0.030232 0.005188]\n","RMSE  MAE\n","[[0.03   0.0055]\n"," [0.0302 0.0051]\n"," [0.0299 0.0056]\n"," [0.0302 0.0052]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.012  0.0021]\n","totally cost 17.539185762405396\n","4/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000893 0.029879 0.00604 ]\n","RMSE  MAE\n","[[0.03   0.0055]\n"," [0.0302 0.0051]\n"," [0.0299 0.0056]\n"," [0.0302 0.0052]\n"," [0.0299 0.006 ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.015  0.0027]\n","totally cost 17.368852138519287\n","5/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000897 0.02995  0.005712]\n","RMSE  MAE\n","[[0.03   0.0055]\n"," [0.0302 0.0051]\n"," [0.0299 0.0056]\n"," [0.0302 0.0052]\n"," [0.0299 0.006 ]\n"," [0.0299 0.0057]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.018  0.0033]\n","totally cost 17.802355527877808\n","6/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000918 0.030292 0.005015]\n","RMSE  MAE\n","[[0.03   0.0055]\n"," [0.0302 0.0051]\n"," [0.0299 0.0056]\n"," [0.0302 0.0052]\n"," [0.0299 0.006 ]\n"," [0.0299 0.0057]\n"," [0.0303 0.005 ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.021  0.0038]\n","totally cost 17.296244382858276\n","7/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000914 0.030237 0.005239]\n","RMSE  MAE\n","[[0.03   0.0055]\n"," [0.0302 0.0051]\n"," [0.0299 0.0056]\n"," [0.0302 0.0052]\n"," [0.0299 0.006 ]\n"," [0.0299 0.0057]\n"," [0.0303 0.005 ]\n"," [0.0302 0.0052]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0241 0.0043]\n","totally cost 17.053728342056274\n","8/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000918 0.0303   0.004925]\n","RMSE  MAE\n","[[0.03   0.0055]\n"," [0.0302 0.0051]\n"," [0.0299 0.0056]\n"," [0.0302 0.0052]\n"," [0.0299 0.006 ]\n"," [0.0299 0.0057]\n"," [0.0303 0.005 ]\n"," [0.0302 0.0052]\n"," [0.0303 0.0049]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0271 0.0048]\n","totally cost 17.803939819335938\n","9/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000893 0.029879 0.005912]\n","RMSE  MAE\n","[[0.03   0.0055]\n"," [0.0302 0.0051]\n"," [0.0299 0.0056]\n"," [0.0302 0.0052]\n"," [0.0299 0.006 ]\n"," [0.0299 0.0057]\n"," [0.0303 0.005 ]\n"," [0.0302 0.0052]\n"," [0.0303 0.0049]\n"," [0.0299 0.0059]]\n","RMSE  MAE\n","[0.0301 0.0054]\n","totally cost 17.368128061294556\n","10/10\n"]}]},{"cell_type":"code","source":["# m4_Night\n","\n","import numpy as np\n","\n","class MM:\n","    def __init__(self,MM_max,MM_min):\n","        self.max=MM_max\n","        self.min=MM_min\n","\n","# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n","def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n","    \n","    all_data=np.load('data3/m4_Night.npy')\n","    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n","    len_total,feature,map_height,map_width=all_data.shape\n","    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n","    #len_total,feature,map_height,map_width=all_data.shape\n","    print('all_data shape: ',all_data.shape)\n","    #mm=MM(np.max(all_data),np.min(all_data))\n","    print('max=',np.max(all_data),' min=',np.min(all_data))\n","    \n","    #for time\n","    time=np.arange(len_total,dtype=int)\n","    #hour\n","    time_hour=time%T_period\n","    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n","    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n","    for i in range(len_total):\n","        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #day\n","    time_day=(time//T_period)%7\n","    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n","    for i in range(len_total):\n","        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #con\n","    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n","    \n","    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n","    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n","    \n","    if len_trend>0:\n","        number_of_skip_hours=T_trend*len_trend\n","    elif len_period>0:\n","        number_of_skip_hours=T_period*len_period\n","    elif len_closeness>0:\n","        number_of_skip_hours=T_closeness*len_closeness  \n","    else:\n","        print(\"wrong\")\n","    print('number_of_skip_hours:',number_of_skip_hours)\n","    \n","    Y=all_data[number_of_skip_hours:len_total]\n","\n","    if len_closeness>0:\n","        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n","        for i in range(len_closeness-1):\n","            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n","    if len_period>0:\n","        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n","        for i in range(len_period-1):\n","            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n","    if len_trend>0:\n","        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n","        for i in range(len_trend-1):\n","            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n","    \n","    matrix_T=matrix_T[number_of_skip_hours:]\n","    \n","    X_closeness_train=X_closeness[:-len_test] \n","    X_period_train=X_period[:-len_test] \n","    X_trend_train=X_trend[:-len_test]  \n","    T_train=matrix_T[:-len_test] \n","    X_closeness_test=X_closeness[-len_test:] \n","    X_period_test=X_period[-len_test:] \n","    X_trend_test=X_trend[-len_test:]          \n","    T_test=matrix_T[-len_test:]         \n","    \n","    X_train=[X_closeness_train,X_period_train,X_trend_train]\n","    X_test=[X_closeness_test,X_period_test,X_trend_test]\n","    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n","    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n","    Y_train=Y[:-len_test] \n","    Y_test=Y[-len_test:] \n","\n","    len_train=X_closeness_train.shape[0]\n","    len_test=X_closeness_test.shape[0]\n","    print('len_train='+str(len_train))\n","    print('len_test ='+str(len_test ))\n","    \n","    '''\n","    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n","    for i in range(poi.shape[0]):\n","        poi[i]=poi[i]/np.max(poi[i])\n","    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n","    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n","    \n","    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n","    '''\n","    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n","  \n","\n","\n","print(\"loading data...\")\n","#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","\n","R_N = 4   # number of residual units\n","\n","#from keras.optimizers import Adam\n","from tensorflow.keras.optimizers import Adam\n","from keras.layers.convolutional import Conv2D\n","#from DST_network.STResNet import stresnet\n","#import DST_network.metrics as metrics\n","#import PPT3_network.metrics as metrics\n","\n","def build_model(external_dim,CFN):\n","  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n","  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n","  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n","\n","  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n","  \n","  adam = Adam(lr=lr)\n","  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n","  #model.summary()\n","  #from keras.utils.visualize_util import plot\n","  #plot(model, to_file='model.png', show_shapes=True)\n","  return model\n","\n","\n","CF=64\n","\n","iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n","\n","RMSE=np.zeros([iterate_num,1])\n","MAE =np.zeros([iterate_num,1])\n","count_sum=iterate_num\n","\n","import time\n","\n","count=0\n","\n","  \n","for iterate_index in range(iterate_num):\n","  count=count+1\n","  iterate=iterate_loop[iterate_index]\n","      \n","  time_start=time.time()\n","  \n","  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n","      \n","  model = build_model(external_dim=False,CFN=CF)\n","  '''\n","  model_checkpoint=ModelCheckpoint(\n","      filepath=F,\n","      monitor='val_rmse',\n","      verbose=1,\n","      save_best_only=True,\n","      save_weights_only=False,\n","      mode='min',\n","      period=1)\n","  '''    \n","  print('=' * 10)\n","  print(\"training model...\")\n","  history = model.fit(X_train, Y_train,\n","                      epochs=epoch,\n","                      batch_size=batch_size,\n","                      validation_split=0.1,\n","                      #callbacks=[model_checkpoint],\n","                      verbose=0)\n","      \n","  #print('=' * 10)\n","  #print('evaluating using the model that has the best loss on the valid set')\n","  #model.load_weights(F)\n","  \n","  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n","  print('              mse     rmse    mae')\n","  print('Train score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n","  print('Test  score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  print(np.array(score))\n","      \n","  RMSE[iterate_index,0]=score[1]\n","  MAE [iterate_index,0]=score[2]\n","      \n","  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n","\n","  np.set_printoptions(precision=4, suppress=True)\n","  print('RMSE  MAE')\n","  print(for_show)\n","      \n","  for_show=np.mean(for_show,axis=0)\n","  print('RMSE  MAE')\n","  print(for_show)\n","  \n","  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n","      \n","  time_end=time.time()\n","      \n","  print('totally cost',time_end-time_start)\n","  print(str(count)+'/'+str(count_sum))\n","\n","\n","    "],"metadata":{"id":"se0ZqU5rox9-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657430063520,"user_tz":-540,"elapsed":175302,"user":{"displayName":"Heounmo Go","userId":"00816368495368211847"}},"outputId":"4ab7d6c2-b524-4793-e215-0af9e5f6aca6"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["loading data...\n","all_data shape:  (800, 1, 16, 12)\n","max= 13.0  min= 0.0\n","mean= -0.9996183894230768  variance= 0.010054515338544382\n","number_of_skip_hours: 224\n","len_train=464\n","len_test =112\n","external_dim: False\n","==========\n","training model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["              mse     rmse    mae\n","Train score: Test  score: [0.00004  0.006295 0.000308]\n","RMSE  MAE\n","[[0.0063 0.0003]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0006 0.    ]\n","totally cost 17.084946870803833\n","1/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.00004  0.006296 0.000257]\n","RMSE  MAE\n","[[0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0013 0.0001]\n","totally cost 17.61987042427063\n","2/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.00004  0.006295 0.000256]\n","RMSE  MAE\n","[[0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0019 0.0001]\n","totally cost 17.54533576965332\n","3/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.00004  0.006295 0.000274]\n","RMSE  MAE\n","[[0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0025 0.0001]\n","totally cost 17.768001794815063\n","4/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.00004  0.006295 0.000245]\n","RMSE  MAE\n","[[0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0002]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0031 0.0001]\n","totally cost 17.34204387664795\n","5/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.00004  0.006293 0.00028 ]\n","RMSE  MAE\n","[[0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0002]\n"," [0.0063 0.0003]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0038 0.0002]\n","totally cost 17.23624014854431\n","6/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.00004  0.006297 0.000255]\n","RMSE  MAE\n","[[0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0002]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0044 0.0002]\n","totally cost 17.904037952423096\n","7/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.00004  0.006295 0.00025 ]\n","RMSE  MAE\n","[[0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0002]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.005  0.0002]\n","totally cost 17.26449155807495\n","8/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.00004  0.006294 0.00028 ]\n","RMSE  MAE\n","[[0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0002]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0057 0.0002]\n","totally cost 17.27370810508728\n","9/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.00004  0.006296 0.000267]\n","RMSE  MAE\n","[[0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0002]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]\n"," [0.0063 0.0003]]\n","RMSE  MAE\n","[0.0063 0.0003]\n","totally cost 17.609663486480713\n","10/10\n"]}]},{"cell_type":"code","source":["# m5_Outdoor\n","\n","import numpy as np\n","\n","class MM:\n","    def __init__(self,MM_max,MM_min):\n","        self.max=MM_max\n","        self.min=MM_min\n","\n","# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n","def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n","    \n","    all_data=np.load('data3/m5_Outdoor.npy')\n","    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n","    len_total,feature,map_height,map_width=all_data.shape\n","    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n","    #len_total,feature,map_height,map_width=all_data.shape\n","    print('all_data shape: ',all_data.shape)\n","    #mm=MM(np.max(all_data),np.min(all_data))\n","    print('max=',np.max(all_data),' min=',np.min(all_data))\n","    \n","    #for time\n","    time=np.arange(len_total,dtype=int)\n","    #hour\n","    time_hour=time%T_period\n","    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n","    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n","    for i in range(len_total):\n","        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #day\n","    time_day=(time//T_period)%7\n","    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n","    for i in range(len_total):\n","        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #con\n","    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n","    \n","    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n","    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n","    \n","    if len_trend>0:\n","        number_of_skip_hours=T_trend*len_trend\n","    elif len_period>0:\n","        number_of_skip_hours=T_period*len_period\n","    elif len_closeness>0:\n","        number_of_skip_hours=T_closeness*len_closeness  \n","    else:\n","        print(\"wrong\")\n","    print('number_of_skip_hours:',number_of_skip_hours)\n","    \n","    Y=all_data[number_of_skip_hours:len_total]\n","\n","    if len_closeness>0:\n","        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n","        for i in range(len_closeness-1):\n","            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n","    if len_period>0:\n","        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n","        for i in range(len_period-1):\n","            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n","    if len_trend>0:\n","        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n","        for i in range(len_trend-1):\n","            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n","    \n","    matrix_T=matrix_T[number_of_skip_hours:]\n","    \n","    X_closeness_train=X_closeness[:-len_test] \n","    X_period_train=X_period[:-len_test] \n","    X_trend_train=X_trend[:-len_test]  \n","    T_train=matrix_T[:-len_test] \n","    X_closeness_test=X_closeness[-len_test:] \n","    X_period_test=X_period[-len_test:] \n","    X_trend_test=X_trend[-len_test:]          \n","    T_test=matrix_T[-len_test:]         \n","    \n","    X_train=[X_closeness_train,X_period_train,X_trend_train]\n","    X_test=[X_closeness_test,X_period_test,X_trend_test]\n","    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n","    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n","    Y_train=Y[:-len_test] \n","    Y_test=Y[-len_test:] \n","\n","    len_train=X_closeness_train.shape[0]\n","    len_test=X_closeness_test.shape[0]\n","    print('len_train='+str(len_train))\n","    print('len_test ='+str(len_test ))\n","    \n","    '''\n","    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n","    for i in range(poi.shape[0]):\n","        poi[i]=poi[i]/np.max(poi[i])\n","    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n","    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n","    \n","    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n","    '''\n","    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n","  \n","\n","\n","print(\"loading data...\")\n","#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","\n","R_N = 4   # number of residual units\n","\n","#from keras.optimizers import Adam\n","from tensorflow.keras.optimizers import Adam\n","from keras.layers.convolutional import Conv2D\n","#from DST_network.STResNet import stresnet\n","#import DST_network.metrics as metrics\n","#import PPT3_network.metrics as metrics\n","\n","def build_model(external_dim,CFN):\n","  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n","  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n","  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n","\n","  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n","  \n","  adam = Adam(lr=lr)\n","  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n","  #model.summary()\n","  #from keras.utils.visualize_util import plot\n","  #plot(model, to_file='model.png', show_shapes=True)\n","  return model\n","\n","\n","CF=64\n","\n","iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n","\n","RMSE=np.zeros([iterate_num,1])\n","MAE =np.zeros([iterate_num,1])\n","count_sum=iterate_num\n","\n","import time\n","\n","count=0\n","\n","  \n","for iterate_index in range(iterate_num):\n","  count=count+1\n","  iterate=iterate_loop[iterate_index]\n","      \n","  time_start=time.time()\n","  \n","  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n","      \n","  model = build_model(external_dim=False,CFN=CF)\n","  '''\n","  model_checkpoint=ModelCheckpoint(\n","      filepath=F,\n","      monitor='val_rmse',\n","      verbose=1,\n","      save_best_only=True,\n","      save_weights_only=False,\n","      mode='min',\n","      period=1)\n","  '''    \n","  print('=' * 10)\n","  print(\"training model...\")\n","  history = model.fit(X_train, Y_train,\n","                      epochs=epoch,\n","                      batch_size=batch_size,\n","                      validation_split=0.1,\n","                      #callbacks=[model_checkpoint],\n","                      verbose=0)\n","      \n","  #print('=' * 10)\n","  #print('evaluating using the model that has the best loss on the valid set')\n","  #model.load_weights(F)\n","  \n","  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n","  print('              mse     rmse    mae')\n","  print('Train score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n","  print('Test  score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  print(np.array(score))\n","      \n","  RMSE[iterate_index,0]=score[1]\n","  MAE [iterate_index,0]=score[2]\n","      \n","  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n","\n","  np.set_printoptions(precision=4, suppress=True)\n","  print('RMSE  MAE')\n","  print(for_show)\n","      \n","  for_show=np.mean(for_show,axis=0)\n","  print('RMSE  MAE')\n","  print(for_show)\n","  \n","  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n","      \n","  time_end=time.time()\n","      \n","  print('totally cost',time_end-time_start)\n","  print(str(count)+'/'+str(count_sum))\n","\n","\n","    "],"metadata":{"id":"WYxOJ4yGox7x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657430237659,"user_tz":-540,"elapsed":174167,"user":{"displayName":"Heounmo Go","userId":"00816368495368211847"}},"outputId":"eb4428d4-3133-44a6-ee15-224fd09c9384"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["loading data...\n","all_data shape:  (800, 1, 16, 12)\n","max= 48.0  min= 0.0\n","mean= -0.9933797200520835  variance= 0.03452679972215169\n","number_of_skip_hours: 224\n","len_train=464\n","len_test =112\n","external_dim: False\n","==========\n","training model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["              mse     rmse    mae\n","Train score: Test  score: [0.000314 0.017723 0.004444]\n","RMSE  MAE\n","[[0.0177 0.0044]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0018 0.0004]\n","totally cost 17.249155282974243\n","1/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000318 0.017834 0.003839]\n","RMSE  MAE\n","[[0.0177 0.0044]\n"," [0.0178 0.0038]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0036 0.0008]\n","totally cost 17.504307746887207\n","2/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000318 0.017837 0.003927]\n","RMSE  MAE\n","[[0.0177 0.0044]\n"," [0.0178 0.0038]\n"," [0.0178 0.0039]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0053 0.0012]\n","totally cost 17.334347009658813\n","3/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000321 0.017907 0.003226]\n","RMSE  MAE\n","[[0.0177 0.0044]\n"," [0.0178 0.0038]\n"," [0.0178 0.0039]\n"," [0.0179 0.0032]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0071 0.0015]\n","totally cost 17.476276874542236\n","4/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000319 0.017857 0.003781]\n","RMSE  MAE\n","[[0.0177 0.0044]\n"," [0.0178 0.0038]\n"," [0.0178 0.0039]\n"," [0.0179 0.0032]\n"," [0.0179 0.0038]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0089 0.0019]\n","totally cost 17.638538360595703\n","5/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000319 0.017849 0.003627]\n","RMSE  MAE\n","[[0.0177 0.0044]\n"," [0.0178 0.0038]\n"," [0.0178 0.0039]\n"," [0.0179 0.0032]\n"," [0.0179 0.0038]\n"," [0.0178 0.0036]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0107 0.0023]\n","totally cost 17.125800848007202\n","6/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000319 0.017855 0.003582]\n","RMSE  MAE\n","[[0.0177 0.0044]\n"," [0.0178 0.0038]\n"," [0.0178 0.0039]\n"," [0.0179 0.0032]\n"," [0.0179 0.0038]\n"," [0.0178 0.0036]\n"," [0.0179 0.0036]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0125 0.0026]\n","totally cost 17.262470960617065\n","7/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000319 0.017848 0.003984]\n","RMSE  MAE\n","[[0.0177 0.0044]\n"," [0.0178 0.0038]\n"," [0.0178 0.0039]\n"," [0.0179 0.0032]\n"," [0.0179 0.0038]\n"," [0.0178 0.0036]\n"," [0.0179 0.0036]\n"," [0.0178 0.004 ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0143 0.003 ]\n","totally cost 17.697648763656616\n","8/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000311 0.017628 0.00425 ]\n","RMSE  MAE\n","[[0.0177 0.0044]\n"," [0.0178 0.0038]\n"," [0.0178 0.0039]\n"," [0.0179 0.0032]\n"," [0.0179 0.0038]\n"," [0.0178 0.0036]\n"," [0.0179 0.0036]\n"," [0.0178 0.004 ]\n"," [0.0176 0.0042]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.016  0.0035]\n","totally cost 17.133615732192993\n","9/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000321 0.017907 0.003283]\n","RMSE  MAE\n","[[0.0177 0.0044]\n"," [0.0178 0.0038]\n"," [0.0178 0.0039]\n"," [0.0179 0.0032]\n"," [0.0179 0.0038]\n"," [0.0178 0.0036]\n"," [0.0179 0.0036]\n"," [0.0178 0.004 ]\n"," [0.0176 0.0042]\n"," [0.0179 0.0033]]\n","RMSE  MAE\n","[0.0178 0.0038]\n","totally cost 17.044071435928345\n","10/10\n"]}]},{"cell_type":"code","source":["# m6_Pro\n","\n","import numpy as np\n","\n","class MM:\n","    def __init__(self,MM_max,MM_min):\n","        self.max=MM_max\n","        self.min=MM_min\n","\n","# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n","def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n","    \n","    all_data=np.load('data3/m6_Pro.npy')\n","    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n","    len_total,feature,map_height,map_width=all_data.shape\n","    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n","    #len_total,feature,map_height,map_width=all_data.shape\n","    print('all_data shape: ',all_data.shape)\n","    #mm=MM(np.max(all_data),np.min(all_data))\n","    print('max=',np.max(all_data),' min=',np.min(all_data))\n","    \n","    #for time\n","    time=np.arange(len_total,dtype=int)\n","    #hour\n","    time_hour=time%T_period\n","    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n","    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n","    for i in range(len_total):\n","        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #day\n","    time_day=(time//T_period)%7\n","    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n","    for i in range(len_total):\n","        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #con\n","    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n","    \n","    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n","    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n","    \n","    if len_trend>0:\n","        number_of_skip_hours=T_trend*len_trend\n","    elif len_period>0:\n","        number_of_skip_hours=T_period*len_period\n","    elif len_closeness>0:\n","        number_of_skip_hours=T_closeness*len_closeness  \n","    else:\n","        print(\"wrong\")\n","    print('number_of_skip_hours:',number_of_skip_hours)\n","    \n","    Y=all_data[number_of_skip_hours:len_total]\n","\n","    if len_closeness>0:\n","        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n","        for i in range(len_closeness-1):\n","            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n","    if len_period>0:\n","        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n","        for i in range(len_period-1):\n","            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n","    if len_trend>0:\n","        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n","        for i in range(len_trend-1):\n","            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n","    \n","    matrix_T=matrix_T[number_of_skip_hours:]\n","    \n","    X_closeness_train=X_closeness[:-len_test] \n","    X_period_train=X_period[:-len_test] \n","    X_trend_train=X_trend[:-len_test]  \n","    T_train=matrix_T[:-len_test] \n","    X_closeness_test=X_closeness[-len_test:] \n","    X_period_test=X_period[-len_test:] \n","    X_trend_test=X_trend[-len_test:]          \n","    T_test=matrix_T[-len_test:]         \n","    \n","    X_train=[X_closeness_train,X_period_train,X_trend_train]\n","    X_test=[X_closeness_test,X_period_test,X_trend_test]\n","    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n","    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n","    Y_train=Y[:-len_test] \n","    Y_test=Y[-len_test:] \n","\n","    len_train=X_closeness_train.shape[0]\n","    len_test=X_closeness_test.shape[0]\n","    print('len_train='+str(len_train))\n","    print('len_test ='+str(len_test ))\n","    \n","    '''\n","    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n","    for i in range(poi.shape[0]):\n","        poi[i]=poi[i]/np.max(poi[i])\n","    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n","    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n","    \n","    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n","    '''\n","    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n","  \n","\n","\n","print(\"loading data...\")\n","#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","\n","R_N = 4   # number of residual units\n","\n","#from keras.optimizers import Adam\n","from tensorflow.keras.optimizers import Adam\n","from keras.layers.convolutional import Conv2D\n","#from DST_network.STResNet import stresnet\n","#import DST_network.metrics as metrics\n","#import PPT3_network.metrics as metrics\n","\n","def build_model(external_dim,CFN):\n","  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n","  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n","  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n","\n","  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n","  \n","  adam = Adam(lr=lr)\n","  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n","  #model.summary()\n","  #from keras.utils.visualize_util import plot\n","  #plot(model, to_file='model.png', show_shapes=True)\n","  return model\n","\n","\n","CF=64\n","\n","iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n","\n","RMSE=np.zeros([iterate_num,1])\n","MAE =np.zeros([iterate_num,1])\n","count_sum=iterate_num\n","\n","import time\n","\n","count=0\n","\n","  \n","for iterate_index in range(iterate_num):\n","  count=count+1\n","  iterate=iterate_loop[iterate_index]\n","      \n","  time_start=time.time()\n","  \n","  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n","      \n","  model = build_model(external_dim=False,CFN=CF)\n","  '''\n","  model_checkpoint=ModelCheckpoint(\n","      filepath=F,\n","      monitor='val_rmse',\n","      verbose=1,\n","      save_best_only=True,\n","      save_weights_only=False,\n","      mode='min',\n","      period=1)\n","  '''    \n","  print('=' * 10)\n","  print(\"training model...\")\n","  history = model.fit(X_train, Y_train,\n","                      epochs=epoch,\n","                      batch_size=batch_size,\n","                      validation_split=0.1,\n","                      #callbacks=[model_checkpoint],\n","                      verbose=0)\n","      \n","  #print('=' * 10)\n","  #print('evaluating using the model that has the best loss on the valid set')\n","  #model.load_weights(F)\n","  \n","  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n","  print('              mse     rmse    mae')\n","  print('Train score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n","  print('Test  score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  print(np.array(score))\n","      \n","  RMSE[iterate_index,0]=score[1]\n","  MAE [iterate_index,0]=score[2]\n","      \n","  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n","\n","  np.set_printoptions(precision=4, suppress=True)\n","  print('RMSE  MAE')\n","  print(for_show)\n","      \n","  for_show=np.mean(for_show,axis=0)\n","  print('RMSE  MAE')\n","  print(for_show)\n","  \n","  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n","      \n","  time_end=time.time()\n","      \n","  print('totally cost',time_end-time_start)\n","  print(str(count)+'/'+str(count_sum))\n","\n","\n","    "],"metadata":{"id":"ju7JGMXjoxz9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657430412405,"user_tz":-540,"elapsed":174770,"user":{"displayName":"Heounmo Go","userId":"00816368495368211847"}},"outputId":"0e56f06f-ccfd-4299-fe4a-503770a3ab57"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["loading data...\n","all_data shape:  (800, 1, 16, 12)\n","max= 68.0  min= 0.0\n","mean= -0.9916000306372551  variance= 0.04181876512912886\n","number_of_skip_hours: 224\n","len_train=464\n","len_test =112\n","external_dim: False\n","==========\n","training model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["              mse     rmse    mae\n","Train score: Test  score: [0.00052  0.022793 0.00583 ]\n","RMSE  MAE\n","[[0.0228 0.0058]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0023 0.0006]\n","totally cost 17.830864429473877\n","1/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000516 0.022716 0.005808]\n","RMSE  MAE\n","[[0.0228 0.0058]\n"," [0.0227 0.0058]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0046 0.0012]\n","totally cost 17.26081395149231\n","2/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000526 0.022939 0.005148]\n","RMSE  MAE\n","[[0.0228 0.0058]\n"," [0.0227 0.0058]\n"," [0.0229 0.0051]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0068 0.0017]\n","totally cost 17.51769995689392\n","3/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000528 0.022986 0.004933]\n","RMSE  MAE\n","[[0.0228 0.0058]\n"," [0.0227 0.0058]\n"," [0.0229 0.0051]\n"," [0.023  0.0049]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0091 0.0022]\n","totally cost 17.409459590911865\n","4/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000527 0.022954 0.005288]\n","RMSE  MAE\n","[[0.0228 0.0058]\n"," [0.0227 0.0058]\n"," [0.0229 0.0051]\n"," [0.023  0.0049]\n"," [0.023  0.0053]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0114 0.0027]\n","totally cost 17.29262137413025\n","5/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000521 0.022821 0.005365]\n","RMSE  MAE\n","[[0.0228 0.0058]\n"," [0.0227 0.0058]\n"," [0.0229 0.0051]\n"," [0.023  0.0049]\n"," [0.023  0.0053]\n"," [0.0228 0.0054]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0137 0.0032]\n","totally cost 17.66056203842163\n","6/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000523 0.022876 0.005723]\n","RMSE  MAE\n","[[0.0228 0.0058]\n"," [0.0227 0.0058]\n"," [0.0229 0.0051]\n"," [0.023  0.0049]\n"," [0.023  0.0053]\n"," [0.0228 0.0054]\n"," [0.0229 0.0057]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.016  0.0038]\n","totally cost 17.287866592407227\n","7/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000527 0.022964 0.005082]\n","RMSE  MAE\n","[[0.0228 0.0058]\n"," [0.0227 0.0058]\n"," [0.0229 0.0051]\n"," [0.023  0.0049]\n"," [0.023  0.0053]\n"," [0.0228 0.0054]\n"," [0.0229 0.0057]\n"," [0.023  0.0051]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0183 0.0043]\n","totally cost 17.087649822235107\n","8/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000527 0.02296  0.005365]\n","RMSE  MAE\n","[[0.0228 0.0058]\n"," [0.0227 0.0058]\n"," [0.0229 0.0051]\n"," [0.023  0.0049]\n"," [0.023  0.0053]\n"," [0.0228 0.0054]\n"," [0.0229 0.0057]\n"," [0.023  0.0051]\n"," [0.023  0.0054]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0206 0.0049]\n","totally cost 17.629271984100342\n","9/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000527 0.022967 0.005074]\n","RMSE  MAE\n","[[0.0228 0.0058]\n"," [0.0227 0.0058]\n"," [0.0229 0.0051]\n"," [0.023  0.0049]\n"," [0.023  0.0053]\n"," [0.0228 0.0054]\n"," [0.0229 0.0057]\n"," [0.023  0.0051]\n"," [0.023  0.0054]\n"," [0.023  0.0051]]\n","RMSE  MAE\n","[0.0229 0.0054]\n","totally cost 17.170403003692627\n","10/10\n"]}]},{"cell_type":"code","source":["# m7_Res\n","\n","import numpy as np\n","\n","class MM:\n","    def __init__(self,MM_max,MM_min):\n","        self.max=MM_max\n","        self.min=MM_min\n","\n","# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n","def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n","    \n","    all_data=np.load('data3/m7_Res.npy')\n","    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n","    len_total,feature,map_height,map_width=all_data.shape\n","    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n","    #len_total,feature,map_height,map_width=all_data.shape\n","    print('all_data shape: ',all_data.shape)\n","    #mm=MM(np.max(all_data),np.min(all_data))\n","    print('max=',np.max(all_data),' min=',np.min(all_data))\n","    \n","    #for time\n","    time=np.arange(len_total,dtype=int)\n","    #hour\n","    time_hour=time%T_period\n","    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n","    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n","    for i in range(len_total):\n","        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #day\n","    time_day=(time//T_period)%7\n","    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n","    for i in range(len_total):\n","        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #con\n","    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n","    \n","    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n","    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n","    \n","    if len_trend>0:\n","        number_of_skip_hours=T_trend*len_trend\n","    elif len_period>0:\n","        number_of_skip_hours=T_period*len_period\n","    elif len_closeness>0:\n","        number_of_skip_hours=T_closeness*len_closeness  \n","    else:\n","        print(\"wrong\")\n","    print('number_of_skip_hours:',number_of_skip_hours)\n","    \n","    Y=all_data[number_of_skip_hours:len_total]\n","\n","    if len_closeness>0:\n","        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n","        for i in range(len_closeness-1):\n","            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n","    if len_period>0:\n","        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n","        for i in range(len_period-1):\n","            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n","    if len_trend>0:\n","        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n","        for i in range(len_trend-1):\n","            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n","    \n","    matrix_T=matrix_T[number_of_skip_hours:]\n","    \n","    X_closeness_train=X_closeness[:-len_test] \n","    X_period_train=X_period[:-len_test] \n","    X_trend_train=X_trend[:-len_test]  \n","    T_train=matrix_T[:-len_test] \n","    X_closeness_test=X_closeness[-len_test:] \n","    X_period_test=X_period[-len_test:] \n","    X_trend_test=X_trend[-len_test:]          \n","    T_test=matrix_T[-len_test:]         \n","    \n","    X_train=[X_closeness_train,X_period_train,X_trend_train]\n","    X_test=[X_closeness_test,X_period_test,X_trend_test]\n","    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n","    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n","    Y_train=Y[:-len_test] \n","    Y_test=Y[-len_test:] \n","\n","    len_train=X_closeness_train.shape[0]\n","    len_test=X_closeness_test.shape[0]\n","    print('len_train='+str(len_train))\n","    print('len_test ='+str(len_test ))\n","    \n","    '''\n","    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n","    for i in range(poi.shape[0]):\n","        poi[i]=poi[i]/np.max(poi[i])\n","    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n","    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n","    \n","    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n","    '''\n","    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n","  \n","\n","\n","print(\"loading data...\")\n","#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","\n","R_N = 4   # number of residual units\n","\n","#from keras.optimizers import Adam\n","from tensorflow.keras.optimizers import Adam\n","from keras.layers.convolutional import Conv2D\n","#from DST_network.STResNet import stresnet\n","#import DST_network.metrics as metrics\n","#import PPT3_network.metrics as metrics\n","\n","def build_model(external_dim,CFN):\n","  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n","  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n","  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n","\n","  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n","  \n","  adam = Adam(lr=lr)\n","  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n","  #model.summary()\n","  #from keras.utils.visualize_util import plot\n","  #plot(model, to_file='model.png', show_shapes=True)\n","  return model\n","\n","\n","CF=64\n","\n","iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n","\n","RMSE=np.zeros([iterate_num,1])\n","MAE =np.zeros([iterate_num,1])\n","count_sum=iterate_num\n","\n","import time\n","\n","count=0\n","\n","  \n","for iterate_index in range(iterate_num):\n","  count=count+1\n","  iterate=iterate_loop[iterate_index]\n","      \n","  time_start=time.time()\n","  \n","  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n","      \n","  model = build_model(external_dim=False,CFN=CF)\n","  '''\n","  model_checkpoint=ModelCheckpoint(\n","      filepath=F,\n","      monitor='val_rmse',\n","      verbose=1,\n","      save_best_only=True,\n","      save_weights_only=False,\n","      mode='min',\n","      period=1)\n","  '''    \n","  print('=' * 10)\n","  print(\"training model...\")\n","  history = model.fit(X_train, Y_train,\n","                      epochs=epoch,\n","                      batch_size=batch_size,\n","                      validation_split=0.1,\n","                      #callbacks=[model_checkpoint],\n","                      verbose=0)\n","      \n","  #print('=' * 10)\n","  #print('evaluating using the model that has the best loss on the valid set')\n","  #model.load_weights(F)\n","  \n","  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n","  print('              mse     rmse    mae')\n","  print('Train score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n","  print('Test  score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  print(np.array(score))\n","      \n","  RMSE[iterate_index,0]=score[1]\n","  MAE [iterate_index,0]=score[2]\n","      \n","  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n","\n","  np.set_printoptions(precision=4, suppress=True)\n","  print('RMSE  MAE')\n","  print(for_show)\n","      \n","  for_show=np.mean(for_show,axis=0)\n","  print('RMSE  MAE')\n","  print(for_show)\n","  \n","  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n","      \n","  time_end=time.time()\n","      \n","  print('totally cost',time_end-time_start)\n","  print(str(count)+'/'+str(count_sum))\n","\n","\n","    "],"metadata":{"id":"s_q3_XRjrHUd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657430587691,"user_tz":-540,"elapsed":175312,"user":{"displayName":"Heounmo Go","userId":"00816368495368211847"}},"outputId":"b66de70b-ec17-43fd-d49c-bd20da880632"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["loading data...\n","all_data shape:  (800, 1, 16, 12)\n","max= 4.0  min= 0.0\n","mean= -0.997197265625  variance= 0.03973737211395832\n","number_of_skip_hours: 224\n","len_train=464\n","len_test =112\n","external_dim: False\n","==========\n","training model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["              mse     rmse    mae\n","Train score: Test  score: [0.000639 0.025283 0.001476]\n","RMSE  MAE\n","[[0.0253 0.0015]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0025 0.0001]\n","totally cost 17.678790807724\n","1/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000638 0.025254 0.001881]\n","RMSE  MAE\n","[[0.0253 0.0015]\n"," [0.0253 0.0019]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0051 0.0003]\n","totally cost 17.31190514564514\n","2/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000639 0.025287 0.001347]\n","RMSE  MAE\n","[[0.0253 0.0015]\n"," [0.0253 0.0019]\n"," [0.0253 0.0013]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0076 0.0005]\n","totally cost 17.236235857009888\n","3/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000639 0.02527  0.001548]\n","RMSE  MAE\n","[[0.0253 0.0015]\n"," [0.0253 0.0019]\n"," [0.0253 0.0013]\n"," [0.0253 0.0015]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0101 0.0006]\n","totally cost 17.613038778305054\n","4/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.00064  0.025291 0.001534]\n","RMSE  MAE\n","[[0.0253 0.0015]\n"," [0.0253 0.0019]\n"," [0.0253 0.0013]\n"," [0.0253 0.0015]\n"," [0.0253 0.0015]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0126 0.0008]\n","totally cost 17.393606424331665\n","5/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000638 0.025262 0.001761]\n","RMSE  MAE\n","[[0.0253 0.0015]\n"," [0.0253 0.0019]\n"," [0.0253 0.0013]\n"," [0.0253 0.0015]\n"," [0.0253 0.0015]\n"," [0.0253 0.0018]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0152 0.001 ]\n","totally cost 17.546151638031006\n","6/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.00064  0.025291 0.001499]\n","RMSE  MAE\n","[[0.0253 0.0015]\n"," [0.0253 0.0019]\n"," [0.0253 0.0013]\n"," [0.0253 0.0015]\n"," [0.0253 0.0015]\n"," [0.0253 0.0018]\n"," [0.0253 0.0015]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0177 0.0011]\n","totally cost 17.838836908340454\n","7/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000639 0.02528  0.001719]\n","RMSE  MAE\n","[[0.0253 0.0015]\n"," [0.0253 0.0019]\n"," [0.0253 0.0013]\n"," [0.0253 0.0015]\n"," [0.0253 0.0015]\n"," [0.0253 0.0018]\n"," [0.0253 0.0015]\n"," [0.0253 0.0017]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0202 0.0013]\n","totally cost 17.269078969955444\n","8/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000639 0.02527  0.001803]\n","RMSE  MAE\n","[[0.0253 0.0015]\n"," [0.0253 0.0019]\n"," [0.0253 0.0013]\n"," [0.0253 0.0015]\n"," [0.0253 0.0015]\n"," [0.0253 0.0018]\n"," [0.0253 0.0015]\n"," [0.0253 0.0017]\n"," [0.0253 0.0018]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0227 0.0015]\n","totally cost 17.558305263519287\n","9/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000639 0.025279 0.001507]\n","RMSE  MAE\n","[[0.0253 0.0015]\n"," [0.0253 0.0019]\n"," [0.0253 0.0013]\n"," [0.0253 0.0015]\n"," [0.0253 0.0015]\n"," [0.0253 0.0018]\n"," [0.0253 0.0015]\n"," [0.0253 0.0017]\n"," [0.0253 0.0018]\n"," [0.0253 0.0015]]\n","RMSE  MAE\n","[0.0253 0.0016]\n","totally cost 17.195451021194458\n","10/10\n"]}]},{"cell_type":"code","source":["# m8_Shop\n","\n","import numpy as np\n","\n","class MM:\n","    def __init__(self,MM_max,MM_min):\n","        self.max=MM_max\n","        self.min=MM_min\n","\n","# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n","def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n","    \n","    all_data=np.load('data3/m8_Shop.npy')\n","    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n","    len_total,feature,map_height,map_width=all_data.shape\n","    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n","    #len_total,feature,map_height,map_width=all_data.shape\n","    print('all_data shape: ',all_data.shape)\n","    #mm=MM(np.max(all_data),np.min(all_data))\n","    print('max=',np.max(all_data),' min=',np.min(all_data))\n","    \n","    #for time\n","    time=np.arange(len_total,dtype=int)\n","    #hour\n","    time_hour=time%T_period\n","    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n","    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n","    for i in range(len_total):\n","        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #day\n","    time_day=(time//T_period)%7\n","    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n","    for i in range(len_total):\n","        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #con\n","    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n","    \n","    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n","    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n","    \n","    if len_trend>0:\n","        number_of_skip_hours=T_trend*len_trend\n","    elif len_period>0:\n","        number_of_skip_hours=T_period*len_period\n","    elif len_closeness>0:\n","        number_of_skip_hours=T_closeness*len_closeness  \n","    else:\n","        print(\"wrong\")\n","    print('number_of_skip_hours:',number_of_skip_hours)\n","    \n","    Y=all_data[number_of_skip_hours:len_total]\n","\n","    if len_closeness>0:\n","        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n","        for i in range(len_closeness-1):\n","            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n","    if len_period>0:\n","        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n","        for i in range(len_period-1):\n","            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n","    if len_trend>0:\n","        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n","        for i in range(len_trend-1):\n","            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n","    \n","    matrix_T=matrix_T[number_of_skip_hours:]\n","    \n","    X_closeness_train=X_closeness[:-len_test] \n","    X_period_train=X_period[:-len_test] \n","    X_trend_train=X_trend[:-len_test]  \n","    T_train=matrix_T[:-len_test] \n","    X_closeness_test=X_closeness[-len_test:] \n","    X_period_test=X_period[-len_test:] \n","    X_trend_test=X_trend[-len_test:]          \n","    T_test=matrix_T[-len_test:]         \n","    \n","    X_train=[X_closeness_train,X_period_train,X_trend_train]\n","    X_test=[X_closeness_test,X_period_test,X_trend_test]\n","    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n","    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n","    Y_train=Y[:-len_test] \n","    Y_test=Y[-len_test:] \n","\n","    len_train=X_closeness_train.shape[0]\n","    len_test=X_closeness_test.shape[0]\n","    print('len_train='+str(len_train))\n","    print('len_test ='+str(len_test ))\n","    \n","    '''\n","    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n","    for i in range(poi.shape[0]):\n","        poi[i]=poi[i]/np.max(poi[i])\n","    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n","    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n","    \n","    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n","    '''\n","    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n","  \n","\n","\n","print(\"loading data...\")\n","#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","\n","R_N = 4   # number of residual units\n","\n","#from keras.optimizers import Adam\n","from tensorflow.keras.optimizers import Adam\n","from keras.layers.convolutional import Conv2D\n","#from DST_network.STResNet import stresnet\n","#import DST_network.metrics as metrics\n","#import PPT3_network.metrics as metrics\n","\n","def build_model(external_dim,CFN):\n","  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n","  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n","  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n","\n","  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n","  \n","  adam = Adam(lr=lr)\n","  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n","  #model.summary()\n","  #from keras.utils.visualize_util import plot\n","  #plot(model, to_file='model.png', show_shapes=True)\n","  return model\n","\n","\n","CF=64\n","\n","iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n","\n","RMSE=np.zeros([iterate_num,1])\n","MAE =np.zeros([iterate_num,1])\n","count_sum=iterate_num\n","\n","import time\n","\n","count=0\n","\n","  \n","for iterate_index in range(iterate_num):\n","  count=count+1\n","  iterate=iterate_loop[iterate_index]\n","      \n","  time_start=time.time()\n","  \n","  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n","      \n","  model = build_model(external_dim=False,CFN=CF)\n","  '''\n","  model_checkpoint=ModelCheckpoint(\n","      filepath=F,\n","      monitor='val_rmse',\n","      verbose=1,\n","      save_best_only=True,\n","      save_weights_only=False,\n","      mode='min',\n","      period=1)\n","  '''    \n","  print('=' * 10)\n","  print(\"training model...\")\n","  history = model.fit(X_train, Y_train,\n","                      epochs=epoch,\n","                      batch_size=batch_size,\n","                      validation_split=0.1,\n","                      #callbacks=[model_checkpoint],\n","                      verbose=0)\n","      \n","  #print('=' * 10)\n","  #print('evaluating using the model that has the best loss on the valid set')\n","  #model.load_weights(F)\n","  \n","  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n","  print('              mse     rmse    mae')\n","  print('Train score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n","  print('Test  score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  print(np.array(score))\n","      \n","  RMSE[iterate_index,0]=score[1]\n","  MAE [iterate_index,0]=score[2]\n","      \n","  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n","\n","  np.set_printoptions(precision=4, suppress=True)\n","  print('RMSE  MAE')\n","  print(for_show)\n","      \n","  for_show=np.mean(for_show,axis=0)\n","  print('RMSE  MAE')\n","  print(for_show)\n","  \n","  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n","      \n","  time_end=time.time()\n","      \n","  print('totally cost',time_end-time_start)\n","  print(str(count)+'/'+str(count_sum))\n","\n","\n","    "],"metadata":{"id":"9z1jH3y2rHSK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657430763341,"user_tz":-540,"elapsed":175675,"user":{"displayName":"Heounmo Go","userId":"00816368495368211847"}},"outputId":"4bbd3208-cc19-49e3-ca92-de6a9a8a34b5"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["loading data...\n","all_data shape:  (800, 1, 16, 12)\n","max= 60.0  min= 0.0\n","mean= -0.9908684895833333  variance= 0.04447277708632065\n","number_of_skip_hours: 224\n","len_train=464\n","len_test =112\n","external_dim: False\n","==========\n","training model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["              mse     rmse    mae\n","Train score: Test  score: [0.000719 0.026823 0.0055  ]\n","RMSE  MAE\n","[[0.0268 0.0055]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0027 0.0005]\n","totally cost 17.343958854675293\n","1/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.00072  0.026827 0.00549 ]\n","RMSE  MAE\n","[[0.0268 0.0055]\n"," [0.0268 0.0055]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0054 0.0011]\n","totally cost 17.567633152008057\n","2/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000713 0.026702 0.006301]\n","RMSE  MAE\n","[[0.0268 0.0055]\n"," [0.0268 0.0055]\n"," [0.0267 0.0063]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.008  0.0017]\n","totally cost 17.29020881652832\n","3/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000717 0.026776 0.005841]\n","RMSE  MAE\n","[[0.0268 0.0055]\n"," [0.0268 0.0055]\n"," [0.0267 0.0063]\n"," [0.0268 0.0058]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0107 0.0023]\n","totally cost 17.19579315185547\n","4/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.00072  0.026827 0.005499]\n","RMSE  MAE\n","[[0.0268 0.0055]\n"," [0.0268 0.0055]\n"," [0.0267 0.0063]\n"," [0.0268 0.0058]\n"," [0.0268 0.0055]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0134 0.0029]\n","totally cost 17.624756813049316\n","5/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.00072  0.026827 0.005536]\n","RMSE  MAE\n","[[0.0268 0.0055]\n"," [0.0268 0.0055]\n"," [0.0267 0.0063]\n"," [0.0268 0.0058]\n"," [0.0268 0.0055]\n"," [0.0268 0.0055]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0161 0.0034]\n","totally cost 17.28978991508484\n","6/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000719 0.026821 0.005708]\n","RMSE  MAE\n","[[0.0268 0.0055]\n"," [0.0268 0.0055]\n"," [0.0267 0.0063]\n"," [0.0268 0.0058]\n"," [0.0268 0.0055]\n"," [0.0268 0.0055]\n"," [0.0268 0.0057]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0188 0.004 ]\n","totally cost 17.686311960220337\n","7/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000703 0.026512 0.006661]\n","RMSE  MAE\n","[[0.0268 0.0055]\n"," [0.0268 0.0055]\n"," [0.0267 0.0063]\n"," [0.0268 0.0058]\n"," [0.0268 0.0055]\n"," [0.0268 0.0055]\n"," [0.0268 0.0057]\n"," [0.0265 0.0067]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0214 0.0047]\n","totally cost 17.2857403755188\n","8/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000701 0.026477 0.006028]\n","RMSE  MAE\n","[[0.0268 0.0055]\n"," [0.0268 0.0055]\n"," [0.0267 0.0063]\n"," [0.0268 0.0058]\n"," [0.0268 0.0055]\n"," [0.0268 0.0055]\n"," [0.0268 0.0057]\n"," [0.0265 0.0067]\n"," [0.0265 0.006 ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0241 0.0053]\n","totally cost 17.484241008758545\n","9/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000719 0.026816 0.00583 ]\n","RMSE  MAE\n","[[0.0268 0.0055]\n"," [0.0268 0.0055]\n"," [0.0267 0.0063]\n"," [0.0268 0.0058]\n"," [0.0268 0.0055]\n"," [0.0268 0.0055]\n"," [0.0268 0.0057]\n"," [0.0265 0.0067]\n"," [0.0265 0.006 ]\n"," [0.0268 0.0058]]\n","RMSE  MAE\n","[0.0267 0.0058]\n","totally cost 18.086674213409424\n","10/10\n"]}]},{"cell_type":"code","source":["# m9_Tra\n","\n","import numpy as np\n","\n","class MM:\n","    def __init__(self,MM_max,MM_min):\n","        self.max=MM_max\n","        self.min=MM_min\n","\n","# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n","def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n","    \n","    all_data=np.load('data3/m9_Tra.npy')\n","    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n","    len_total,feature,map_height,map_width=all_data.shape\n","    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n","    #len_total,feature,map_height,map_width=all_data.shape\n","    print('all_data shape: ',all_data.shape)\n","    #mm=MM(np.max(all_data),np.min(all_data))\n","    print('max=',np.max(all_data),' min=',np.min(all_data))\n","    \n","    #for time\n","    time=np.arange(len_total,dtype=int)\n","    #hour\n","    time_hour=time%T_period\n","    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n","    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n","    for i in range(len_total):\n","        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #day\n","    time_day=(time//T_period)%7\n","    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n","    for i in range(len_total):\n","        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n","    #con\n","    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n","    \n","    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n","    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n","    \n","    if len_trend>0:\n","        number_of_skip_hours=T_trend*len_trend\n","    elif len_period>0:\n","        number_of_skip_hours=T_period*len_period\n","    elif len_closeness>0:\n","        number_of_skip_hours=T_closeness*len_closeness  \n","    else:\n","        print(\"wrong\")\n","    print('number_of_skip_hours:',number_of_skip_hours)\n","    \n","    Y=all_data[number_of_skip_hours:len_total]\n","\n","    if len_closeness>0:\n","        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n","        for i in range(len_closeness-1):\n","            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n","    if len_period>0:\n","        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n","        for i in range(len_period-1):\n","            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n","    if len_trend>0:\n","        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n","        for i in range(len_trend-1):\n","            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n","    \n","    matrix_T=matrix_T[number_of_skip_hours:]\n","    \n","    X_closeness_train=X_closeness[:-len_test] \n","    X_period_train=X_period[:-len_test] \n","    X_trend_train=X_trend[:-len_test]  \n","    T_train=matrix_T[:-len_test] \n","    X_closeness_test=X_closeness[-len_test:] \n","    X_period_test=X_period[-len_test:] \n","    X_trend_test=X_trend[-len_test:]          \n","    T_test=matrix_T[-len_test:]         \n","    \n","    X_train=[X_closeness_train,X_period_train,X_trend_train]\n","    X_test=[X_closeness_test,X_period_test,X_trend_test]\n","    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n","    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n","    Y_train=Y[:-len_test] \n","    Y_test=Y[-len_test:] \n","\n","    len_train=X_closeness_train.shape[0]\n","    len_test=X_closeness_test.shape[0]\n","    print('len_train='+str(len_train))\n","    print('len_test ='+str(len_test ))\n","    \n","    '''\n","    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n","    for i in range(poi.shape[0]):\n","        poi[i]=poi[i]/np.max(poi[i])\n","    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n","    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n","    \n","    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n","    '''\n","    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n","  \n","\n","\n","print(\"loading data...\")\n","#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n","\n","R_N = 4   # number of residual units\n","\n","#from keras.optimizers import Adam\n","from tensorflow.keras.optimizers import Adam\n","from keras.layers.convolutional import Conv2D\n","#from DST_network.STResNet import stresnet\n","#import DST_network.metrics as metrics\n","#import PPT3_network.metrics as metrics\n","\n","def build_model(external_dim,CFN):\n","  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n","  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n","  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n","\n","  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n","  \n","  adam = Adam(lr=lr)\n","  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n","  #model.summary()\n","  #from keras.utils.visualize_util import plot\n","  #plot(model, to_file='model.png', show_shapes=True)\n","  return model\n","\n","\n","CF=64\n","\n","iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n","\n","RMSE=np.zeros([iterate_num,1])\n","MAE =np.zeros([iterate_num,1])\n","count_sum=iterate_num\n","\n","import time\n","\n","count=0\n","\n","  \n","for iterate_index in range(iterate_num):\n","  count=count+1\n","  iterate=iterate_loop[iterate_index]\n","      \n","  time_start=time.time()\n","  \n","  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n","      \n","  model = build_model(external_dim=False,CFN=CF)\n","  '''\n","  model_checkpoint=ModelCheckpoint(\n","      filepath=F,\n","      monitor='val_rmse',\n","      verbose=1,\n","      save_best_only=True,\n","      save_weights_only=False,\n","      mode='min',\n","      period=1)\n","  '''    \n","  print('=' * 10)\n","  print(\"training model...\")\n","  history = model.fit(X_train, Y_train,\n","                      epochs=epoch,\n","                      batch_size=batch_size,\n","                      validation_split=0.1,\n","                      #callbacks=[model_checkpoint],\n","                      verbose=0)\n","      \n","  #print('=' * 10)\n","  #print('evaluating using the model that has the best loss on the valid set')\n","  #model.load_weights(F)\n","  \n","  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n","  print('              mse     rmse    mae')\n","  print('Train score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n","  print('Test  score:',end=' ')\n","  np.set_printoptions(precision=6, suppress=True)\n","  print(np.array(score))\n","      \n","  RMSE[iterate_index,0]=score[1]\n","  MAE [iterate_index,0]=score[2]\n","      \n","  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n","\n","  np.set_printoptions(precision=4, suppress=True)\n","  print('RMSE  MAE')\n","  print(for_show)\n","      \n","  for_show=np.mean(for_show,axis=0)\n","  print('RMSE  MAE')\n","  print(for_show)\n","  \n","  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n","      \n","  time_end=time.time()\n","      \n","  print('totally cost',time_end-time_start)\n","  print(str(count)+'/'+str(count_sum))\n","\n","\n","    "],"metadata":{"id":"h0aYDQWkrHQB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657430938168,"user_tz":-540,"elapsed":174850,"user":{"displayName":"Heounmo Go","userId":"00816368495368211847"}},"outputId":"56190b5c-2bd0-4fcc-8c8e-60fcd66cbbab"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["loading data...\n","all_data shape:  (800, 1, 16, 12)\n","max= 37.0  min= 0.0\n","mean= -0.9933016610360359  variance= 0.037008620307463456\n","number_of_skip_hours: 224\n","len_train=464\n","len_test =112\n","external_dim: False\n","==========\n","training model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["              mse     rmse    mae\n","Train score: Test  score: [0.000438 0.020924 0.003773]\n","RMSE  MAE\n","[[0.0209 0.0038]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0021 0.0004]\n","totally cost 17.2713143825531\n","1/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000437 0.020897 0.003799]\n","RMSE  MAE\n","[[0.0209 0.0038]\n"," [0.0209 0.0038]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0042 0.0008]\n","totally cost 17.24692463874817\n","2/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000436 0.020878 0.004444]\n","RMSE  MAE\n","[[0.0209 0.0038]\n"," [0.0209 0.0038]\n"," [0.0209 0.0044]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0063 0.0012]\n","totally cost 17.641173362731934\n","3/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000432 0.020782 0.004784]\n","RMSE  MAE\n","[[0.0209 0.0038]\n"," [0.0209 0.0038]\n"," [0.0209 0.0044]\n"," [0.0208 0.0048]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0083 0.0017]\n","totally cost 17.42056131362915\n","4/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000428 0.020682 0.00494 ]\n","RMSE  MAE\n","[[0.0209 0.0038]\n"," [0.0209 0.0038]\n"," [0.0209 0.0044]\n"," [0.0208 0.0048]\n"," [0.0207 0.0049]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0104 0.0022]\n","totally cost 17.74889636039734\n","5/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000432 0.020791 0.004519]\n","RMSE  MAE\n","[[0.0209 0.0038]\n"," [0.0209 0.0038]\n"," [0.0209 0.0044]\n"," [0.0208 0.0048]\n"," [0.0207 0.0049]\n"," [0.0208 0.0045]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0125 0.0026]\n","totally cost 17.283055067062378\n","6/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000438 0.020923 0.003662]\n","RMSE  MAE\n","[[0.0209 0.0038]\n"," [0.0209 0.0038]\n"," [0.0209 0.0044]\n"," [0.0208 0.0048]\n"," [0.0207 0.0049]\n"," [0.0208 0.0045]\n"," [0.0209 0.0037]\n"," [0.     0.    ]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0146 0.003 ]\n","totally cost 17.17911410331726\n","7/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000438 0.020928 0.003674]\n","RMSE  MAE\n","[[0.0209 0.0038]\n"," [0.0209 0.0038]\n"," [0.0209 0.0044]\n"," [0.0208 0.0048]\n"," [0.0207 0.0049]\n"," [0.0208 0.0045]\n"," [0.0209 0.0037]\n"," [0.0209 0.0037]\n"," [0.     0.    ]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0167 0.0034]\n","totally cost 17.625275135040283\n","8/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000438 0.020923 0.003787]\n","RMSE  MAE\n","[[0.0209 0.0038]\n"," [0.0209 0.0038]\n"," [0.0209 0.0044]\n"," [0.0208 0.0048]\n"," [0.0207 0.0049]\n"," [0.0208 0.0045]\n"," [0.0209 0.0037]\n"," [0.0209 0.0037]\n"," [0.0209 0.0038]\n"," [0.     0.    ]]\n","RMSE  MAE\n","[0.0188 0.0037]\n","totally cost 17.328253984451294\n","9/10\n","external_dim: False\n","==========\n","training model...\n","              mse     rmse    mae\n","Train score: Test  score: [0.000437 0.020894 0.004003]\n","RMSE  MAE\n","[[0.0209 0.0038]\n"," [0.0209 0.0038]\n"," [0.0209 0.0044]\n"," [0.0208 0.0048]\n"," [0.0207 0.0049]\n"," [0.0208 0.0045]\n"," [0.0209 0.0037]\n"," [0.0209 0.0037]\n"," [0.0209 0.0038]\n"," [0.0209 0.004 ]]\n","RMSE  MAE\n","[0.0209 0.0041]\n","totally cost 17.305407762527466\n","10/10\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"qX4eKng8rHN-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"IsE1gk5srHLq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"n3bVi1CJrHJi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"TE3MVH7QrHHS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"8d3Mj3pkrHE_"},"execution_count":null,"outputs":[]}]}