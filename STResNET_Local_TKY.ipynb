{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KV_EdNWClAq9",
        "outputId": "8f26a2b3-6822-4872-8bc8-0ac53a8c77ae"
      },
      "source": [
        "# google drive connect\n",
        "Copied_path = '/content/drive/MyDrive/Colab Notebooks/MyPaper/GlocalSTN' # Paste target directory here\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(Copied_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AauHopRUnGYv"
      },
      "source": [
        "# m0_Ent\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class MM:\n",
        "    def __init__(self,MM_max,MM_min):\n",
        "        self.max=MM_max\n",
        "        self.min=MM_min\n",
        "\n",
        "# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n",
        "def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n",
        "\n",
        "    all_data=np.load('data2/m0_Ent.npy')\n",
        "    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n",
        "    len_total,feature,map_height,map_width=all_data.shape\n",
        "    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n",
        "    #len_total,feature,map_height,map_width=all_data.shape\n",
        "    print('all_data shape: ',all_data.shape)\n",
        "    #mm=MM(np.max(all_data),np.min(all_data))\n",
        "    print('max=',np.max(all_data),' min=',np.min(all_data))\n",
        "\n",
        "    #for time\n",
        "    time=np.arange(len_total,dtype=int)\n",
        "    #hour\n",
        "    time_hour=time%T_period\n",
        "    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n",
        "    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n",
        "    for i in range(len_total):\n",
        "        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #day\n",
        "    time_day=(time//T_period)%7\n",
        "    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n",
        "    for i in range(len_total):\n",
        "        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #con\n",
        "    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n",
        "\n",
        "    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n",
        "    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n",
        "\n",
        "    if len_trend>0:\n",
        "        number_of_skip_hours=T_trend*len_trend\n",
        "    elif len_period>0:\n",
        "        number_of_skip_hours=T_period*len_period\n",
        "    elif len_closeness>0:\n",
        "        number_of_skip_hours=T_closeness*len_closeness\n",
        "    else:\n",
        "        print(\"wrong\")\n",
        "    print('number_of_skip_hours:',number_of_skip_hours)\n",
        "\n",
        "    Y=all_data[number_of_skip_hours:len_total]\n",
        "\n",
        "    if len_closeness>0:\n",
        "        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n",
        "        for i in range(len_closeness-1):\n",
        "            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n",
        "    if len_period>0:\n",
        "        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n",
        "        for i in range(len_period-1):\n",
        "            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n",
        "    if len_trend>0:\n",
        "        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n",
        "        for i in range(len_trend-1):\n",
        "            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n",
        "\n",
        "    matrix_T=matrix_T[number_of_skip_hours:]\n",
        "\n",
        "    X_closeness_train=X_closeness[:-len_test]\n",
        "    X_period_train=X_period[:-len_test]\n",
        "    X_trend_train=X_trend[:-len_test]\n",
        "    T_train=matrix_T[:-len_test]\n",
        "    X_closeness_test=X_closeness[-len_test:]\n",
        "    X_period_test=X_period[-len_test:]\n",
        "    X_trend_test=X_trend[-len_test:]\n",
        "    T_test=matrix_T[-len_test:]\n",
        "\n",
        "    X_train=[X_closeness_train,X_period_train,X_trend_train]\n",
        "    X_test=[X_closeness_test,X_period_test,X_trend_test]\n",
        "    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n",
        "    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n",
        "    Y_train=Y[:-len_test]\n",
        "    Y_test=Y[-len_test:]\n",
        "\n",
        "    len_train=X_closeness_train.shape[0]\n",
        "    len_test=X_closeness_test.shape[0]\n",
        "    print('len_train='+str(len_train))\n",
        "    print('len_test ='+str(len_test ))\n",
        "\n",
        "    '''\n",
        "    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n",
        "    for i in range(poi.shape[0]):\n",
        "        poi[i]=poi[i]/np.max(poi[i])\n",
        "    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n",
        "    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n",
        "\n",
        "    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n",
        "    '''\n",
        "    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# DST Network/ilayer.py 이건 ST resnet 쪽에 있던 ilayer,똑같은 거 같음\n",
        "\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "# from keras.layers import Dense\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class iLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        # self.output_dim = output_dim\n",
        "        super(iLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        initial_weight_value = np.random.random(input_shape[1:])\n",
        "        self.W = K.variable(initial_weight_value)\n",
        "        self.trainable_weights = [self.W]\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        return x * self.W\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return input_shape\n",
        "'''\n"
      ],
      "metadata": {
        "id": "cTwpbtYcnVFs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "00453ca0-df92-4607-e801-8a3f07f46edf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# DST Network/ilayer.py 이건 ST resnet 쪽에 있던 ilayer,똑같은 거 같음\\n\\n\\nfrom keras import backend as K\\nfrom keras.engine.topology import Layer\\n# from keras.layers import Dense\\nimport numpy as np\\n\\n\\nclass iLayer(Layer):\\n    def __init__(self, **kwargs):\\n        # self.output_dim = output_dim\\n        super(iLayer, self).__init__(**kwargs)\\n\\n    def build(self, input_shape):\\n        initial_weight_value = np.random.random(input_shape[1:])\\n        self.W = K.variable(initial_weight_value)\\n        self.trainable_weights = [self.W]\\n\\n    def call(self, x, mask=None):\\n        return x * self.W\\n\\n    def get_output_shape_for(self, input_shape):\\n        return input_shape\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgFX7E7fo_a8"
      },
      "source": [
        "# DST Network/ilayer.py\n",
        "\n",
        "from keras import backend as K\n",
        "#from keras.engine.topology import Layer\n",
        "#from tensorflow.keras.layers import Layer\n",
        "from keras.layers import Layer\n",
        "# from keras.layers import Dense\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class iLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        # self.output_dim = output_dim\n",
        "        super(iLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        initial_weight_value = np.random.random(input_shape[1:])\n",
        "        self.W = K.variable(initial_weight_value)\n",
        "        #self.trainable_weights = [self.W]\n",
        "        self.trainable_weight = [self.W]\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        return x * self.W\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return input_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k925xkl8Uynj"
      },
      "source": [
        "# \"metrics.py\"\n",
        "\n",
        "# import numpy as np\n",
        "from keras import backend as K\n",
        "\n",
        "def mean_squared_error(y_true, y_pred):\n",
        "    return K.mean(K.square(y_pred - y_true))\n",
        "\n",
        "\n",
        "def root_mean_square_error(y_true, y_pred):\n",
        "    return mean_squared_error(y_true, y_pred) ** 0.5\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return mean_squared_error(y_true, y_pred) ** 0.5\n",
        "\n",
        "\n",
        "# aliases\n",
        "mse = MSE = mean_squared_error\n",
        "# rmse = RMSE = root_mean_square_error\n",
        "\n",
        "\n",
        "def masked_mean_squared_error(y_true, y_pred):\n",
        "    idx = (y_true > 1e-6).nonzero()\n",
        "    return K.mean(K.square(y_pred[idx] - y_true[idx]))\n",
        "\n",
        "def masked_rmse(y_true, y_pred):\n",
        "    return masked_mean_squared_error(y_true, y_pred) ** 0.5\n",
        "\n",
        "\n",
        "def mean_absolute_error(y_true, y_pred):\n",
        "    return K.mean(K.abs(y_pred - y_true))\n",
        "\n",
        "def mae(y_true, y_pred):\n",
        "    return K.mean(K.abs(y_pred - y_true))\n",
        "\n",
        "\n",
        "threshold=0.05\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    return K.mean( K.abs(y_pred-y_true) / K.maximum(K.cast(threshold,'float32'),y_true+1.0) )\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    return K.mean( K.abs(y_pred-y_true) / K.maximum(K.cast(threshold,'float32'),y_true+1.0) )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    ST-ResNet: Deep Spatio-temporal Residual Networks\n",
        "'''\n",
        "#!pip install keras-layer-normalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from __future__ import print_function\n",
        "from keras.layers import (\n",
        "    Input,\n",
        "    Activation,\n",
        "    merge,\n",
        "    Dense,\n",
        "    Reshape\n",
        ")\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Input,Activation,Dropout,BatchNormalization,AveragePooling2D,ZeroPadding2D,Multiply, Add\n",
        "#from keras.layers import concatenate\n",
        "#from tensorflow.keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "#from keras.utils.visualize_util import plot\n",
        "\n",
        "\n",
        "def _shortcut(input, residual):\n",
        "    #return merge([input, residual], mode='sum')\n",
        "    return Add()([input,residual])\n",
        "\n",
        "\n",
        "\n",
        "def _bn_relu_conv(nb_filter, nb_row, nb_col, subsample=(1, 1), bn=False):\n",
        "    def f(input):\n",
        "        if bn:\n",
        "            input = BatchNormalization(mode=0, axis=1)(input)\n",
        "        activation = Activation('relu')(input)\n",
        "        #return Convolution2D(nb_filter=nb_filter, nb_row=nb_row, nb_col=nb_col, subsample=subsample, border_mode=\"same\")(activation)\n",
        "        return Conv2D(filters=nb_filter, kernel_size=(nb_row, nb_col), strides=(1,1), padding=\"same\")(activation)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _residual_unit(nb_filter, init_subsample=(1, 1)):\n",
        "    def f(input):\n",
        "        residual = _bn_relu_conv(nb_filter, 3, 3)(input)\n",
        "        residual = _bn_relu_conv(nb_filter, 3, 3)(residual)\n",
        "        return _shortcut(input, residual)\n",
        "    return f\n",
        "\n",
        "\n",
        "def ResUnits(residual_unit, nb_filter, repetations=1):\n",
        "    def f(input):\n",
        "        for i in range(repetations):\n",
        "            init_subsample = (1, 1)\n",
        "            input = residual_unit(nb_filter=nb_filter,init_subsample=init_subsample)(input)\n",
        "        return input\n",
        "    return f\n",
        "\n",
        "\n",
        "def stresnet(c_conf=(3, 2, 32, 32), p_conf=(3, 2, 32, 32), t_conf=(3, 2, 32, 32), external_dim=8, nb_residual_unit=3, CF=64):\n",
        "    '''\n",
        "    C - Temporal Closeness\n",
        "    P - Period\n",
        "    T - Trend\n",
        "    conf = (len_seq, nb_flow, map_height, map_width)\n",
        "    external_dim\n",
        "    '''\n",
        "\n",
        "    # main input\n",
        "    main_inputs = []\n",
        "    outputs = []\n",
        "    for conf in [c_conf, p_conf, t_conf]:\n",
        "        if conf is not None:\n",
        "            len_seq, nb_flow, map_height, map_width = conf\n",
        "            input = Input(shape=(nb_flow * len_seq, map_height, map_width))\n",
        "            main_inputs.append(input)\n",
        "            # Conv1\n",
        "            #conv1 = Convolution2D(nb_filter=CF, nb_row=3, nb_col=3, border_mode=\"same\")(input)\n",
        "            conv1 = Conv2D(filters=CF, kernel_size=(3,3),padding=\"same\")(input)\n",
        "            # [nb_residual_unit] Residual Units\n",
        "            residual_output = ResUnits(_residual_unit, nb_filter=CF,\n",
        "                              repetations=nb_residual_unit)(conv1)\n",
        "            # Conv2\n",
        "            activation = Activation('relu')(residual_output)\n",
        "            #conv2 = Convolution2D(nb_filter=nb_flow, nb_row=3, nb_col=3, border_mode=\"same\")(activation)\n",
        "            conv2 = Conv2D(filters=nb_flow, kernel_size=(3,3),padding=\"same\")(activation)\n",
        "            outputs.append(conv2)\n",
        "\n",
        "    # parameter-matrix-based fusion\n",
        "    if len(outputs) == 1:\n",
        "        main_output = outputs[0]\n",
        "    else:\n",
        "        #from DST_network.ilayer import iLayer\n",
        "        new_outputs = []\n",
        "        for output in outputs:\n",
        "            new_outputs.append(iLayer()(output))\n",
        "        #main_output = merge(new_outputs, mode='sum')\n",
        "        main_output = Add()(new_outputs)\n",
        "\n",
        "    # fusing with external component\n",
        "    if external_dim != None and external_dim > 0:\n",
        "        # external input\n",
        "        external_input = Input(shape=(external_dim,))\n",
        "        main_inputs.append(external_input)\n",
        "        embedding = Dense(output_dim=10)(external_input)\n",
        "        embedding = Activation('relu')(embedding)\n",
        "        h1 = Dense(output_dim=nb_flow * map_height * map_width)(embedding)\n",
        "        activation = Activation('relu')(h1)\n",
        "        external_output = Reshape((nb_flow, map_height, map_width))(activation)\n",
        "        main_output = merge([main_output, external_output], mode='sum')\n",
        "    else:\n",
        "        print('external_dim:', external_dim)\n",
        "\n",
        "    main_output = Activation('tanh')(main_output)\n",
        "    model = Model(inputs=main_inputs, outputs=main_output)\n",
        "\n",
        "    return model\n",
        "'''\n",
        "if __name__ == '__main__':\n",
        "    model = stresnet(external_dim=28, nb_residual_unit=12)\n",
        "    #plot(model, to_file='ST-ResNet.png', show_shapes=True)\n",
        "    model.summary()\n",
        "'''"
      ],
      "metadata": {
        "id": "nJA-LD4IoEwq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5fbce86a-9fab-45fe-9190-5870efa41f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nif __name__ == '__main__':\\n    model = stresnet(external_dim=28, nb_residual_unit=12)\\n    #plot(model, to_file='ST-ResNet.png', show_shapes=True)\\n    model.summary()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "NO=4\n",
        "#for reproduction\n",
        "seed=1\n",
        "for i in range(NO):\n",
        "    seed=seed*10+7\n",
        "seed=seed*10+7\n",
        "np.random.seed(seed)\n",
        "import tensorflow as tf  #from V1707\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "#hyperparameters\n",
        "epoch = 100  # number of epoch at training stage\n",
        "batch_size = 32  # batch size\n",
        "lr = 0.0001  # learning rate\n",
        "\n",
        "#H,W,channel = 21,12,2   # grid size\n",
        "H,W,channel = 14,12,1   # grid size\n",
        "\n",
        "#T = 24*1  # number of time intervals in one day\n",
        "T = 8*1  # number of time intervals in one day\n",
        "\n",
        "len_closeness = 4  # length of closeness dependent sequence\n",
        "len_period = 4  # length of peroid dependent sequence\n",
        "len_trend = 4  # length of trend dependent sequence\n",
        "\n",
        "T_closeness,T_period,T_trend=1,T,T*7\n",
        "\n",
        "# last 7 days for testing data\n",
        "days_test = 14\n",
        "len_test = T * days_test\n",
        "\n",
        "#the number of repetition and if retrain the model\n",
        "iterate_num=10\n"
      ],
      "metadata": {
        "id": "D6ttw6NLq5ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"loading data...\")\n",
        "#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "\n",
        "R_N = 4   # number of residual units\n",
        "\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Conv2D\n",
        "#from DST_network.STResNet import stresnet\n",
        "#import DST_network.metrics as metrics\n",
        "#import PPT3_network.metrics as metrics\n",
        "\n",
        "def build_model(external_dim,CFN):\n",
        "  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n",
        "  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n",
        "  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n",
        "\n",
        "  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n",
        "\n",
        "  adam = Adam(lr=lr)\n",
        "  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n",
        "  #model.summary()\n",
        "  #from keras.utils.visualize_util import plot\n",
        "  #plot(model, to_file='model.png', show_shapes=True)\n",
        "  return model\n",
        "\n",
        "\n",
        "CF=64\n",
        "\n",
        "iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n",
        "\n",
        "RMSE=np.zeros([iterate_num,1])\n",
        "MAE =np.zeros([iterate_num,1])\n",
        "count_sum=iterate_num\n",
        "\n",
        "import time\n",
        "\n",
        "count=0\n",
        "\n",
        "\n",
        "for iterate_index in range(iterate_num):\n",
        "  count=count+1\n",
        "  iterate=iterate_loop[iterate_index]\n",
        "\n",
        "  time_start=time.time()\n",
        "\n",
        "  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n",
        "\n",
        "  model = build_model(external_dim=False,CFN=CF)\n",
        "  '''\n",
        "  model_checkpoint=ModelCheckpoint(\n",
        "      filepath=F,\n",
        "      monitor='val_rmse',\n",
        "      verbose=1,\n",
        "      save_best_only=True,\n",
        "      save_weights_only=False,\n",
        "      mode='min',\n",
        "      period=1)\n",
        "  '''\n",
        "  print('=' * 10)\n",
        "  print(\"training model...\")\n",
        "  history = model.fit(X_train, Y_train,\n",
        "                      epochs=epoch,\n",
        "                      batch_size=batch_size,\n",
        "                      validation_split=0.1,\n",
        "                      #callbacks=[model_checkpoint],\n",
        "                      verbose=0)\n",
        "\n",
        "  #print('=' * 10)\n",
        "  #print('evaluating using the model that has the best loss on the valid set')\n",
        "  #model.load_weights(F)\n",
        "\n",
        "  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n",
        "  print('              mse     rmse    mae')\n",
        "  print('Train score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
        "  print('Test  score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  print(np.array(score))\n",
        "\n",
        "  RMSE[iterate_index,0]=score[1]\n",
        "  MAE [iterate_index,0]=score[2]\n",
        "\n",
        "  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n",
        "\n",
        "  np.set_printoptions(precision=4, suppress=True)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  for_show=np.mean(for_show,axis=0)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n",
        "\n",
        "  time_end=time.time()\n",
        "\n",
        "  print('totally cost',time_end-time_start)\n",
        "  print(str(count)+'/'+str(count_sum))\n",
        "\n"
      ],
      "metadata": {
        "id": "9Ym-sGl1oyGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aaf4d25-7b33-413e-ed74-f20c81afcd16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data...\n",
            "all_data shape:  (797, 1, 14, 12)\n",
            "max= 33.0  min= 0.0\n",
            "mean= -0.9878032883051704  variance= 0.06483403736343217\n",
            "number_of_skip_hours: 224\n",
            "len_train=461\n",
            "len_test =112\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.002324 0.048211 0.010578]\n",
            "RMSE  MAE\n",
            "[[0.0482 0.0106]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0048 0.0011]\n",
            "totally cost 35.27445697784424\n",
            "1/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.002225 0.047165 0.012295]\n",
            "RMSE  MAE\n",
            "[[0.0482 0.0106]\n",
            " [0.0472 0.0123]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0095 0.0023]\n",
            "totally cost 19.441701412200928\n",
            "2/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.002239 0.047322 0.011563]\n",
            "RMSE  MAE\n",
            "[[0.0482 0.0106]\n",
            " [0.0472 0.0123]\n",
            " [0.0473 0.0116]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0143 0.0034]\n",
            "totally cost 19.361191987991333\n",
            "3/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.00228  0.047752 0.011317]\n",
            "RMSE  MAE\n",
            "[[0.0482 0.0106]\n",
            " [0.0472 0.0123]\n",
            " [0.0473 0.0116]\n",
            " [0.0478 0.0113]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.019  0.0046]\n",
            "totally cost 20.01276469230652\n",
            "4/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.002286 0.047814 0.012246]\n",
            "RMSE  MAE\n",
            "[[0.0482 0.0106]\n",
            " [0.0472 0.0123]\n",
            " [0.0473 0.0116]\n",
            " [0.0478 0.0113]\n",
            " [0.0478 0.0122]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0238 0.0058]\n",
            "totally cost 19.518662452697754\n",
            "5/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.002293 0.047883 0.011706]\n",
            "RMSE  MAE\n",
            "[[0.0482 0.0106]\n",
            " [0.0472 0.0123]\n",
            " [0.0473 0.0116]\n",
            " [0.0478 0.0113]\n",
            " [0.0478 0.0122]\n",
            " [0.0479 0.0117]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0286 0.007 ]\n",
            "totally cost 19.783133268356323\n",
            "6/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.002273 0.047677 0.011175]\n",
            "RMSE  MAE\n",
            "[[0.0482 0.0106]\n",
            " [0.0472 0.0123]\n",
            " [0.0473 0.0116]\n",
            " [0.0478 0.0113]\n",
            " [0.0478 0.0122]\n",
            " [0.0479 0.0117]\n",
            " [0.0477 0.0112]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0334 0.0081]\n",
            "totally cost 20.255289316177368\n",
            "7/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.002342 0.048393 0.010697]\n",
            "RMSE  MAE\n",
            "[[0.0482 0.0106]\n",
            " [0.0472 0.0123]\n",
            " [0.0473 0.0116]\n",
            " [0.0478 0.0113]\n",
            " [0.0478 0.0122]\n",
            " [0.0479 0.0117]\n",
            " [0.0477 0.0112]\n",
            " [0.0484 0.0107]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0382 0.0092]\n",
            "totally cost 19.856544017791748\n",
            "8/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.002348 0.048454 0.009751]\n",
            "RMSE  MAE\n",
            "[[0.0482 0.0106]\n",
            " [0.0472 0.0123]\n",
            " [0.0473 0.0116]\n",
            " [0.0478 0.0113]\n",
            " [0.0478 0.0122]\n",
            " [0.0479 0.0117]\n",
            " [0.0477 0.0112]\n",
            " [0.0484 0.0107]\n",
            " [0.0485 0.0098]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0431 0.0101]\n",
            "totally cost 19.99796748161316\n",
            "9/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.002303 0.047991 0.010314]\n",
            "RMSE  MAE\n",
            "[[0.0482 0.0106]\n",
            " [0.0472 0.0123]\n",
            " [0.0473 0.0116]\n",
            " [0.0478 0.0113]\n",
            " [0.0478 0.0122]\n",
            " [0.0479 0.0117]\n",
            " [0.0477 0.0112]\n",
            " [0.0484 0.0107]\n",
            " [0.0485 0.0098]\n",
            " [0.048  0.0103]]\n",
            "RMSE  MAE\n",
            "[0.0479 0.0112]\n",
            "totally cost 20.368154048919678\n",
            "10/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# m1_Col\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class MM:\n",
        "    def __init__(self,MM_max,MM_min):\n",
        "        self.max=MM_max\n",
        "        self.min=MM_min\n",
        "\n",
        "# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n",
        "def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n",
        "\n",
        "    all_data=np.load('data2/m1_Col.npy')\n",
        "    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n",
        "    len_total,feature,map_height,map_width=all_data.shape\n",
        "    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n",
        "    #len_total,feature,map_height,map_width=all_data.shape\n",
        "    print('all_data shape: ',all_data.shape)\n",
        "    #mm=MM(np.max(all_data),np.min(all_data))\n",
        "    print('max=',np.max(all_data),' min=',np.min(all_data))\n",
        "\n",
        "    #for time\n",
        "    time=np.arange(len_total,dtype=int)\n",
        "    #hour\n",
        "    time_hour=time%T_period\n",
        "    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n",
        "    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n",
        "    for i in range(len_total):\n",
        "        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #day\n",
        "    time_day=(time//T_period)%7\n",
        "    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n",
        "    for i in range(len_total):\n",
        "        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #con\n",
        "    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n",
        "\n",
        "    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n",
        "    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n",
        "\n",
        "    if len_trend>0:\n",
        "        number_of_skip_hours=T_trend*len_trend\n",
        "    elif len_period>0:\n",
        "        number_of_skip_hours=T_period*len_period\n",
        "    elif len_closeness>0:\n",
        "        number_of_skip_hours=T_closeness*len_closeness\n",
        "    else:\n",
        "        print(\"wrong\")\n",
        "    print('number_of_skip_hours:',number_of_skip_hours)\n",
        "\n",
        "    Y=all_data[number_of_skip_hours:len_total]\n",
        "\n",
        "    if len_closeness>0:\n",
        "        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n",
        "        for i in range(len_closeness-1):\n",
        "            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n",
        "    if len_period>0:\n",
        "        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n",
        "        for i in range(len_period-1):\n",
        "            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n",
        "    if len_trend>0:\n",
        "        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n",
        "        for i in range(len_trend-1):\n",
        "            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n",
        "\n",
        "    matrix_T=matrix_T[number_of_skip_hours:]\n",
        "\n",
        "    X_closeness_train=X_closeness[:-len_test]\n",
        "    X_period_train=X_period[:-len_test]\n",
        "    X_trend_train=X_trend[:-len_test]\n",
        "    T_train=matrix_T[:-len_test]\n",
        "    X_closeness_test=X_closeness[-len_test:]\n",
        "    X_period_test=X_period[-len_test:]\n",
        "    X_trend_test=X_trend[-len_test:]\n",
        "    T_test=matrix_T[-len_test:]\n",
        "\n",
        "    X_train=[X_closeness_train,X_period_train,X_trend_train]\n",
        "    X_test=[X_closeness_test,X_period_test,X_trend_test]\n",
        "    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n",
        "    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n",
        "    Y_train=Y[:-len_test]\n",
        "    Y_test=Y[-len_test:]\n",
        "\n",
        "    len_train=X_closeness_train.shape[0]\n",
        "    len_test=X_closeness_test.shape[0]\n",
        "    print('len_train='+str(len_train))\n",
        "    print('len_test ='+str(len_test ))\n",
        "\n",
        "    '''\n",
        "    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n",
        "    for i in range(poi.shape[0]):\n",
        "        poi[i]=poi[i]/np.max(poi[i])\n",
        "    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n",
        "    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n",
        "\n",
        "    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n",
        "    '''\n",
        "    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n",
        "\n",
        "\n",
        "\n",
        "print(\"loading data...\")\n",
        "#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "\n",
        "R_N = 4   # number of residual units\n",
        "\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Conv2D\n",
        "#from DST_network.STResNet import stresnet\n",
        "#import DST_network.metrics as metrics\n",
        "#import PPT3_network.metrics as metrics\n",
        "\n",
        "def build_model(external_dim,CFN):\n",
        "  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n",
        "  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n",
        "  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n",
        "\n",
        "  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n",
        "\n",
        "  adam = Adam(lr=lr)\n",
        "  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n",
        "  #model.summary()\n",
        "  #from keras.utils.visualize_util import plot\n",
        "  #plot(model, to_file='model.png', show_shapes=True)\n",
        "  return model\n",
        "\n",
        "\n",
        "CF=64\n",
        "\n",
        "iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n",
        "\n",
        "RMSE=np.zeros([iterate_num,1])\n",
        "MAE =np.zeros([iterate_num,1])\n",
        "count_sum=iterate_num\n",
        "\n",
        "import time\n",
        "\n",
        "count=0\n",
        "\n",
        "\n",
        "for iterate_index in range(iterate_num):\n",
        "  count=count+1\n",
        "  iterate=iterate_loop[iterate_index]\n",
        "\n",
        "  time_start=time.time()\n",
        "\n",
        "  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n",
        "\n",
        "  model = build_model(external_dim=False,CFN=CF)\n",
        "  '''\n",
        "  model_checkpoint=ModelCheckpoint(\n",
        "      filepath=F,\n",
        "      monitor='val_rmse',\n",
        "      verbose=1,\n",
        "      save_best_only=True,\n",
        "      save_weights_only=False,\n",
        "      mode='min',\n",
        "      period=1)\n",
        "  '''\n",
        "  print('=' * 10)\n",
        "  print(\"training model...\")\n",
        "  history = model.fit(X_train, Y_train,\n",
        "                      epochs=epoch,\n",
        "                      batch_size=batch_size,\n",
        "                      validation_split=0.1,\n",
        "                      #callbacks=[model_checkpoint],\n",
        "                      verbose=0)\n",
        "\n",
        "  #print('=' * 10)\n",
        "  #print('evaluating using the model that has the best loss on the valid set')\n",
        "  #model.load_weights(F)\n",
        "\n",
        "  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n",
        "  print('              mse     rmse    mae')\n",
        "  print('Train score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
        "  print('Test  score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  print(np.array(score))\n",
        "\n",
        "  RMSE[iterate_index,0]=score[1]\n",
        "  MAE [iterate_index,0]=score[2]\n",
        "\n",
        "  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n",
        "\n",
        "  np.set_printoptions(precision=4, suppress=True)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  for_show=np.mean(for_show,axis=0)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n",
        "\n",
        "  time_end=time.time()\n",
        "\n",
        "  print('totally cost',time_end-time_start)\n",
        "  print(str(count)+'/'+str(count_sum))\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "_lnZBDA6oyEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f561055-cab3-474c-bb01-d92fe5b7c9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data...\n",
            "all_data shape:  (797, 1, 14, 12)\n",
            "max= 13.0  min= 0.0\n",
            "mean= -0.9942343311226624  variance= 0.04226600741012836\n",
            "number_of_skip_hours: 224\n",
            "len_train=461\n",
            "len_test =112\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000836 0.02892  0.004363]\n",
            "RMSE  MAE\n",
            "[[0.0289 0.0044]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0029 0.0004]\n",
            "totally cost 19.63086175918579\n",
            "1/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000834 0.028876 0.005142]\n",
            "RMSE  MAE\n",
            "[[0.0289 0.0044]\n",
            " [0.0289 0.0051]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0058 0.001 ]\n",
            "totally cost 19.730453491210938\n",
            "2/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000832 0.028847 0.005577]\n",
            "RMSE  MAE\n",
            "[[0.0289 0.0044]\n",
            " [0.0289 0.0051]\n",
            " [0.0288 0.0056]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0087 0.0015]\n",
            "totally cost 19.557302236557007\n",
            "3/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000836 0.028917 0.004044]\n",
            "RMSE  MAE\n",
            "[[0.0289 0.0044]\n",
            " [0.0289 0.0051]\n",
            " [0.0288 0.0056]\n",
            " [0.0289 0.004 ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0116 0.0019]\n",
            "totally cost 19.605775117874146\n",
            "4/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000836 0.028915 0.004234]\n",
            "RMSE  MAE\n",
            "[[0.0289 0.0044]\n",
            " [0.0289 0.0051]\n",
            " [0.0288 0.0056]\n",
            " [0.0289 0.004 ]\n",
            " [0.0289 0.0042]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0144 0.0023]\n",
            "totally cost 20.52017569541931\n",
            "5/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000837 0.02893  0.004238]\n",
            "RMSE  MAE\n",
            "[[0.0289 0.0044]\n",
            " [0.0289 0.0051]\n",
            " [0.0288 0.0056]\n",
            " [0.0289 0.004 ]\n",
            " [0.0289 0.0042]\n",
            " [0.0289 0.0042]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0173 0.0028]\n",
            "totally cost 19.892088890075684\n",
            "6/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000834 0.028879 0.004338]\n",
            "RMSE  MAE\n",
            "[[0.0289 0.0044]\n",
            " [0.0289 0.0051]\n",
            " [0.0288 0.0056]\n",
            " [0.0289 0.004 ]\n",
            " [0.0289 0.0042]\n",
            " [0.0289 0.0042]\n",
            " [0.0289 0.0043]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0202 0.0032]\n",
            "totally cost 19.914803981781006\n",
            "7/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000839 0.028966 0.003555]\n",
            "RMSE  MAE\n",
            "[[0.0289 0.0044]\n",
            " [0.0289 0.0051]\n",
            " [0.0288 0.0056]\n",
            " [0.0289 0.004 ]\n",
            " [0.0289 0.0042]\n",
            " [0.0289 0.0042]\n",
            " [0.0289 0.0043]\n",
            " [0.029  0.0036]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0231 0.0035]\n",
            "totally cost 19.801058053970337\n",
            "8/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000834 0.028877 0.004545]\n",
            "RMSE  MAE\n",
            "[[0.0289 0.0044]\n",
            " [0.0289 0.0051]\n",
            " [0.0288 0.0056]\n",
            " [0.0289 0.004 ]\n",
            " [0.0289 0.0042]\n",
            " [0.0289 0.0042]\n",
            " [0.0289 0.0043]\n",
            " [0.029  0.0036]\n",
            " [0.0289 0.0045]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.026 0.004]\n",
            "totally cost 19.976600646972656\n",
            "9/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000835 0.028888 0.005035]\n",
            "RMSE  MAE\n",
            "[[0.0289 0.0044]\n",
            " [0.0289 0.0051]\n",
            " [0.0288 0.0056]\n",
            " [0.0289 0.004 ]\n",
            " [0.0289 0.0042]\n",
            " [0.0289 0.0042]\n",
            " [0.0289 0.0043]\n",
            " [0.029  0.0036]\n",
            " [0.0289 0.0045]\n",
            " [0.0289 0.005 ]]\n",
            "RMSE  MAE\n",
            "[0.0289 0.0045]\n",
            "totally cost 19.735861778259277\n",
            "10/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# m2_Ev\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class MM:\n",
        "    def __init__(self,MM_max,MM_min):\n",
        "        self.max=MM_max\n",
        "        self.min=MM_min\n",
        "\n",
        "# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n",
        "def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n",
        "\n",
        "    all_data=np.load('data2/m2_Ev.npy')\n",
        "    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n",
        "    len_total,feature,map_height,map_width=all_data.shape\n",
        "    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n",
        "    #len_total,feature,map_height,map_width=all_data.shape\n",
        "    print('all_data shape: ',all_data.shape)\n",
        "    #mm=MM(np.max(all_data),np.min(all_data))\n",
        "    print('max=',np.max(all_data),' min=',np.min(all_data))\n",
        "\n",
        "    #for time\n",
        "    time=np.arange(len_total,dtype=int)\n",
        "    #hour\n",
        "    time_hour=time%T_period\n",
        "    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n",
        "    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n",
        "    for i in range(len_total):\n",
        "        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #day\n",
        "    time_day=(time//T_period)%7\n",
        "    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n",
        "    for i in range(len_total):\n",
        "        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #con\n",
        "    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n",
        "\n",
        "    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n",
        "    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n",
        "\n",
        "    if len_trend>0:\n",
        "        number_of_skip_hours=T_trend*len_trend\n",
        "    elif len_period>0:\n",
        "        number_of_skip_hours=T_period*len_period\n",
        "    elif len_closeness>0:\n",
        "        number_of_skip_hours=T_closeness*len_closeness\n",
        "    else:\n",
        "        print(\"wrong\")\n",
        "    print('number_of_skip_hours:',number_of_skip_hours)\n",
        "\n",
        "    Y=all_data[number_of_skip_hours:len_total]\n",
        "\n",
        "    if len_closeness>0:\n",
        "        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n",
        "        for i in range(len_closeness-1):\n",
        "            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n",
        "    if len_period>0:\n",
        "        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n",
        "        for i in range(len_period-1):\n",
        "            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n",
        "    if len_trend>0:\n",
        "        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n",
        "        for i in range(len_trend-1):\n",
        "            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n",
        "\n",
        "    matrix_T=matrix_T[number_of_skip_hours:]\n",
        "\n",
        "    X_closeness_train=X_closeness[:-len_test]\n",
        "    X_period_train=X_period[:-len_test]\n",
        "    X_trend_train=X_trend[:-len_test]\n",
        "    T_train=matrix_T[:-len_test]\n",
        "    X_closeness_test=X_closeness[-len_test:]\n",
        "    X_period_test=X_period[-len_test:]\n",
        "    X_trend_test=X_trend[-len_test:]\n",
        "    T_test=matrix_T[-len_test:]\n",
        "\n",
        "    X_train=[X_closeness_train,X_period_train,X_trend_train]\n",
        "    X_test=[X_closeness_test,X_period_test,X_trend_test]\n",
        "    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n",
        "    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n",
        "    Y_train=Y[:-len_test]\n",
        "    Y_test=Y[-len_test:]\n",
        "\n",
        "    len_train=X_closeness_train.shape[0]\n",
        "    len_test=X_closeness_test.shape[0]\n",
        "    print('len_train='+str(len_train))\n",
        "    print('len_test ='+str(len_test ))\n",
        "\n",
        "    '''\n",
        "    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n",
        "    for i in range(poi.shape[0]):\n",
        "        poi[i]=poi[i]/np.max(poi[i])\n",
        "    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n",
        "    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n",
        "\n",
        "    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n",
        "    '''\n",
        "    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n",
        "\n",
        "\n",
        "\n",
        "print(\"loading data...\")\n",
        "#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "\n",
        "R_N = 4   # number of residual units\n",
        "\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Conv2D\n",
        "#from DST_network.STResNet import stresnet\n",
        "#import DST_network.metrics as metrics\n",
        "#import PPT3_network.metrics as metrics\n",
        "\n",
        "def build_model(external_dim,CFN):\n",
        "  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n",
        "  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n",
        "  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n",
        "\n",
        "  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n",
        "\n",
        "  adam = Adam(lr=lr)\n",
        "  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n",
        "  #model.summary()\n",
        "  #from keras.utils.visualize_util import plot\n",
        "  #plot(model, to_file='model.png', show_shapes=True)\n",
        "  return model\n",
        "\n",
        "\n",
        "CF=64\n",
        "\n",
        "iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n",
        "\n",
        "RMSE=np.zeros([iterate_num,1])\n",
        "MAE =np.zeros([iterate_num,1])\n",
        "count_sum=iterate_num\n",
        "\n",
        "import time\n",
        "\n",
        "count=0\n",
        "\n",
        "\n",
        "for iterate_index in range(iterate_num):\n",
        "  count=count+1\n",
        "  iterate=iterate_loop[iterate_index]\n",
        "\n",
        "  time_start=time.time()\n",
        "\n",
        "  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n",
        "\n",
        "  model = build_model(external_dim=False,CFN=CF)\n",
        "  '''\n",
        "  model_checkpoint=ModelCheckpoint(\n",
        "      filepath=F,\n",
        "      monitor='val_rmse',\n",
        "      verbose=1,\n",
        "      save_best_only=True,\n",
        "      save_weights_only=False,\n",
        "      mode='min',\n",
        "      period=1)\n",
        "  '''\n",
        "  print('=' * 10)\n",
        "  print(\"training model...\")\n",
        "  history = model.fit(X_train, Y_train,\n",
        "                      epochs=epoch,\n",
        "                      batch_size=batch_size,\n",
        "                      validation_split=0.1,\n",
        "                      #callbacks=[model_checkpoint],\n",
        "                      verbose=0)\n",
        "\n",
        "  #print('=' * 10)\n",
        "  #print('evaluating using the model that has the best loss on the valid set')\n",
        "  #model.load_weights(F)\n",
        "\n",
        "  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n",
        "  print('              mse     rmse    mae')\n",
        "  print('Train score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
        "  print('Test  score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  print(np.array(score))\n",
        "\n",
        "  RMSE[iterate_index,0]=score[1]\n",
        "  MAE [iterate_index,0]=score[2]\n",
        "\n",
        "  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n",
        "\n",
        "  np.set_printoptions(precision=4, suppress=True)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  for_show=np.mean(for_show,axis=0)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n",
        "\n",
        "  time_end=time.time()\n",
        "\n",
        "  print('totally cost',time_end-time_start)\n",
        "  print(str(count)+'/'+str(count_sum))\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "6gmFQYoeoyCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e294a240-052c-4b4b-b9f5-f430781e96aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data...\n",
            "all_data shape:  (797, 1, 14, 12)\n",
            "max= 1.0  min= 0.0\n",
            "mean= -0.9998356933739618  variance= 0.018126948320356582\n",
            "number_of_skip_hours: 224\n",
            "len_train=461\n",
            "len_test =112\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000213 0.014581 0.000138]\n",
            "RMSE  MAE\n",
            "[[0.0146 0.0001]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0015 0.    ]\n",
            "totally cost 19.482852935791016\n",
            "1/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000213 0.014582 0.000182]\n",
            "RMSE  MAE\n",
            "[[0.0146 0.0001]\n",
            " [0.0146 0.0002]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0029 0.    ]\n",
            "totally cost 19.925350189208984\n",
            "2/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000213 0.014581 0.000142]\n",
            "RMSE  MAE\n",
            "[[0.0146 0.0001]\n",
            " [0.0146 0.0002]\n",
            " [0.0146 0.0001]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0044 0.    ]\n",
            "totally cost 20.138166189193726\n",
            "3/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000213 0.014581 0.000132]\n",
            "RMSE  MAE\n",
            "[[0.0146 0.0001]\n",
            " [0.0146 0.0002]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0058 0.0001]\n",
            "totally cost 19.856428384780884\n",
            "4/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000213 0.014582 0.000147]\n",
            "RMSE  MAE\n",
            "[[0.0146 0.0001]\n",
            " [0.0146 0.0002]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0073 0.0001]\n",
            "totally cost 19.561063766479492\n",
            "5/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000213 0.014581 0.000127]\n",
            "RMSE  MAE\n",
            "[[0.0146 0.0001]\n",
            " [0.0146 0.0002]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0087 0.0001]\n",
            "totally cost 19.897281408309937\n",
            "6/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000213 0.014581 0.000147]\n",
            "RMSE  MAE\n",
            "[[0.0146 0.0001]\n",
            " [0.0146 0.0002]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0102 0.0001]\n",
            "totally cost 18.982779026031494\n",
            "7/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000213 0.014582 0.000143]\n",
            "RMSE  MAE\n",
            "[[0.0146 0.0001]\n",
            " [0.0146 0.0002]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0117 0.0001]\n",
            "totally cost 19.770782709121704\n",
            "8/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000213 0.014582 0.000172]\n",
            "RMSE  MAE\n",
            "[[0.0146 0.0001]\n",
            " [0.0146 0.0002]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0002]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0131 0.0001]\n",
            "totally cost 19.70711350440979\n",
            "9/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000213 0.014581 0.000149]\n",
            "RMSE  MAE\n",
            "[[0.0146 0.0001]\n",
            " [0.0146 0.0002]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0001]\n",
            " [0.0146 0.0002]\n",
            " [0.0146 0.0001]]\n",
            "RMSE  MAE\n",
            "[0.0146 0.0001]\n",
            "totally cost 19.28780460357666\n",
            "10/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# m3_Food\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class MM:\n",
        "    def __init__(self,MM_max,MM_min):\n",
        "        self.max=MM_max\n",
        "        self.min=MM_min\n",
        "\n",
        "# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n",
        "def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n",
        "\n",
        "    all_data=np.load('data2/m3_Food.npy')\n",
        "    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n",
        "    len_total,feature,map_height,map_width=all_data.shape\n",
        "    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n",
        "    #len_total,feature,map_height,map_width=all_data.shape\n",
        "    print('all_data shape: ',all_data.shape)\n",
        "    #mm=MM(np.max(all_data),np.min(all_data))\n",
        "    print('max=',np.max(all_data),' min=',np.min(all_data))\n",
        "\n",
        "    #for time\n",
        "    time=np.arange(len_total,dtype=int)\n",
        "    #hour\n",
        "    time_hour=time%T_period\n",
        "    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n",
        "    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n",
        "    for i in range(len_total):\n",
        "        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #day\n",
        "    time_day=(time//T_period)%7\n",
        "    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n",
        "    for i in range(len_total):\n",
        "        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #con\n",
        "    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n",
        "\n",
        "    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n",
        "    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n",
        "\n",
        "    if len_trend>0:\n",
        "        number_of_skip_hours=T_trend*len_trend\n",
        "    elif len_period>0:\n",
        "        number_of_skip_hours=T_period*len_period\n",
        "    elif len_closeness>0:\n",
        "        number_of_skip_hours=T_closeness*len_closeness\n",
        "    else:\n",
        "        print(\"wrong\")\n",
        "    print('number_of_skip_hours:',number_of_skip_hours)\n",
        "\n",
        "    Y=all_data[number_of_skip_hours:len_total]\n",
        "\n",
        "    if len_closeness>0:\n",
        "        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n",
        "        for i in range(len_closeness-1):\n",
        "            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n",
        "    if len_period>0:\n",
        "        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n",
        "        for i in range(len_period-1):\n",
        "            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n",
        "    if len_trend>0:\n",
        "        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n",
        "        for i in range(len_trend-1):\n",
        "            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n",
        "\n",
        "    matrix_T=matrix_T[number_of_skip_hours:]\n",
        "\n",
        "    X_closeness_train=X_closeness[:-len_test]\n",
        "    X_period_train=X_period[:-len_test]\n",
        "    X_trend_train=X_trend[:-len_test]\n",
        "    T_train=matrix_T[:-len_test]\n",
        "    X_closeness_test=X_closeness[-len_test:]\n",
        "    X_period_test=X_period[-len_test:]\n",
        "    X_trend_test=X_trend[-len_test:]\n",
        "    T_test=matrix_T[-len_test:]\n",
        "\n",
        "    X_train=[X_closeness_train,X_period_train,X_trend_train]\n",
        "    X_test=[X_closeness_test,X_period_test,X_trend_test]\n",
        "    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n",
        "    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n",
        "    Y_train=Y[:-len_test]\n",
        "    Y_test=Y[-len_test:]\n",
        "\n",
        "    len_train=X_closeness_train.shape[0]\n",
        "    len_test=X_closeness_test.shape[0]\n",
        "    print('len_train='+str(len_train))\n",
        "    print('len_test ='+str(len_test ))\n",
        "\n",
        "    '''\n",
        "    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n",
        "    for i in range(poi.shape[0]):\n",
        "        poi[i]=poi[i]/np.max(poi[i])\n",
        "    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n",
        "    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n",
        "\n",
        "    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n",
        "    '''\n",
        "    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n",
        "\n",
        "\n",
        "\n",
        "print(\"loading data...\")\n",
        "#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "\n",
        "R_N = 4   # number of residual units\n",
        "\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Conv2D\n",
        "#from DST_network.STResNet import stresnet\n",
        "#import DST_network.metrics as metrics\n",
        "#import PPT3_network.metrics as metrics\n",
        "\n",
        "def build_model(external_dim,CFN):\n",
        "  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n",
        "  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n",
        "  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n",
        "\n",
        "  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n",
        "\n",
        "  adam = Adam(lr=lr)\n",
        "  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n",
        "  #model.summary()\n",
        "  #from keras.utils.visualize_util import plot\n",
        "  #plot(model, to_file='model.png', show_shapes=True)\n",
        "  return model\n",
        "\n",
        "\n",
        "CF=64\n",
        "\n",
        "iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n",
        "\n",
        "RMSE=np.zeros([iterate_num,1])\n",
        "MAE =np.zeros([iterate_num,1])\n",
        "count_sum=iterate_num\n",
        "\n",
        "import time\n",
        "\n",
        "count=0\n",
        "\n",
        "\n",
        "for iterate_index in range(iterate_num):\n",
        "  count=count+1\n",
        "  iterate=iterate_loop[iterate_index]\n",
        "\n",
        "  time_start=time.time()\n",
        "\n",
        "  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n",
        "\n",
        "  model = build_model(external_dim=False,CFN=CF)\n",
        "  '''\n",
        "  model_checkpoint=ModelCheckpoint(\n",
        "      filepath=F,\n",
        "      monitor='val_rmse',\n",
        "      verbose=1,\n",
        "      save_best_only=True,\n",
        "      save_weights_only=False,\n",
        "      mode='min',\n",
        "      period=1)\n",
        "  '''\n",
        "  print('=' * 10)\n",
        "  print(\"training model...\")\n",
        "  history = model.fit(X_train, Y_train,\n",
        "                      epochs=epoch,\n",
        "                      batch_size=batch_size,\n",
        "                      validation_split=0.1,\n",
        "                      #callbacks=[model_checkpoint],\n",
        "                      verbose=0)\n",
        "\n",
        "  #print('=' * 10)\n",
        "  #print('evaluating using the model that has the best loss on the valid set')\n",
        "  #model.load_weights(F)\n",
        "\n",
        "  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n",
        "  print('              mse     rmse    mae')\n",
        "  print('Train score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
        "  print('Test  score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  print(np.array(score))\n",
        "\n",
        "  RMSE[iterate_index,0]=score[1]\n",
        "  MAE [iterate_index,0]=score[2]\n",
        "\n",
        "  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n",
        "\n",
        "  np.set_printoptions(precision=4, suppress=True)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  for_show=np.mean(for_show,axis=0)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n",
        "\n",
        "  time_end=time.time()\n",
        "\n",
        "  print('totally cost',time_end-time_start)\n",
        "  print(str(count)+'/'+str(count_sum))\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "3kSWHETFoyAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30425148-3946-4a4d-ec9a-70e94b94a38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data...\n",
            "all_data shape:  (797, 1, 14, 12)\n",
            "max= 63.0  min= 0.0\n",
            "mean= -0.9811303442330509  variance= 0.07453364279577186\n",
            "number_of_skip_hours: 224\n",
            "len_train=461\n",
            "len_test =112\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.003332 0.057726 0.017926]\n",
            "RMSE  MAE\n",
            "[[0.0577 0.0179]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0058 0.0018]\n",
            "totally cost 20.01195192337036\n",
            "1/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.003646 0.060383 0.014674]\n",
            "RMSE  MAE\n",
            "[[0.0577 0.0179]\n",
            " [0.0604 0.0147]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0118 0.0033]\n",
            "totally cost 19.73185634613037\n",
            "2/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.003369 0.058041 0.018474]\n",
            "RMSE  MAE\n",
            "[[0.0577 0.0179]\n",
            " [0.0604 0.0147]\n",
            " [0.058  0.0185]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0176 0.0051]\n",
            "totally cost 19.8944411277771\n",
            "3/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.003391 0.058234 0.016991]\n",
            "RMSE  MAE\n",
            "[[0.0577 0.0179]\n",
            " [0.0604 0.0147]\n",
            " [0.058  0.0185]\n",
            " [0.0582 0.017 ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0234 0.0068]\n",
            "totally cost 20.173869609832764\n",
            "4/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.003167 0.05628  0.021101]\n",
            "RMSE  MAE\n",
            "[[0.0577 0.0179]\n",
            " [0.0604 0.0147]\n",
            " [0.058  0.0185]\n",
            " [0.0582 0.017 ]\n",
            " [0.0563 0.0211]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0291 0.0089]\n",
            "totally cost 19.74164056777954\n",
            "5/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.003202 0.056584 0.021148]\n",
            "RMSE  MAE\n",
            "[[0.0577 0.0179]\n",
            " [0.0604 0.0147]\n",
            " [0.058  0.0185]\n",
            " [0.0582 0.017 ]\n",
            " [0.0563 0.0211]\n",
            " [0.0566 0.0211]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0347 0.011 ]\n",
            "totally cost 20.43258571624756\n",
            "6/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.00348  0.058995 0.017972]\n",
            "RMSE  MAE\n",
            "[[0.0577 0.0179]\n",
            " [0.0604 0.0147]\n",
            " [0.058  0.0185]\n",
            " [0.0582 0.017 ]\n",
            " [0.0563 0.0211]\n",
            " [0.0566 0.0211]\n",
            " [0.059  0.018 ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0406 0.0128]\n",
            "totally cost 20.03237247467041\n",
            "7/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.003408 0.058379 0.017895]\n",
            "RMSE  MAE\n",
            "[[0.0577 0.0179]\n",
            " [0.0604 0.0147]\n",
            " [0.058  0.0185]\n",
            " [0.0582 0.017 ]\n",
            " [0.0563 0.0211]\n",
            " [0.0566 0.0211]\n",
            " [0.059  0.018 ]\n",
            " [0.0584 0.0179]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0465 0.0146]\n",
            "totally cost 20.07616877555847\n",
            "8/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.00338  0.05814  0.018036]\n",
            "RMSE  MAE\n",
            "[[0.0577 0.0179]\n",
            " [0.0604 0.0147]\n",
            " [0.058  0.0185]\n",
            " [0.0582 0.017 ]\n",
            " [0.0563 0.0211]\n",
            " [0.0566 0.0211]\n",
            " [0.059  0.018 ]\n",
            " [0.0584 0.0179]\n",
            " [0.0581 0.018 ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0523 0.0164]\n",
            "totally cost 20.288227319717407\n",
            "9/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.00336  0.057965 0.016167]\n",
            "RMSE  MAE\n",
            "[[0.0577 0.0179]\n",
            " [0.0604 0.0147]\n",
            " [0.058  0.0185]\n",
            " [0.0582 0.017 ]\n",
            " [0.0563 0.0211]\n",
            " [0.0566 0.0211]\n",
            " [0.059  0.018 ]\n",
            " [0.0584 0.0179]\n",
            " [0.0581 0.018 ]\n",
            " [0.058  0.0162]]\n",
            "RMSE  MAE\n",
            "[0.0581 0.018 ]\n",
            "totally cost 19.855950593948364\n",
            "10/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# m4_Night\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class MM:\n",
        "    def __init__(self,MM_max,MM_min):\n",
        "        self.max=MM_max\n",
        "        self.min=MM_min\n",
        "\n",
        "# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n",
        "def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n",
        "\n",
        "    all_data=np.load('data2/m4_Night.npy')\n",
        "    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n",
        "    len_total,feature,map_height,map_width=all_data.shape\n",
        "    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n",
        "    #len_total,feature,map_height,map_width=all_data.shape\n",
        "    print('all_data shape: ',all_data.shape)\n",
        "    #mm=MM(np.max(all_data),np.min(all_data))\n",
        "    print('max=',np.max(all_data),' min=',np.min(all_data))\n",
        "\n",
        "    #for time\n",
        "    time=np.arange(len_total,dtype=int)\n",
        "    #hour\n",
        "    time_hour=time%T_period\n",
        "    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n",
        "    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n",
        "    for i in range(len_total):\n",
        "        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #day\n",
        "    time_day=(time//T_period)%7\n",
        "    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n",
        "    for i in range(len_total):\n",
        "        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #con\n",
        "    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n",
        "\n",
        "    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n",
        "    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n",
        "\n",
        "    if len_trend>0:\n",
        "        number_of_skip_hours=T_trend*len_trend\n",
        "    elif len_period>0:\n",
        "        number_of_skip_hours=T_period*len_period\n",
        "    elif len_closeness>0:\n",
        "        number_of_skip_hours=T_closeness*len_closeness\n",
        "    else:\n",
        "        print(\"wrong\")\n",
        "    print('number_of_skip_hours:',number_of_skip_hours)\n",
        "\n",
        "    Y=all_data[number_of_skip_hours:len_total]\n",
        "\n",
        "    if len_closeness>0:\n",
        "        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n",
        "        for i in range(len_closeness-1):\n",
        "            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n",
        "    if len_period>0:\n",
        "        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n",
        "        for i in range(len_period-1):\n",
        "            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n",
        "    if len_trend>0:\n",
        "        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n",
        "        for i in range(len_trend-1):\n",
        "            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n",
        "\n",
        "    matrix_T=matrix_T[number_of_skip_hours:]\n",
        "\n",
        "    X_closeness_train=X_closeness[:-len_test]\n",
        "    X_period_train=X_period[:-len_test]\n",
        "    X_trend_train=X_trend[:-len_test]\n",
        "    T_train=matrix_T[:-len_test]\n",
        "    X_closeness_test=X_closeness[-len_test:]\n",
        "    X_period_test=X_period[-len_test:]\n",
        "    X_trend_test=X_trend[-len_test:]\n",
        "    T_test=matrix_T[-len_test:]\n",
        "\n",
        "    X_train=[X_closeness_train,X_period_train,X_trend_train]\n",
        "    X_test=[X_closeness_test,X_period_test,X_trend_test]\n",
        "    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n",
        "    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n",
        "    Y_train=Y[:-len_test]\n",
        "    Y_test=Y[-len_test:]\n",
        "\n",
        "    len_train=X_closeness_train.shape[0]\n",
        "    len_test=X_closeness_test.shape[0]\n",
        "    print('len_train='+str(len_train))\n",
        "    print('len_test ='+str(len_test ))\n",
        "\n",
        "    '''\n",
        "    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n",
        "    for i in range(poi.shape[0]):\n",
        "        poi[i]=poi[i]/np.max(poi[i])\n",
        "    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n",
        "    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n",
        "\n",
        "    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n",
        "    '''\n",
        "    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n",
        "\n",
        "\n",
        "\n",
        "print(\"loading data...\")\n",
        "#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "\n",
        "R_N = 4   # number of residual units\n",
        "\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Conv2D\n",
        "#from DST_network.STResNet import stresnet\n",
        "#import DST_network.metrics as metrics\n",
        "#import PPT3_network.metrics as metrics\n",
        "\n",
        "def build_model(external_dim,CFN):\n",
        "  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n",
        "  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n",
        "  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n",
        "\n",
        "  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n",
        "\n",
        "  adam = Adam(lr=lr)\n",
        "  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n",
        "  #model.summary()\n",
        "  #from keras.utils.visualize_util import plot\n",
        "  #plot(model, to_file='model.png', show_shapes=True)\n",
        "  return model\n",
        "\n",
        "\n",
        "CF=64\n",
        "\n",
        "iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n",
        "\n",
        "RMSE=np.zeros([iterate_num,1])\n",
        "MAE =np.zeros([iterate_num,1])\n",
        "count_sum=iterate_num\n",
        "\n",
        "import time\n",
        "\n",
        "count=0\n",
        "\n",
        "\n",
        "for iterate_index in range(iterate_num):\n",
        "  count=count+1\n",
        "  iterate=iterate_loop[iterate_index]\n",
        "\n",
        "  time_start=time.time()\n",
        "\n",
        "  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n",
        "\n",
        "  model = build_model(external_dim=False,CFN=CF)\n",
        "  '''\n",
        "  model_checkpoint=ModelCheckpoint(\n",
        "      filepath=F,\n",
        "      monitor='val_rmse',\n",
        "      verbose=1,\n",
        "      save_best_only=True,\n",
        "      save_weights_only=False,\n",
        "      mode='min',\n",
        "      period=1)\n",
        "  '''\n",
        "  print('=' * 10)\n",
        "  print(\"training model...\")\n",
        "  history = model.fit(X_train, Y_train,\n",
        "                      epochs=epoch,\n",
        "                      batch_size=batch_size,\n",
        "                      validation_split=0.1,\n",
        "                      #callbacks=[model_checkpoint],\n",
        "                      verbose=0)\n",
        "\n",
        "  #print('=' * 10)\n",
        "  #print('evaluating using the model that has the best loss on the valid set')\n",
        "  #model.load_weights(F)\n",
        "\n",
        "  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n",
        "  print('              mse     rmse    mae')\n",
        "  print('Train score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
        "  print('Test  score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  print(np.array(score))\n",
        "\n",
        "  RMSE[iterate_index,0]=score[1]\n",
        "  MAE [iterate_index,0]=score[2]\n",
        "\n",
        "  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n",
        "\n",
        "  np.set_printoptions(precision=4, suppress=True)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  for_show=np.mean(for_show,axis=0)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n",
        "\n",
        "  time_end=time.time()\n",
        "\n",
        "  print('totally cost',time_end-time_start)\n",
        "  print(str(count)+'/'+str(count_sum))\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "se0ZqU5rox9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3341bc85-53d6-4bb6-c659-5504f19e17db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data...\n",
            "all_data shape:  (797, 1, 14, 12)\n",
            "max= 3.0  min= 0.0\n",
            "mean= -0.9968283842185973  variance= 0.048270752295892394\n",
            "number_of_skip_hours: 224\n",
            "len_train=461\n",
            "len_test =112\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001673 0.040898 0.003048]\n",
            "RMSE  MAE\n",
            "[[0.0409 0.003 ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0041 0.0003]\n",
            "totally cost 20.73455500602722\n",
            "1/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001677 0.040954 0.002414]\n",
            "RMSE  MAE\n",
            "[[0.0409 0.003 ]\n",
            " [0.041  0.0024]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0082 0.0005]\n",
            "totally cost 19.617950439453125\n",
            "2/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001677 0.040947 0.00281 ]\n",
            "RMSE  MAE\n",
            "[[0.0409 0.003 ]\n",
            " [0.041  0.0024]\n",
            " [0.0409 0.0028]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0123 0.0008]\n",
            "totally cost 18.895735502243042\n",
            "3/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001673 0.040901 0.002758]\n",
            "RMSE  MAE\n",
            "[[0.0409 0.003 ]\n",
            " [0.041  0.0024]\n",
            " [0.0409 0.0028]\n",
            " [0.0409 0.0028]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0164 0.0011]\n",
            "totally cost 19.985987901687622\n",
            "4/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001677 0.040954 0.002557]\n",
            "RMSE  MAE\n",
            "[[0.0409 0.003 ]\n",
            " [0.041  0.0024]\n",
            " [0.0409 0.0028]\n",
            " [0.0409 0.0028]\n",
            " [0.041  0.0026]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0205 0.0014]\n",
            "totally cost 19.439194202423096\n",
            "5/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001673 0.040905 0.002827]\n",
            "RMSE  MAE\n",
            "[[0.0409 0.003 ]\n",
            " [0.041  0.0024]\n",
            " [0.0409 0.0028]\n",
            " [0.0409 0.0028]\n",
            " [0.041  0.0026]\n",
            " [0.0409 0.0028]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0246 0.0016]\n",
            "totally cost 20.030067682266235\n",
            "6/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001677 0.040953 0.002399]\n",
            "RMSE  MAE\n",
            "[[0.0409 0.003 ]\n",
            " [0.041  0.0024]\n",
            " [0.0409 0.0028]\n",
            " [0.0409 0.0028]\n",
            " [0.041  0.0026]\n",
            " [0.0409 0.0028]\n",
            " [0.041  0.0024]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0287 0.0019]\n",
            "totally cost 19.676975965499878\n",
            "7/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001677 0.040952 0.002395]\n",
            "RMSE  MAE\n",
            "[[0.0409 0.003 ]\n",
            " [0.041  0.0024]\n",
            " [0.0409 0.0028]\n",
            " [0.0409 0.0028]\n",
            " [0.041  0.0026]\n",
            " [0.0409 0.0028]\n",
            " [0.041  0.0024]\n",
            " [0.041  0.0024]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0327 0.0021]\n",
            "totally cost 19.162593841552734\n",
            "8/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001676 0.040938 0.002966]\n",
            "RMSE  MAE\n",
            "[[0.0409 0.003 ]\n",
            " [0.041  0.0024]\n",
            " [0.0409 0.0028]\n",
            " [0.0409 0.0028]\n",
            " [0.041  0.0026]\n",
            " [0.0409 0.0028]\n",
            " [0.041  0.0024]\n",
            " [0.041  0.0024]\n",
            " [0.0409 0.003 ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0368 0.0024]\n",
            "totally cost 20.032641410827637\n",
            "9/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001677 0.040955 0.002552]\n",
            "RMSE  MAE\n",
            "[[0.0409 0.003 ]\n",
            " [0.041  0.0024]\n",
            " [0.0409 0.0028]\n",
            " [0.0409 0.0028]\n",
            " [0.041  0.0026]\n",
            " [0.0409 0.0028]\n",
            " [0.041  0.0024]\n",
            " [0.041  0.0024]\n",
            " [0.0409 0.003 ]\n",
            " [0.041  0.0026]]\n",
            "RMSE  MAE\n",
            "[0.0409 0.0027]\n",
            "totally cost 19.39117693901062\n",
            "10/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# m5_Outdoor\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class MM:\n",
        "    def __init__(self,MM_max,MM_min):\n",
        "        self.max=MM_max\n",
        "        self.min=MM_min\n",
        "\n",
        "# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n",
        "def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n",
        "\n",
        "    all_data=np.load('data2/m5_Outdoor.npy')\n",
        "    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n",
        "    len_total,feature,map_height,map_width=all_data.shape\n",
        "    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n",
        "    #len_total,feature,map_height,map_width=all_data.shape\n",
        "    print('all_data shape: ',all_data.shape)\n",
        "    #mm=MM(np.max(all_data),np.min(all_data))\n",
        "    print('max=',np.max(all_data),' min=',np.min(all_data))\n",
        "\n",
        "    #for time\n",
        "    time=np.arange(len_total,dtype=int)\n",
        "    #hour\n",
        "    time_hour=time%T_period\n",
        "    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n",
        "    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n",
        "    for i in range(len_total):\n",
        "        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #day\n",
        "    time_day=(time//T_period)%7\n",
        "    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n",
        "    for i in range(len_total):\n",
        "        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #con\n",
        "    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n",
        "\n",
        "    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n",
        "    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n",
        "\n",
        "    if len_trend>0:\n",
        "        number_of_skip_hours=T_trend*len_trend\n",
        "    elif len_period>0:\n",
        "        number_of_skip_hours=T_period*len_period\n",
        "    elif len_closeness>0:\n",
        "        number_of_skip_hours=T_closeness*len_closeness\n",
        "    else:\n",
        "        print(\"wrong\")\n",
        "    print('number_of_skip_hours:',number_of_skip_hours)\n",
        "\n",
        "    Y=all_data[number_of_skip_hours:len_total]\n",
        "\n",
        "    if len_closeness>0:\n",
        "        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n",
        "        for i in range(len_closeness-1):\n",
        "            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n",
        "    if len_period>0:\n",
        "        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n",
        "        for i in range(len_period-1):\n",
        "            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n",
        "    if len_trend>0:\n",
        "        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n",
        "        for i in range(len_trend-1):\n",
        "            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n",
        "\n",
        "    matrix_T=matrix_T[number_of_skip_hours:]\n",
        "\n",
        "    X_closeness_train=X_closeness[:-len_test]\n",
        "    X_period_train=X_period[:-len_test]\n",
        "    X_trend_train=X_trend[:-len_test]\n",
        "    T_train=matrix_T[:-len_test]\n",
        "    X_closeness_test=X_closeness[-len_test:]\n",
        "    X_period_test=X_period[-len_test:]\n",
        "    X_trend_test=X_trend[-len_test:]\n",
        "    T_test=matrix_T[-len_test:]\n",
        "\n",
        "    X_train=[X_closeness_train,X_period_train,X_trend_train]\n",
        "    X_test=[X_closeness_test,X_period_test,X_trend_test]\n",
        "    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n",
        "    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n",
        "    Y_train=Y[:-len_test]\n",
        "    Y_test=Y[-len_test:]\n",
        "\n",
        "    len_train=X_closeness_train.shape[0]\n",
        "    len_test=X_closeness_test.shape[0]\n",
        "    print('len_train='+str(len_train))\n",
        "    print('len_test ='+str(len_test ))\n",
        "\n",
        "    '''\n",
        "    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n",
        "    for i in range(poi.shape[0]):\n",
        "        poi[i]=poi[i]/np.max(poi[i])\n",
        "    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n",
        "    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n",
        "\n",
        "    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n",
        "    '''\n",
        "    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n",
        "\n",
        "\n",
        "\n",
        "print(\"loading data...\")\n",
        "#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "\n",
        "R_N = 4   # number of residual units\n",
        "\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Conv2D\n",
        "#from DST_network.STResNet import stresnet\n",
        "#import DST_network.metrics as metrics\n",
        "#import PPT3_network.metrics as metrics\n",
        "\n",
        "def build_model(external_dim,CFN):\n",
        "  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n",
        "  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n",
        "  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n",
        "\n",
        "  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n",
        "\n",
        "  adam = Adam(lr=lr)\n",
        "  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n",
        "  #model.summary()\n",
        "  #from keras.utils.visualize_util import plot\n",
        "  #plot(model, to_file='model.png', show_shapes=True)\n",
        "  return model\n",
        "\n",
        "\n",
        "CF=64\n",
        "\n",
        "iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n",
        "\n",
        "RMSE=np.zeros([iterate_num,1])\n",
        "MAE =np.zeros([iterate_num,1])\n",
        "count_sum=iterate_num\n",
        "\n",
        "import time\n",
        "\n",
        "count=0\n",
        "\n",
        "\n",
        "for iterate_index in range(iterate_num):\n",
        "  count=count+1\n",
        "  iterate=iterate_loop[iterate_index]\n",
        "\n",
        "  time_start=time.time()\n",
        "\n",
        "  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n",
        "\n",
        "  model = build_model(external_dim=False,CFN=CF)\n",
        "  '''\n",
        "  model_checkpoint=ModelCheckpoint(\n",
        "      filepath=F,\n",
        "      monitor='val_rmse',\n",
        "      verbose=1,\n",
        "      save_best_only=True,\n",
        "      save_weights_only=False,\n",
        "      mode='min',\n",
        "      period=1)\n",
        "  '''\n",
        "  print('=' * 10)\n",
        "  print(\"training model...\")\n",
        "  history = model.fit(X_train, Y_train,\n",
        "                      epochs=epoch,\n",
        "                      batch_size=batch_size,\n",
        "                      validation_split=0.1,\n",
        "                      #callbacks=[model_checkpoint],\n",
        "                      verbose=0)\n",
        "\n",
        "  #print('=' * 10)\n",
        "  #print('evaluating using the model that has the best loss on the valid set')\n",
        "  #model.load_weights(F)\n",
        "\n",
        "  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n",
        "  print('              mse     rmse    mae')\n",
        "  print('Train score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
        "  print('Test  score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  print(np.array(score))\n",
        "\n",
        "  RMSE[iterate_index,0]=score[1]\n",
        "  MAE [iterate_index,0]=score[2]\n",
        "\n",
        "  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n",
        "\n",
        "  np.set_printoptions(precision=4, suppress=True)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  for_show=np.mean(for_show,axis=0)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n",
        "\n",
        "  time_end=time.time()\n",
        "\n",
        "  print('totally cost',time_end-time_start)\n",
        "  print(str(count)+'/'+str(count_sum))\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "WYxOJ4yGox7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0063275-cc7f-4c46-9786-e7b6c0c42e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data...\n",
            "all_data shape:  (797, 1, 14, 12)\n",
            "max= 130.0  min= 0.0\n",
            "mean= -0.9962962069298331  variance= 0.0168414251671113\n",
            "number_of_skip_hours: 224\n",
            "len_train=461\n",
            "len_test =112\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000116 0.010757 0.00276 ]\n",
            "RMSE  MAE\n",
            "[[0.0108 0.0028]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0011 0.0003]\n",
            "totally cost 19.54152512550354\n",
            "1/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000115 0.010744 0.002763]\n",
            "RMSE  MAE\n",
            "[[0.0108 0.0028]\n",
            " [0.0107 0.0028]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0022 0.0006]\n",
            "totally cost 19.739707231521606\n",
            "2/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000116 0.010772 0.00277 ]\n",
            "RMSE  MAE\n",
            "[[0.0108 0.0028]\n",
            " [0.0107 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0032 0.0008]\n",
            "totally cost 19.545132398605347\n",
            "3/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000116 0.010764 0.002758]\n",
            "RMSE  MAE\n",
            "[[0.0108 0.0028]\n",
            " [0.0107 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0043 0.0011]\n",
            "totally cost 19.42006254196167\n",
            "4/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000114 0.010672 0.003157]\n",
            "RMSE  MAE\n",
            "[[0.0108 0.0028]\n",
            " [0.0107 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0107 0.0032]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0054 0.0014]\n",
            "totally cost 20.042930603027344\n",
            "5/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000117 0.010794 0.002788]\n",
            "RMSE  MAE\n",
            "[[0.0108 0.0028]\n",
            " [0.0107 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0107 0.0032]\n",
            " [0.0108 0.0028]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0065 0.0017]\n",
            "totally cost 19.43608570098877\n",
            "6/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000116 0.010764 0.002828]\n",
            "RMSE  MAE\n",
            "[[0.0108 0.0028]\n",
            " [0.0107 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0107 0.0032]\n",
            " [0.0108 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0075 0.002 ]\n",
            "totally cost 19.840319633483887\n",
            "7/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000116 0.010793 0.002754]\n",
            "RMSE  MAE\n",
            "[[0.0108 0.0028]\n",
            " [0.0107 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0107 0.0032]\n",
            " [0.0108 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0086 0.0023]\n",
            "totally cost 20.016664743423462\n",
            "8/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000115 0.010741 0.00287 ]\n",
            "RMSE  MAE\n",
            "[[0.0108 0.0028]\n",
            " [0.0107 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0107 0.0032]\n",
            " [0.0108 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0107 0.0029]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0097 0.0025]\n",
            "totally cost 19.934890508651733\n",
            "9/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.000114 0.010666 0.003097]\n",
            "RMSE  MAE\n",
            "[[0.0108 0.0028]\n",
            " [0.0107 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0107 0.0032]\n",
            " [0.0108 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0108 0.0028]\n",
            " [0.0107 0.0029]\n",
            " [0.0107 0.0031]]\n",
            "RMSE  MAE\n",
            "[0.0107 0.0029]\n",
            "totally cost 20.147704124450684\n",
            "10/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# m6_Pro\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class MM:\n",
        "    def __init__(self,MM_max,MM_min):\n",
        "        self.max=MM_max\n",
        "        self.min=MM_min\n",
        "\n",
        "# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n",
        "def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n",
        "\n",
        "    all_data=np.load('data2/m6_Pro.npy')\n",
        "    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n",
        "    len_total,feature,map_height,map_width=all_data.shape\n",
        "    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n",
        "    #len_total,feature,map_height,map_width=all_data.shape\n",
        "    print('all_data shape: ',all_data.shape)\n",
        "    #mm=MM(np.max(all_data),np.min(all_data))\n",
        "    print('max=',np.max(all_data),' min=',np.min(all_data))\n",
        "\n",
        "    #for time\n",
        "    time=np.arange(len_total,dtype=int)\n",
        "    #hour\n",
        "    time_hour=time%T_period\n",
        "    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n",
        "    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n",
        "    for i in range(len_total):\n",
        "        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #day\n",
        "    time_day=(time//T_period)%7\n",
        "    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n",
        "    for i in range(len_total):\n",
        "        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #con\n",
        "    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n",
        "\n",
        "    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n",
        "    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n",
        "\n",
        "    if len_trend>0:\n",
        "        number_of_skip_hours=T_trend*len_trend\n",
        "    elif len_period>0:\n",
        "        number_of_skip_hours=T_period*len_period\n",
        "    elif len_closeness>0:\n",
        "        number_of_skip_hours=T_closeness*len_closeness\n",
        "    else:\n",
        "        print(\"wrong\")\n",
        "    print('number_of_skip_hours:',number_of_skip_hours)\n",
        "\n",
        "    Y=all_data[number_of_skip_hours:len_total]\n",
        "\n",
        "    if len_closeness>0:\n",
        "        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n",
        "        for i in range(len_closeness-1):\n",
        "            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n",
        "    if len_period>0:\n",
        "        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n",
        "        for i in range(len_period-1):\n",
        "            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n",
        "    if len_trend>0:\n",
        "        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n",
        "        for i in range(len_trend-1):\n",
        "            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n",
        "\n",
        "    matrix_T=matrix_T[number_of_skip_hours:]\n",
        "\n",
        "    X_closeness_train=X_closeness[:-len_test]\n",
        "    X_period_train=X_period[:-len_test]\n",
        "    X_trend_train=X_trend[:-len_test]\n",
        "    T_train=matrix_T[:-len_test]\n",
        "    X_closeness_test=X_closeness[-len_test:]\n",
        "    X_period_test=X_period[-len_test:]\n",
        "    X_trend_test=X_trend[-len_test:]\n",
        "    T_test=matrix_T[-len_test:]\n",
        "\n",
        "    X_train=[X_closeness_train,X_period_train,X_trend_train]\n",
        "    X_test=[X_closeness_test,X_period_test,X_trend_test]\n",
        "    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n",
        "    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n",
        "    Y_train=Y[:-len_test]\n",
        "    Y_test=Y[-len_test:]\n",
        "\n",
        "    len_train=X_closeness_train.shape[0]\n",
        "    len_test=X_closeness_test.shape[0]\n",
        "    print('len_train='+str(len_train))\n",
        "    print('len_test ='+str(len_test ))\n",
        "\n",
        "    '''\n",
        "    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n",
        "    for i in range(poi.shape[0]):\n",
        "        poi[i]=poi[i]/np.max(poi[i])\n",
        "    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n",
        "    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n",
        "\n",
        "    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n",
        "    '''\n",
        "    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n",
        "\n",
        "\n",
        "\n",
        "print(\"loading data...\")\n",
        "#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "\n",
        "R_N = 4   # number of residual units\n",
        "\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Conv2D\n",
        "#from DST_network.STResNet import stresnet\n",
        "#import DST_network.metrics as metrics\n",
        "#import PPT3_network.metrics as metrics\n",
        "\n",
        "def build_model(external_dim,CFN):\n",
        "  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n",
        "  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n",
        "  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n",
        "\n",
        "  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n",
        "\n",
        "  adam = Adam(lr=lr)\n",
        "  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n",
        "  #model.summary()\n",
        "  #from keras.utils.visualize_util import plot\n",
        "  #plot(model, to_file='model.png', show_shapes=True)\n",
        "  return model\n",
        "\n",
        "\n",
        "CF=64\n",
        "\n",
        "iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n",
        "\n",
        "RMSE=np.zeros([iterate_num,1])\n",
        "MAE =np.zeros([iterate_num,1])\n",
        "count_sum=iterate_num\n",
        "\n",
        "import time\n",
        "\n",
        "count=0\n",
        "\n",
        "\n",
        "for iterate_index in range(iterate_num):\n",
        "  count=count+1\n",
        "  iterate=iterate_loop[iterate_index]\n",
        "\n",
        "  time_start=time.time()\n",
        "\n",
        "  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n",
        "\n",
        "  model = build_model(external_dim=False,CFN=CF)\n",
        "  '''\n",
        "  model_checkpoint=ModelCheckpoint(\n",
        "      filepath=F,\n",
        "      monitor='val_rmse',\n",
        "      verbose=1,\n",
        "      save_best_only=True,\n",
        "      save_weights_only=False,\n",
        "      mode='min',\n",
        "      period=1)\n",
        "  '''\n",
        "  print('=' * 10)\n",
        "  print(\"training model...\")\n",
        "  history = model.fit(X_train, Y_train,\n",
        "                      epochs=epoch,\n",
        "                      batch_size=batch_size,\n",
        "                      validation_split=0.1,\n",
        "                      #callbacks=[model_checkpoint],\n",
        "                      verbose=0)\n",
        "\n",
        "  #print('=' * 10)\n",
        "  #print('evaluating using the model that has the best loss on the valid set')\n",
        "  #model.load_weights(F)\n",
        "\n",
        "  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n",
        "  print('              mse     rmse    mae')\n",
        "  print('Train score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
        "  print('Test  score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  print(np.array(score))\n",
        "\n",
        "  RMSE[iterate_index,0]=score[1]\n",
        "  MAE [iterate_index,0]=score[2]\n",
        "\n",
        "  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n",
        "\n",
        "  np.set_printoptions(precision=4, suppress=True)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  for_show=np.mean(for_show,axis=0)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n",
        "\n",
        "  time_end=time.time()\n",
        "\n",
        "  print('totally cost',time_end-time_start)\n",
        "  print(str(count)+'/'+str(count_sum))\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "ju7JGMXjoxz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af91e3df-e649-4ee5-f718-dddaad87443d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data...\n",
            "all_data shape:  (797, 1, 14, 12)\n",
            "max= 35.0  min= 0.0\n",
            "mean= -0.985686545634565  variance= 0.052230389053797795\n",
            "number_of_skip_hours: 224\n",
            "len_train=461\n",
            "len_test =112\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001645 0.040562 0.01551 ]\n",
            "RMSE  MAE\n",
            "[[0.0406 0.0155]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0041 0.0016]\n",
            "totally cost 19.594473600387573\n",
            "1/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001698 0.041201 0.013393]\n",
            "RMSE  MAE\n",
            "[[0.0406 0.0155]\n",
            " [0.0412 0.0134]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0082 0.0029]\n",
            "totally cost 20.32574486732483\n",
            "2/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.00168  0.040982 0.016089]\n",
            "RMSE  MAE\n",
            "[[0.0406 0.0155]\n",
            " [0.0412 0.0134]\n",
            " [0.041  0.0161]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0123 0.0045]\n",
            "totally cost 19.534133195877075\n",
            "3/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001717 0.041436 0.013766]\n",
            "RMSE  MAE\n",
            "[[0.0406 0.0155]\n",
            " [0.0412 0.0134]\n",
            " [0.041  0.0161]\n",
            " [0.0414 0.0138]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0164 0.0059]\n",
            "totally cost 19.92290711402893\n",
            "4/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001649 0.040606 0.01465 ]\n",
            "RMSE  MAE\n",
            "[[0.0406 0.0155]\n",
            " [0.0412 0.0134]\n",
            " [0.041  0.0161]\n",
            " [0.0414 0.0138]\n",
            " [0.0406 0.0147]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0205 0.0073]\n",
            "totally cost 19.84169030189514\n",
            "5/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001782 0.042209 0.011295]\n",
            "RMSE  MAE\n",
            "[[0.0406 0.0155]\n",
            " [0.0412 0.0134]\n",
            " [0.041  0.0161]\n",
            " [0.0414 0.0138]\n",
            " [0.0406 0.0147]\n",
            " [0.0422 0.0113]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0247 0.0085]\n",
            "totally cost 19.222509145736694\n",
            "6/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.00174  0.041716 0.013835]\n",
            "RMSE  MAE\n",
            "[[0.0406 0.0155]\n",
            " [0.0412 0.0134]\n",
            " [0.041  0.0161]\n",
            " [0.0414 0.0138]\n",
            " [0.0406 0.0147]\n",
            " [0.0422 0.0113]\n",
            " [0.0417 0.0138]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0289 0.0099]\n",
            "totally cost 19.30138397216797\n",
            "7/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001697 0.041189 0.013769]\n",
            "RMSE  MAE\n",
            "[[0.0406 0.0155]\n",
            " [0.0412 0.0134]\n",
            " [0.041  0.0161]\n",
            " [0.0414 0.0138]\n",
            " [0.0406 0.0147]\n",
            " [0.0422 0.0113]\n",
            " [0.0417 0.0138]\n",
            " [0.0412 0.0138]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.033  0.0112]\n",
            "totally cost 19.067321062088013\n",
            "8/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001681 0.041003 0.014008]\n",
            "RMSE  MAE\n",
            "[[0.0406 0.0155]\n",
            " [0.0412 0.0134]\n",
            " [0.041  0.0161]\n",
            " [0.0414 0.0138]\n",
            " [0.0406 0.0147]\n",
            " [0.0422 0.0113]\n",
            " [0.0417 0.0138]\n",
            " [0.0412 0.0138]\n",
            " [0.041  0.014 ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0371 0.0126]\n",
            "totally cost 18.86251425743103\n",
            "9/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001654 0.04067  0.014232]\n",
            "RMSE  MAE\n",
            "[[0.0406 0.0155]\n",
            " [0.0412 0.0134]\n",
            " [0.041  0.0161]\n",
            " [0.0414 0.0138]\n",
            " [0.0406 0.0147]\n",
            " [0.0422 0.0113]\n",
            " [0.0417 0.0138]\n",
            " [0.0412 0.0138]\n",
            " [0.041  0.014 ]\n",
            " [0.0407 0.0142]]\n",
            "RMSE  MAE\n",
            "[0.0412 0.0141]\n",
            "totally cost 19.4193172454834\n",
            "10/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# m7_Res\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class MM:\n",
        "    def __init__(self,MM_max,MM_min):\n",
        "        self.max=MM_max\n",
        "        self.min=MM_min\n",
        "\n",
        "# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n",
        "def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n",
        "\n",
        "    all_data=np.load('data2/m7_Res.npy')\n",
        "    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n",
        "    len_total,feature,map_height,map_width=all_data.shape\n",
        "    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n",
        "    #len_total,feature,map_height,map_width=all_data.shape\n",
        "    print('all_data shape: ',all_data.shape)\n",
        "    #mm=MM(np.max(all_data),np.min(all_data))\n",
        "    print('max=',np.max(all_data),' min=',np.min(all_data))\n",
        "\n",
        "    #for time\n",
        "    time=np.arange(len_total,dtype=int)\n",
        "    #hour\n",
        "    time_hour=time%T_period\n",
        "    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n",
        "    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n",
        "    for i in range(len_total):\n",
        "        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #day\n",
        "    time_day=(time//T_period)%7\n",
        "    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n",
        "    for i in range(len_total):\n",
        "        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #con\n",
        "    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n",
        "\n",
        "    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n",
        "    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n",
        "\n",
        "    if len_trend>0:\n",
        "        number_of_skip_hours=T_trend*len_trend\n",
        "    elif len_period>0:\n",
        "        number_of_skip_hours=T_period*len_period\n",
        "    elif len_closeness>0:\n",
        "        number_of_skip_hours=T_closeness*len_closeness\n",
        "    else:\n",
        "        print(\"wrong\")\n",
        "    print('number_of_skip_hours:',number_of_skip_hours)\n",
        "\n",
        "    Y=all_data[number_of_skip_hours:len_total]\n",
        "\n",
        "    if len_closeness>0:\n",
        "        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n",
        "        for i in range(len_closeness-1):\n",
        "            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n",
        "    if len_period>0:\n",
        "        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n",
        "        for i in range(len_period-1):\n",
        "            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n",
        "    if len_trend>0:\n",
        "        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n",
        "        for i in range(len_trend-1):\n",
        "            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n",
        "\n",
        "    matrix_T=matrix_T[number_of_skip_hours:]\n",
        "\n",
        "    X_closeness_train=X_closeness[:-len_test]\n",
        "    X_period_train=X_period[:-len_test]\n",
        "    X_trend_train=X_trend[:-len_test]\n",
        "    T_train=matrix_T[:-len_test]\n",
        "    X_closeness_test=X_closeness[-len_test:]\n",
        "    X_period_test=X_period[-len_test:]\n",
        "    X_trend_test=X_trend[-len_test:]\n",
        "    T_test=matrix_T[-len_test:]\n",
        "\n",
        "    X_train=[X_closeness_train,X_period_train,X_trend_train]\n",
        "    X_test=[X_closeness_test,X_period_test,X_trend_test]\n",
        "    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n",
        "    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n",
        "    Y_train=Y[:-len_test]\n",
        "    Y_test=Y[-len_test:]\n",
        "\n",
        "    len_train=X_closeness_train.shape[0]\n",
        "    len_test=X_closeness_test.shape[0]\n",
        "    print('len_train='+str(len_train))\n",
        "    print('len_test ='+str(len_test ))\n",
        "\n",
        "    '''\n",
        "    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n",
        "    for i in range(poi.shape[0]):\n",
        "        poi[i]=poi[i]/np.max(poi[i])\n",
        "    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n",
        "    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n",
        "\n",
        "    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n",
        "    '''\n",
        "    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n",
        "\n",
        "\n",
        "\n",
        "print(\"loading data...\")\n",
        "#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "\n",
        "R_N = 4   # number of residual units\n",
        "\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Conv2D\n",
        "#from DST_network.STResNet import stresnet\n",
        "#import DST_network.metrics as metrics\n",
        "#import PPT3_network.metrics as metrics\n",
        "\n",
        "def build_model(external_dim,CFN):\n",
        "  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n",
        "  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n",
        "  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n",
        "\n",
        "  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n",
        "\n",
        "  adam = Adam(lr=lr)\n",
        "  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n",
        "  #model.summary()\n",
        "  #from keras.utils.visualize_util import plot\n",
        "  #plot(model, to_file='model.png', show_shapes=True)\n",
        "  return model\n",
        "\n",
        "\n",
        "CF=64\n",
        "\n",
        "iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n",
        "\n",
        "RMSE=np.zeros([iterate_num,1])\n",
        "MAE =np.zeros([iterate_num,1])\n",
        "count_sum=iterate_num\n",
        "\n",
        "import time\n",
        "\n",
        "count=0\n",
        "\n",
        "\n",
        "for iterate_index in range(iterate_num):\n",
        "  count=count+1\n",
        "  iterate=iterate_loop[iterate_index]\n",
        "\n",
        "  time_start=time.time()\n",
        "\n",
        "  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n",
        "\n",
        "  model = build_model(external_dim=False,CFN=CF)\n",
        "  '''\n",
        "  model_checkpoint=ModelCheckpoint(\n",
        "      filepath=F,\n",
        "      monitor='val_rmse',\n",
        "      verbose=1,\n",
        "      save_best_only=True,\n",
        "      save_weights_only=False,\n",
        "      mode='min',\n",
        "      period=1)\n",
        "  '''\n",
        "  print('=' * 10)\n",
        "  print(\"training model...\")\n",
        "  history = model.fit(X_train, Y_train,\n",
        "                      epochs=epoch,\n",
        "                      batch_size=batch_size,\n",
        "                      validation_split=0.1,\n",
        "                      #callbacks=[model_checkpoint],\n",
        "                      verbose=0)\n",
        "\n",
        "  #print('=' * 10)\n",
        "  #print('evaluating using the model that has the best loss on the valid set')\n",
        "  #model.load_weights(F)\n",
        "\n",
        "  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n",
        "  print('              mse     rmse    mae')\n",
        "  print('Train score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
        "  print('Test  score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  print(np.array(score))\n",
        "\n",
        "  RMSE[iterate_index,0]=score[1]\n",
        "  MAE [iterate_index,0]=score[2]\n",
        "\n",
        "  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n",
        "\n",
        "  np.set_printoptions(precision=4, suppress=True)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  for_show=np.mean(for_show,axis=0)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n",
        "\n",
        "  time_end=time.time()\n",
        "\n",
        "  print('totally cost',time_end-time_start)\n",
        "  print(str(count)+'/'+str(count_sum))\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "s_q3_XRjrHUd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0af5b25-bc0a-4153-90d8-7f8b350b0458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data...\n",
            "all_data shape:  (797, 1, 14, 12)\n",
            "max= 4.0  min= 0.0\n",
            "mean= -0.9962097448766206  variance= 0.04684482697013769\n",
            "number_of_skip_hours: 224\n",
            "len_train=461\n",
            "len_test =112\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001764 0.041994 0.003857]\n",
            "RMSE  MAE\n",
            "[[0.042  0.0039]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0042 0.0004]\n",
            "totally cost 19.745365142822266\n",
            "1/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001764 0.042004 0.003344]\n",
            "RMSE  MAE\n",
            "[[0.042  0.0039]\n",
            " [0.042  0.0033]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0084 0.0007]\n",
            "totally cost 19.214434385299683\n",
            "2/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001764 0.042006 0.003614]\n",
            "RMSE  MAE\n",
            "[[0.042  0.0039]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0036]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0126 0.0011]\n",
            "totally cost 20.21133542060852\n",
            "3/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001767 0.042038 0.003256]\n",
            "RMSE  MAE\n",
            "[[0.042  0.0039]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0036]\n",
            " [0.042  0.0033]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0168 0.0014]\n",
            "totally cost 19.941722631454468\n",
            "4/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001761 0.041966 0.004068]\n",
            "RMSE  MAE\n",
            "[[0.042  0.0039]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0036]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0041]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.021  0.0018]\n",
            "totally cost 19.672107219696045\n",
            "5/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001767 0.042034 0.003311]\n",
            "RMSE  MAE\n",
            "[[0.042  0.0039]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0036]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0041]\n",
            " [0.042  0.0033]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0252 0.0021]\n",
            "totally cost 20.595882892608643\n",
            "6/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001767 0.042037 0.003168]\n",
            "RMSE  MAE\n",
            "[[0.042  0.0039]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0036]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0041]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0032]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0294 0.0025]\n",
            "totally cost 19.62606644630432\n",
            "7/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001767 0.042035 0.003274]\n",
            "RMSE  MAE\n",
            "[[0.042  0.0039]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0036]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0041]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0032]\n",
            " [0.042  0.0033]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0336 0.0028]\n",
            "totally cost 20.157050371170044\n",
            "8/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001764 0.042003 0.003375]\n",
            "RMSE  MAE\n",
            "[[0.042  0.0039]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0036]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0041]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0032]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0034]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0378 0.0031]\n",
            "totally cost 19.798108339309692\n",
            "9/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001766 0.042025 0.003268]\n",
            "RMSE  MAE\n",
            "[[0.042  0.0039]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0036]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0041]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0032]\n",
            " [0.042  0.0033]\n",
            " [0.042  0.0034]\n",
            " [0.042  0.0033]]\n",
            "RMSE  MAE\n",
            "[0.042  0.0035]\n",
            "totally cost 19.15781307220459\n",
            "10/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# m8_Shop\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class MM:\n",
        "    def __init__(self,MM_max,MM_min):\n",
        "        self.max=MM_max\n",
        "        self.min=MM_min\n",
        "\n",
        "# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n",
        "def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n",
        "\n",
        "    all_data=np.load('data2/m8_Shop.npy')\n",
        "    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n",
        "    len_total,feature,map_height,map_width=all_data.shape\n",
        "    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n",
        "    #len_total,feature,map_height,map_width=all_data.shape\n",
        "    print('all_data shape: ',all_data.shape)\n",
        "    #mm=MM(np.max(all_data),np.min(all_data))\n",
        "    print('max=',np.max(all_data),' min=',np.min(all_data))\n",
        "\n",
        "    #for time\n",
        "    time=np.arange(len_total,dtype=int)\n",
        "    #hour\n",
        "    time_hour=time%T_period\n",
        "    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n",
        "    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n",
        "    for i in range(len_total):\n",
        "        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #day\n",
        "    time_day=(time//T_period)%7\n",
        "    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n",
        "    for i in range(len_total):\n",
        "        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #con\n",
        "    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n",
        "\n",
        "    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n",
        "    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n",
        "\n",
        "    if len_trend>0:\n",
        "        number_of_skip_hours=T_trend*len_trend\n",
        "    elif len_period>0:\n",
        "        number_of_skip_hours=T_period*len_period\n",
        "    elif len_closeness>0:\n",
        "        number_of_skip_hours=T_closeness*len_closeness\n",
        "    else:\n",
        "        print(\"wrong\")\n",
        "    print('number_of_skip_hours:',number_of_skip_hours)\n",
        "\n",
        "    Y=all_data[number_of_skip_hours:len_total]\n",
        "\n",
        "    if len_closeness>0:\n",
        "        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n",
        "        for i in range(len_closeness-1):\n",
        "            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n",
        "    if len_period>0:\n",
        "        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n",
        "        for i in range(len_period-1):\n",
        "            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n",
        "    if len_trend>0:\n",
        "        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n",
        "        for i in range(len_trend-1):\n",
        "            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n",
        "\n",
        "    matrix_T=matrix_T[number_of_skip_hours:]\n",
        "\n",
        "    X_closeness_train=X_closeness[:-len_test]\n",
        "    X_period_train=X_period[:-len_test]\n",
        "    X_trend_train=X_trend[:-len_test]\n",
        "    T_train=matrix_T[:-len_test]\n",
        "    X_closeness_test=X_closeness[-len_test:]\n",
        "    X_period_test=X_period[-len_test:]\n",
        "    X_trend_test=X_trend[-len_test:]\n",
        "    T_test=matrix_T[-len_test:]\n",
        "\n",
        "    X_train=[X_closeness_train,X_period_train,X_trend_train]\n",
        "    X_test=[X_closeness_test,X_period_test,X_trend_test]\n",
        "    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n",
        "    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n",
        "    Y_train=Y[:-len_test]\n",
        "    Y_test=Y[-len_test:]\n",
        "\n",
        "    len_train=X_closeness_train.shape[0]\n",
        "    len_test=X_closeness_test.shape[0]\n",
        "    print('len_train='+str(len_train))\n",
        "    print('len_test ='+str(len_test ))\n",
        "\n",
        "    '''\n",
        "    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n",
        "    for i in range(poi.shape[0]):\n",
        "        poi[i]=poi[i]/np.max(poi[i])\n",
        "    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n",
        "    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n",
        "\n",
        "    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n",
        "    '''\n",
        "    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n",
        "\n",
        "\n",
        "\n",
        "print(\"loading data...\")\n",
        "#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "\n",
        "R_N = 4   # number of residual units\n",
        "\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Conv2D\n",
        "#from DST_network.STResNet import stresnet\n",
        "#import DST_network.metrics as metrics\n",
        "#import PPT3_network.metrics as metrics\n",
        "\n",
        "def build_model(external_dim,CFN):\n",
        "  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n",
        "  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n",
        "  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n",
        "\n",
        "  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n",
        "\n",
        "  adam = Adam(lr=lr)\n",
        "  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n",
        "  #model.summary()\n",
        "  #from keras.utils.visualize_util import plot\n",
        "  #plot(model, to_file='model.png', show_shapes=True)\n",
        "  return model\n",
        "\n",
        "\n",
        "CF=64\n",
        "\n",
        "iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n",
        "\n",
        "RMSE=np.zeros([iterate_num,1])\n",
        "MAE =np.zeros([iterate_num,1])\n",
        "count_sum=iterate_num\n",
        "\n",
        "import time\n",
        "\n",
        "count=0\n",
        "\n",
        "\n",
        "for iterate_index in range(iterate_num):\n",
        "  count=count+1\n",
        "  iterate=iterate_loop[iterate_index]\n",
        "\n",
        "  time_start=time.time()\n",
        "\n",
        "  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n",
        "\n",
        "  model = build_model(external_dim=False,CFN=CF)\n",
        "  '''\n",
        "  model_checkpoint=ModelCheckpoint(\n",
        "      filepath=F,\n",
        "      monitor='val_rmse',\n",
        "      verbose=1,\n",
        "      save_best_only=True,\n",
        "      save_weights_only=False,\n",
        "      mode='min',\n",
        "      period=1)\n",
        "  '''\n",
        "  print('=' * 10)\n",
        "  print(\"training model...\")\n",
        "  history = model.fit(X_train, Y_train,\n",
        "                      epochs=epoch,\n",
        "                      batch_size=batch_size,\n",
        "                      validation_split=0.1,\n",
        "                      #callbacks=[model_checkpoint],\n",
        "                      verbose=0)\n",
        "\n",
        "  #print('=' * 10)\n",
        "  #print('evaluating using the model that has the best loss on the valid set')\n",
        "  #model.load_weights(F)\n",
        "\n",
        "  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n",
        "  print('              mse     rmse    mae')\n",
        "  print('Train score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
        "  print('Test  score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  print(np.array(score))\n",
        "\n",
        "  RMSE[iterate_index,0]=score[1]\n",
        "  MAE [iterate_index,0]=score[2]\n",
        "\n",
        "  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n",
        "\n",
        "  np.set_printoptions(precision=4, suppress=True)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  for_show=np.mean(for_show,axis=0)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n",
        "\n",
        "  time_end=time.time()\n",
        "\n",
        "  print('totally cost',time_end-time_start)\n",
        "  print(str(count)+'/'+str(count_sum))\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "9z1jH3y2rHSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ee1458-11ad-4931-8104-a0b822b02be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data...\n",
            "all_data shape:  (797, 1, 14, 12)\n",
            "max= 146.0  min= 0.0\n",
            "mean= -0.9895630507750447  variance= 0.04576444793426465\n",
            "number_of_skip_hours: 224\n",
            "len_train=461\n",
            "len_test =112\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.0013   0.036053 0.008593]\n",
            "RMSE  MAE\n",
            "[[0.0361 0.0086]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0036 0.0009]\n",
            "totally cost 19.90634822845459\n",
            "1/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001281 0.035795 0.008837]\n",
            "RMSE  MAE\n",
            "[[0.0361 0.0086]\n",
            " [0.0358 0.0088]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0072 0.0017]\n",
            "totally cost 19.871694803237915\n",
            "2/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001225 0.035003 0.01161 ]\n",
            "RMSE  MAE\n",
            "[[0.0361 0.0086]\n",
            " [0.0358 0.0088]\n",
            " [0.035  0.0116]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0107 0.0029]\n",
            "totally cost 19.862059116363525\n",
            "3/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001275 0.035703 0.009073]\n",
            "RMSE  MAE\n",
            "[[0.0361 0.0086]\n",
            " [0.0358 0.0088]\n",
            " [0.035  0.0116]\n",
            " [0.0357 0.0091]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0143 0.0038]\n",
            "totally cost 20.270848512649536\n",
            "4/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001281 0.03579  0.008492]\n",
            "RMSE  MAE\n",
            "[[0.0361 0.0086]\n",
            " [0.0358 0.0088]\n",
            " [0.035  0.0116]\n",
            " [0.0357 0.0091]\n",
            " [0.0358 0.0085]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0178 0.0047]\n",
            "totally cost 19.91625690460205\n",
            "5/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001267 0.035591 0.008547]\n",
            "RMSE  MAE\n",
            "[[0.0361 0.0086]\n",
            " [0.0358 0.0088]\n",
            " [0.035  0.0116]\n",
            " [0.0357 0.0091]\n",
            " [0.0358 0.0085]\n",
            " [0.0356 0.0085]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0214 0.0055]\n",
            "totally cost 18.837690591812134\n",
            "6/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001314 0.036249 0.008279]\n",
            "RMSE  MAE\n",
            "[[0.0361 0.0086]\n",
            " [0.0358 0.0088]\n",
            " [0.035  0.0116]\n",
            " [0.0357 0.0091]\n",
            " [0.0358 0.0085]\n",
            " [0.0356 0.0085]\n",
            " [0.0362 0.0083]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.025  0.0063]\n",
            "totally cost 20.068430423736572\n",
            "7/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001283 0.035823 0.00958 ]\n",
            "RMSE  MAE\n",
            "[[0.0361 0.0086]\n",
            " [0.0358 0.0088]\n",
            " [0.035  0.0116]\n",
            " [0.0357 0.0091]\n",
            " [0.0358 0.0085]\n",
            " [0.0356 0.0085]\n",
            " [0.0362 0.0083]\n",
            " [0.0358 0.0096]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0286 0.0073]\n",
            "totally cost 19.44396162033081\n",
            "8/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001236 0.035151 0.009834]\n",
            "RMSE  MAE\n",
            "[[0.0361 0.0086]\n",
            " [0.0358 0.0088]\n",
            " [0.035  0.0116]\n",
            " [0.0357 0.0091]\n",
            " [0.0358 0.0085]\n",
            " [0.0356 0.0085]\n",
            " [0.0362 0.0083]\n",
            " [0.0358 0.0096]\n",
            " [0.0352 0.0098]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0321 0.0083]\n",
            "totally cost 20.14698362350464\n",
            "9/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.001291 0.035926 0.008683]\n",
            "RMSE  MAE\n",
            "[[0.0361 0.0086]\n",
            " [0.0358 0.0088]\n",
            " [0.035  0.0116]\n",
            " [0.0357 0.0091]\n",
            " [0.0358 0.0085]\n",
            " [0.0356 0.0085]\n",
            " [0.0362 0.0083]\n",
            " [0.0358 0.0096]\n",
            " [0.0352 0.0098]\n",
            " [0.0359 0.0087]]\n",
            "RMSE  MAE\n",
            "[0.0357 0.0092]\n",
            "totally cost 20.025205373764038\n",
            "10/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# m9_Tra\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class MM:\n",
        "    def __init__(self,MM_max,MM_min):\n",
        "        self.max=MM_max\n",
        "        self.min=MM_min\n",
        "\n",
        "# 전처리에서 한 타임슬롯이 6시간으로 처리, T_period는 기존에 24여서 4로, T_trend는 기존에 일주일이어서 4*7로 수정\n",
        "def lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness=1,T_period=4,T_trend=4*7):\n",
        "\n",
        "    all_data=np.load('data2/m9_Tra.npy')\n",
        "    all_data = all_data[:, np.newaxis, :, :] # 기존 코드와 dimension 맞춰주기 위해서 피쳐 축 하나 추가\n",
        "    len_total,feature,map_height,map_width=all_data.shape\n",
        "    #all_data=np.arange(48*24*7*256).reshape(-1,2,16,8)\n",
        "    #len_total,feature,map_height,map_width=all_data.shape\n",
        "    print('all_data shape: ',all_data.shape)\n",
        "    #mm=MM(np.max(all_data),np.min(all_data))\n",
        "    print('max=',np.max(all_data),' min=',np.min(all_data))\n",
        "\n",
        "    #for time\n",
        "    time=np.arange(len_total,dtype=int)\n",
        "    #hour\n",
        "    time_hour=time%T_period\n",
        "    #matrix_hour=np.zeros([len_total,24,map_height,map_width]) # len_total(시간 단위) 마다 시간 별 맵 매트릭스 초기화\n",
        "    matrix_hour=np.zeros([len_total,T_period,map_height,map_width]) # 24가 하루를 나타낸다고 보고, 한 슬랏에 6시간이니 24-> 4로 바꿈\n",
        "    for i in range(len_total):\n",
        "        matrix_hour[i,time_hour[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #day\n",
        "    time_day=(time//T_period)%7\n",
        "    matrix_day=np.zeros([len_total,7,map_height,map_width]) # len_total(시간 단위) 마다 요일 별 맵 매트릭스 초기화\n",
        "    for i in range(len_total):\n",
        "        matrix_day[i,time_day[i],:,:]=1 # 대각선 부분만 1로 초기화?\n",
        "    #con\n",
        "    matrix_T=np.concatenate((matrix_hour,matrix_day),axis=1) # 가로로 concat\n",
        "\n",
        "    all_data=(2.0*all_data-(np.max(all_data)+np.min(all_data)))/(np.max(all_data)-np.min(all_data))\n",
        "    print('mean=',np.mean(all_data),' variance=',np.std(all_data))\n",
        "\n",
        "    if len_trend>0:\n",
        "        number_of_skip_hours=T_trend*len_trend\n",
        "    elif len_period>0:\n",
        "        number_of_skip_hours=T_period*len_period\n",
        "    elif len_closeness>0:\n",
        "        number_of_skip_hours=T_closeness*len_closeness\n",
        "    else:\n",
        "        print(\"wrong\")\n",
        "    print('number_of_skip_hours:',number_of_skip_hours)\n",
        "\n",
        "    Y=all_data[number_of_skip_hours:len_total]\n",
        "\n",
        "    if len_closeness>0:\n",
        "        X_closeness=all_data[number_of_skip_hours-T_closeness:len_total-T_closeness]\n",
        "        for i in range(len_closeness-1):\n",
        "            X_closeness=np.concatenate((X_closeness,all_data[number_of_skip_hours-T_closeness*(2+i):len_total-T_closeness*(2+i)]),axis=1)\n",
        "    if len_period>0:\n",
        "        X_period=all_data[number_of_skip_hours-T_period:len_total-T_period]\n",
        "        for i in range(len_period-1):\n",
        "            X_period=np.concatenate((X_period,all_data[number_of_skip_hours-T_period*(2+i):len_total-T_period*(2+i)]),axis=1)\n",
        "    if len_trend>0:\n",
        "        X_trend=all_data[number_of_skip_hours-T_trend:len_total-T_trend]\n",
        "        for i in range(len_trend-1):\n",
        "            X_trend=np.concatenate((X_trend,all_data[number_of_skip_hours-T_trend*(2+i):len_total-T_trend*(2+i)]),axis=1)\n",
        "\n",
        "    matrix_T=matrix_T[number_of_skip_hours:]\n",
        "\n",
        "    X_closeness_train=X_closeness[:-len_test]\n",
        "    X_period_train=X_period[:-len_test]\n",
        "    X_trend_train=X_trend[:-len_test]\n",
        "    T_train=matrix_T[:-len_test]\n",
        "    X_closeness_test=X_closeness[-len_test:]\n",
        "    X_period_test=X_period[-len_test:]\n",
        "    X_trend_test=X_trend[-len_test:]\n",
        "    T_test=matrix_T[-len_test:]\n",
        "\n",
        "    X_train=[X_closeness_train,X_period_train,X_trend_train]\n",
        "    X_test=[X_closeness_test,X_period_test,X_trend_test]\n",
        "    #X_train=np.concatenate((X_closeness_train,X_period_train,X_trend_train),axis=1)\n",
        "    #X_test=np.concatenate((X_closeness_test,X_period_test,X_trend_test),axis=1)\n",
        "    Y_train=Y[:-len_test]\n",
        "    Y_test=Y[-len_test:]\n",
        "\n",
        "    len_train=X_closeness_train.shape[0]\n",
        "    len_test=X_closeness_test.shape[0]\n",
        "    print('len_train='+str(len_train))\n",
        "    print('len_test ='+str(len_test ))\n",
        "\n",
        "    '''\n",
        "    poi=np.load('DATA/dataBikeNYC/poi_data.npy')\n",
        "    for i in range(poi.shape[0]):\n",
        "        poi[i]=poi[i]/np.max(poi[i])\n",
        "    P_train=np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_train,axis=0)\n",
        "    P_test =np.repeat(poi.reshape(1,poi.shape[0],map_height,map_width),len_test ,axis=0)\n",
        "\n",
        "    return X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,mm.max-mm.min\n",
        "    '''\n",
        "    return X_train,T_train,Y_train,X_test,T_test,Y_test,np.max(all_data)-np.min(all_data)\n",
        "\n",
        "\n",
        "\n",
        "print(\"loading data...\")\n",
        "#X_train,T_train,P_train,Y_train,X_test,T_test,P_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "X_train,T_train,Y_train,X_test,T_test,Y_test,MM=lzq_load_data(len_test,len_closeness,len_period,len_trend,T_closeness,T_period,T_trend)\n",
        "\n",
        "R_N = 4   # number of residual units\n",
        "\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Conv2D\n",
        "#from DST_network.STResNet import stresnet\n",
        "#import DST_network.metrics as metrics\n",
        "#import PPT3_network.metrics as metrics\n",
        "\n",
        "def build_model(external_dim,CFN):\n",
        "  c_conf = (len_closeness, channel, H, W) if len_closeness > 0 else None\n",
        "  p_conf = (len_period,    channel, H, W) if len_period    > 0 else None\n",
        "  t_conf = (len_trend,     channel, H, W) if len_trend     > 0 else None\n",
        "\n",
        "  model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, external_dim=external_dim, nb_residual_unit=R_N, CF=CFN)\n",
        "\n",
        "  adam = Adam(lr=lr)\n",
        "  model.compile(loss='mse', optimizer=adam, metrics=[rmse,mae])\n",
        "  #model.summary()\n",
        "  #from keras.utils.visualize_util import plot\n",
        "  #plot(model, to_file='model.png', show_shapes=True)\n",
        "  return model\n",
        "\n",
        "\n",
        "CF=64\n",
        "\n",
        "iterate_loop=np.arange(iterate_num)+1+iterate_num*(NO-1)\n",
        "\n",
        "RMSE=np.zeros([iterate_num,1])\n",
        "MAE =np.zeros([iterate_num,1])\n",
        "count_sum=iterate_num\n",
        "\n",
        "import time\n",
        "\n",
        "count=0\n",
        "\n",
        "\n",
        "for iterate_index in range(iterate_num):\n",
        "  count=count+1\n",
        "  iterate=iterate_loop[iterate_index]\n",
        "\n",
        "  time_start=time.time()\n",
        "\n",
        "  #F='DST_MODEL/dst_model_'+str(iterate)+'_.hdf5'\n",
        "\n",
        "  model = build_model(external_dim=False,CFN=CF)\n",
        "  '''\n",
        "  model_checkpoint=ModelCheckpoint(\n",
        "      filepath=F,\n",
        "      monitor='val_rmse',\n",
        "      verbose=1,\n",
        "      save_best_only=True,\n",
        "      save_weights_only=False,\n",
        "      mode='min',\n",
        "      period=1)\n",
        "  '''\n",
        "  print('=' * 10)\n",
        "  print(\"training model...\")\n",
        "  history = model.fit(X_train, Y_train,\n",
        "                      epochs=epoch,\n",
        "                      batch_size=batch_size,\n",
        "                      validation_split=0.1,\n",
        "                      #callbacks=[model_checkpoint],\n",
        "                      verbose=0)\n",
        "\n",
        "  #print('=' * 10)\n",
        "  #print('evaluating using the model that has the best loss on the valid set')\n",
        "  #model.load_weights(F)\n",
        "\n",
        "  score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[0] // 48, verbose=0)\n",
        "  print('              mse     rmse    mae')\n",
        "  print('Train score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  score = model.evaluate(X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
        "  print('Test  score:',end=' ')\n",
        "  np.set_printoptions(precision=6, suppress=True)\n",
        "  print(np.array(score))\n",
        "\n",
        "  RMSE[iterate_index,0]=score[1]\n",
        "  MAE [iterate_index,0]=score[2]\n",
        "\n",
        "  for_show=np.concatenate([RMSE,MAE],axis=1)*MM/2\n",
        "\n",
        "  np.set_printoptions(precision=4, suppress=True)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  for_show=np.mean(for_show,axis=0)\n",
        "  print('RMSE  MAE')\n",
        "  print(for_show)\n",
        "\n",
        "  #np.save('DST_SCORE/dst_score.npy',[RMSE,MAE])\n",
        "\n",
        "  time_end=time.time()\n",
        "\n",
        "  print('totally cost',time_end-time_start)\n",
        "  print(str(count)+'/'+str(count_sum))\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "h0aYDQWkrHQB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c546bc7-e0b9-4b6e-8bcf-56499714485a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data...\n",
            "all_data shape:  (797, 1, 14, 12)\n",
            "max= 132.0  min= 0.0\n",
            "mean= -0.9752139154585828  variance= 0.08477867360777425\n",
            "number_of_skip_hours: 224\n",
            "len_train=461\n",
            "len_test =112\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.004699 0.068548 0.02173 ]\n",
            "RMSE  MAE\n",
            "[[0.0685 0.0217]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0069 0.0022]\n",
            "totally cost 20.038719654083252\n",
            "1/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.004727 0.068751 0.021249]\n",
            "RMSE  MAE\n",
            "[[0.0685 0.0217]\n",
            " [0.0688 0.0212]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0137 0.0043]\n",
            "totally cost 20.320078134536743\n",
            "2/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.004341 0.065883 0.022062]\n",
            "RMSE  MAE\n",
            "[[0.0685 0.0217]\n",
            " [0.0688 0.0212]\n",
            " [0.0659 0.0221]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0203 0.0065]\n",
            "totally cost 20.183928966522217\n",
            "3/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.004084 0.063904 0.027443]\n",
            "RMSE  MAE\n",
            "[[0.0685 0.0217]\n",
            " [0.0688 0.0212]\n",
            " [0.0659 0.0221]\n",
            " [0.0639 0.0274]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0267 0.0092]\n",
            "totally cost 19.54624629020691\n",
            "4/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.004325 0.065764 0.022789]\n",
            "RMSE  MAE\n",
            "[[0.0685 0.0217]\n",
            " [0.0688 0.0212]\n",
            " [0.0659 0.0221]\n",
            " [0.0639 0.0274]\n",
            " [0.0658 0.0228]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0333 0.0115]\n",
            "totally cost 20.360331058502197\n",
            "5/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.004724 0.068728 0.020681]\n",
            "RMSE  MAE\n",
            "[[0.0685 0.0217]\n",
            " [0.0688 0.0212]\n",
            " [0.0659 0.0221]\n",
            " [0.0639 0.0274]\n",
            " [0.0658 0.0228]\n",
            " [0.0687 0.0207]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0402 0.0136]\n",
            "totally cost 19.410449266433716\n",
            "6/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.004223 0.064982 0.022163]\n",
            "RMSE  MAE\n",
            "[[0.0685 0.0217]\n",
            " [0.0688 0.0212]\n",
            " [0.0659 0.0221]\n",
            " [0.0639 0.0274]\n",
            " [0.0658 0.0228]\n",
            " [0.0687 0.0207]\n",
            " [0.065  0.0222]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0467 0.0158]\n",
            "totally cost 19.266591548919678\n",
            "7/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.004728 0.068759 0.02122 ]\n",
            "RMSE  MAE\n",
            "[[0.0685 0.0217]\n",
            " [0.0688 0.0212]\n",
            " [0.0659 0.0221]\n",
            " [0.0639 0.0274]\n",
            " [0.0658 0.0228]\n",
            " [0.0687 0.0207]\n",
            " [0.065  0.0222]\n",
            " [0.0688 0.0212]\n",
            " [0.     0.    ]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0535 0.0179]\n",
            "totally cost 19.23630452156067\n",
            "8/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.004449 0.066701 0.022477]\n",
            "RMSE  MAE\n",
            "[[0.0685 0.0217]\n",
            " [0.0688 0.0212]\n",
            " [0.0659 0.0221]\n",
            " [0.0639 0.0274]\n",
            " [0.0658 0.0228]\n",
            " [0.0687 0.0207]\n",
            " [0.065  0.0222]\n",
            " [0.0688 0.0212]\n",
            " [0.0667 0.0225]\n",
            " [0.     0.    ]]\n",
            "RMSE  MAE\n",
            "[0.0602 0.0202]\n",
            "totally cost 18.92294669151306\n",
            "9/10\n",
            "external_dim: False\n",
            "==========\n",
            "training model...\n",
            "              mse     rmse    mae\n",
            "Train score: Test  score: [0.00428  0.065419 0.023674]\n",
            "RMSE  MAE\n",
            "[[0.0685 0.0217]\n",
            " [0.0688 0.0212]\n",
            " [0.0659 0.0221]\n",
            " [0.0639 0.0274]\n",
            " [0.0658 0.0228]\n",
            " [0.0687 0.0207]\n",
            " [0.065  0.0222]\n",
            " [0.0688 0.0212]\n",
            " [0.0667 0.0225]\n",
            " [0.0654 0.0237]]\n",
            "RMSE  MAE\n",
            "[0.0667 0.0225]\n",
            "totally cost 19.04464840888977\n",
            "10/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qX4eKng8rHN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IsE1gk5srHLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n3bVi1CJrHJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TE3MVH7QrHHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8d3Mj3pkrHE_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}